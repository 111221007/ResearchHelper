paper_id,title,abstract,authors,journal,year,volume,issue,pages,publisher,doi,url,type
paper_001,When AI meets AI: analyzing AI bills using AI,"Abstract With the rapid advancement of Artificial Intelligence (AI) technology and its pervasive integration into society, governments worldwide have introduced a range of AI-related policies. In the United States, the use of AI technology has surged significantly since 2021, driven by the emergence of generative AI and its transformative potential. In response, the U.S. Congress has proposed numerous AI-related bills, reflecting growing legislative engagement with AI governance. This study examines 204 AI-related bills introduced during the 117th and 118th Congresses (2021–2024) through computational text analysis, employing topic modeling to identify recurring legislative themes and sentiment analysis to assess congressional attitudes toward AI policies. The findings reveal distinct variations in legislative focus and tone across chambers and political parties, offering a nuanced understanding of how AI-related issues are framed within U.S. policymaking. In addition, the results highlight how AI is connected to broader opportunities and concerns, including national security, technological innovation, and public service delivery. By applying machine learning techniques to legislative texts, this research provides a systematic and scalable approach to understanding AI policymaking. The study contributes to broader discussions on the partisan and institutional dynamics shaping AI legislation in the United States, offering insights into how emerging technologies are shaped by legislative priorities, regulatory attitudes, and broader political contexts.",Heonuk Ha,AI &amp; SOCIETY,2025,,,,Springer Science and Business Media LLC,10.1007/s00146-025-02466-9,https://doi.org/10.1007/s00146-025-02466-9,journal-article
paper_002,AI Platforms Security,"This report reviews documented data leaks and security incidents involving major AI platforms including OpenAI, Google (DeepMind and Gemini), Anthropic, Meta, and Microsoft. Key findings indicate that while significant breaches have occurred—such as OpenAI's exposure of user payment information, Google's accidental indexing of private chatbot conversations, and Meta's leaked AI model—actual measurable harm to users has primarily involved temporary privacy violations, reputational damage to companies, and organizational disruptions. No substantial financial losses or extensive personal identity compromises have been recorded from these AI-related leaks to date.Compared to traditional cloud services, AI platforms present distinct, though not necessarily greater, risks. Unique vulnerabilities include the inadvertent leakage of sensitive information through conversational prompts, unintended memorization of training data, and misuse of leaked AI models to generate harmful content. Nonetheless, these risks remain relatively limited in scale, especially when users apply basic privacy precautions such as avoiding inputting sensitive personal or corporate data into publicly accessible AI tools.For an average user, the practical risk from interacting with major AI services is modest, provided standard privacy safeguards are followed. Users should exercise general caution, similar to interactions with other online services, understanding that occasional technical errors or breaches are possible but currently uncommon and rarely catastrophic.",Alexander Sidorkin,AI-EDU Arxiv,2025,,,,"California State University, Sacramento",10.36851/ai-edu.vi.5444,https://doi.org/10.36851/ai-edu.vi.5444,journal-article
