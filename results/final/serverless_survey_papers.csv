paper_id,title,abstract,authors,journal,year,volume,issue,pages,publisher,doi,url,type,abstract_source,abstract_confidence,original_category,original_keywords,contributions,limitations
paper_001,Proactive Serverless Function Resource Management,"This paper introduces a new primitive to serverless language runtimes called freshen. With freshen, developers or providers specify functionality to perform before a given function executes. This proactive technique allows for overheads associated with serverless functions to be mitigated at execution time, which improves function responsiveness. We show various predictive opportunities exist to run freshen within reasonable time windows. A high-level design and implementation are described, along with preliminary results to show the potential benefits of our scheme.",Erika Hunhoff; Shazal Irshad; Vijay Thurimella; Ali Tariq; Eric Rozner,Proceedings of the 2020 Sixth International Workshop on Serverless Computing,2020,,,61-66,ACM,10.1145/3429880.3430102,https://doi.org/10.1145/3429880.3430102,proceedings-article,Semantic Scholar,high,"Latency, Resource Management","resource management, serverless, reinforcement learning, prediction",Various predictive opportunities exist to run freshen within reasonable time windows; A new primitive to serverless language runtimes called freshen,Not explicitly mentioned
paper_002,Resource Management in Aurora Serverless,"Amazon Aurora Serverless is an on-demand, autoscaling configuration for Amazon Aurora with full MySQL and PostgreSQL compatibility. It automatically offers capacity scale-up/down (i.e., vertical scaling) based on a customer database application's needs. For customers with time-varying workloads, it offers cost savings compared to provisioned Aurora or other alternatives due to its agile and granular scaling and its usage-based charging model. This paper describes the key ideas underlying Aurora Serverless's resource management. To help meet its goals, Aurora Serverless adapts and fine tunes well-established ideas related to resource over-subscription; reactive control informed by recent measurements; distributed & hierarchical decision-making; and innovations in the DB engine, OS, and hypervisor for efficiency. Perhaps the most challenging goal is to offer a consistent resource elasticity experience while operating hosts at high degrees of utilization. Aurora Serverless implements several novel ideas for striking a balance between these opposing needs. Its technique for mapping workloads to hosts ensures that, in the common case, there is adequate spare capacity within a host to support fast scale-up for a workload. In the rare event this is not so, it live migrates workloads to ensure seamless scale-up. Its load distribution strategy is characterized by ""unbalancing"" of load across hosts to enable agile live migrations. Finally, it employs a token bucket-based rate regulation mechanism to prevent a growing workload from saturating its host faster than live migration-based remedial actions.",Bradley Barnhart; Marc Brooker; Daniil Chinenkov; Tony Hooper; Jihoun Im; Prakash Chandra Jha; Tim Kraska; Ashok Kurakula; Alexey Kuznetsov; Grant McAlister; Arjun Muthukrishnan; Aravinthan Narayanan; Douglas Terry; Bhuvan Urgaonkar; Jiaming Yan,Proceedings of the VLDB Endowment,2024,17,12,4038-4050,Association for Computing Machinery (ACM),10.14778/3685800.3685825,https://doi.org/10.14778/3685800.3685825,journal-article,Semantic Scholar,high,"Cost, Energy Consumption, Resource Management","autoscaling, resource management, serverless, elasticity, load balancing, reinforcement learning, distributed systems",Novel approach to serverless computing challenges,Not explicitly mentioned
paper_003,Function-Aware Resource Management Framework for Serverless Edge Computing,"Serverless edge computing is an emerging concept where only required functions are defined and executed as container instances at the edge cloud. The edge cloud has finite resources; therefore, sophisticated resource management is indispensable to accommodate more requests. In this article, we propose a function-aware resource management (FARM) framework for serverless edge computing that defines per-function queues to maximally utilize edge cloud resources. The FARM framework optimally determines: 1) which container instances should be maintained as warm status and 2) the amount of computing resources assigned to them. The FARM framework specifically formulates a constrained Markov decision process problem to minimize the memory resource consumption for the warm status maintenance while guaranteeing on-time task completion and converts it to a linear programming model to derive the optimal solution. The evaluation results show that the FARM framework can reduce the memory resource consumption of the edge cloud while meeting the on-time task completion.",Haneul Ko; Sangheon Pack,IEEE Internet of Things Journal,2023,10,2,1310-1319,Institute of Electrical and Electronics Engineers (IEEE),10.1109/jiot.2022.3205166,https://doi.org/10.1109/jiot.2022.3205166,journal-article,Semantic Scholar,high,"Survey, Energy Consumption, Resource Management","resource management, serverless, containerization, cloud computing, queuing, reinforcement learning, memory management",A function-aware resource management (farm) framework for serverless edge computing that defines per-function queues to maximally utilize edge cloud resources,To minimize the memory resource consumption for the warm status maintenance while guaranteeing on-time task completion and converts it to a linear programming model to derive the optimal solution
paper_004,Deadline-aware Dynamic Resource Management in Serverless Computing Environments,"Serverless computing enables rapid application development and deployment by composing loosely coupled microservices at a scale. This emerging paradigm greatly unburdens the users of cloud environments, from the need to provision and manage the underlying cloud resources. With this shift in responsibility, the cloud provider faces the challenge of providing acceptable performance to the user without compromising on reliability, while having minimal knowledge of the application requirements. Sub-optimal resource allocations, specifically the CPU resources, could result in the violation of performance requirements of applications. Further, the fine-grained serverless billing model only charges for resource usage in terms of function execution time. At the same time, the provider has to maintain the underlying infrastructure in always-on mode to facilitate asynchronous function calls. Thus, achieving optimum utilization of cloud resources without compromising on application requirements is of high importance to the provider. Most of the current works only focus on minimizing function execution times caused by delays in infrastructure set up and reducing resource costs for the end-user. However, in this paper, we focus on both the provider and user’s perspective and propose a function placement policy and a dynamic resource management policy for applications deployed in serverless computing environments. The policies minimize the resource consumption cost for the service provider while meeting the user’s application requirement, i.e., deadline. The proposed solutions are sensitive to deadline and efficiently increase the resource utilization for the provider, while dynamically managing resources to improve function response times. We implement and evaluate our approach through simulation using ContainerCloudSim toolkit. The proposed function placement policy when compared with baseline scheduling techniques can reduce resource consumption by up to three times. The dynamic resource allocation policy when evaluated with a fixed resource allocation policy and a proportional CPU-shares policy shows improvements of up to 25% in meeting the required function deadlines.",Anupama Mampage; Shanika Karunasekera; Rajkumar Buyya,"2021 IEEE/ACM 21st International Symposium on Cluster, Cloud and Internet Computing (CCGrid)",2021,,,,IEEE,10.1109/ccgrid51090.2021.00058,https://doi.org/10.1109/ccgrid51090.2021.00058,proceedings-article,Semantic Scholar,high,"Latency, Reliability Security Privacy, Cost, Energy Consumption, Resource Management","resource management, function placement, serverless, containerization, microservices, cloud computing, latency, reinforcement learning, deadline, cpu allocation","And evaluate our approach through simulation using containercloudsim toolkit; Through simulation using containercloudsim toolkit; Solutions are sensitive to deadline and efficiently increase the resource utilization for the provider, while dynamically managing resources to improve function response times","Of providing acceptable performance to the user without compromising on reliability, while having minimal knowledge of the application requirements; In this paper, we focus on both the provider and user’s perspective and propose a function placement policy and a dynamic resource management policy for applications deployed in serverless computing environments"
paper_005,Reinforcement learning for resource management in multi-tenant serverless platforms,"Serverless Function-as-a-Service (FaaS) is an emerging cloud computing paradigm that frees application developers from infrastructure management tasks such as resource provisioning and scaling. To reduce the tail latency of functions and improve resource utilization, recent research has been focused on applying online learning algorithms such as reinforcement learning (RL) to manage resources. Compared to existing heuristics-based resource management approaches, RL-based approaches eliminate humans in the loop and avoid the painstaking generation of heuristics. In this paper, we show that the state-of-the-art single-agent RL algorithm (S-RL) suffers up to 4.6x higher function tail latency degradation on multi-tenant serverless FaaS platforms and is unable to converge during training. We then propose and implement a customized multi-agent RL algorithm based on Proximal Policy Optimization, i.e., multi-agent PPO (MA-PPO). We show that in multi-tenant environments, MA-PPO enables each agent to be trained until convergence and provides online performance comparable to S-RL in single-tenant cases with less than 10% degradation. Besides, MA-PPO provides a 4.4x improvement in S-RL performance (in terms of function tail latency) in multi-tenant cases.",Haoran Qiu; Weichao Mao; Archit Patke; Chen Wang; Hubertus Franke; Zbigniew T. Kalbarczyk; Tamer Başar; Ravishankar K. Iyer,Proceedings of the 2nd European Workshop on Machine Learning and Systems,2022,,,20-28,ACM,10.1145/3517207.3526971,https://doi.org/10.1145/3517207.3526971,proceedings-article,Semantic Scholar,high,"Latency, Resource Management","autoscaling, resource management, performance optimization, serverless, cloud computing, latency, multi-tenant, reinforcement learning","That the state-of-the-art single-agent rl algorithm (s-rl) suffers up to 4; That in multi-tenant environments, ma-ppo enables each agent to be trained until convergence and provides online performance comparable to s-rl in single-tenant cases with less than 10% degradation; 4x improvement",Not explicitly mentioned
paper_006,FuncScaler: Cold-Start-Aware Holistic Autoscaling for Serverless Resource Management,"Serverless computing, an emerging paradigm, bolsters operational efficiency and cost savings by enabling the dynamic execution of fine-grained functions through a Function as a Service (FaaS). It incorporates autoscaling, thereby eliminating the need for infrastructure management. However, the conventional autoscaling strategies employed by cloud service providers frequently result in cold starts and inefficiencies. The complexity of variable workloads and the intricate interdependencies between functions amplify this challenge. For the above, this paper introduces FuncScaler, a deep learning- enhanced, cold-start-aware, holistic autoscaling approach for FaaS. FuncScaler employs a Gated Recurrent GCN to capture spatiotemporal relationships among functions, aggregating neighbour information and controlling information flow. Additionally, the framework integrates a cold-start-aware Jackson Queuing Network (JQN), which utilizes predicted workloads to initiate pre-warming and holistically autoscales. This empowers FuncScaler to reveal deeper function relationships, precisely forecast workloads, and concurrently reconfigure interconnected resources, effectively mitigating cold starts and hotspots. Our study shows FuncScaler excels beyond five comparative methods in ensuring Quality of Service (QoS) and enhancing resource utilization, additionally reducing cold start latency by 42.3% compared to the second-best approach.",Shijie Song; Haogang Tong; Chunyang Meng; Maolin Pan; Yang Yu,2024 IEEE International Conference on Web Services (ICWS),2024,7,,1036-1047,IEEE,10.1109/icws62655.2024.00122,https://doi.org/10.1109/icws62655.2024.00122,proceedings-article,Semantic Scholar,high,"Survey, Latency, QoS, Cost, Energy Consumption, Resource Management","cold start, autoscaling, resource management, serverless, cloud computing, latency, queuing, reinforcement learning, deep learning","Funcscaler, a deep learning- enhanced, cold-start-aware, holistic autoscaling approach for faas",The conventional autoscaling strategies employed by cloud service providers frequently result in cold starts and inefficiencies
paper_007,"Resource Management in Serverless Computing - Review, Research Challenges, and Prospects","Serverless Computing has become one of the major trends for running cloud applications. The main advantage of serverless computing is that the infrastructure is being completely taken care of by the providers. Users are spared the burden and the complexity of managing the infrastructure. In serverless computing, cloud applications become for the users a collection of multiple cloud functions. Even though the infrastructure is completely under the control of providers, the resource management is very complex in nature and it is essential to take both the users’ and the consumers’ service requirements into consideration to achieve quality of service (QoS). In this research paper, we conduct a literature review on serverless computing, on various opensource frameworks supporting serverless computing, and on complexities involved in the management of serverless computing platform. The paper ends with a proposal for a rankbased cloud function scheduler for the allocation of cloud functions in the serverless computing environment. Based on the existing works and the preliminary experimentation, we are evident that the proposed mechanism will impact the performance metrics of throughput and the success rate of cloud functions execution.",Kannan Govindarajan; Andrè De Tienne,2023 12th International Conference on Advanced Computing (ICoAC),2023,,,5-Jan,IEEE,10.1109/icoac59537.2023.10249574,https://doi.org/10.1109/icoac59537.2023.10249574,proceedings-article,Semantic Scholar,high,"Survey, QoS, Resource Management","resource management, serverless, cloud computing, throughput, reinforcement learning",Mechanism will impact the performance metrics of throughput and the success rate of cloud functions execution,In nature and it is essential to take both the users’ and the consumers’ service requirements into consideration to achieve quality of service (qos)
paper_008,ENSURE: Efficient Scheduling and Autonomous Resource Management in Serverless Environments,"An imminent challenge in the serverless computing landscape is the escalating cost of infrastructure needed to handle the growing traffic at scale. This work presents ENSURE, a function-level scheduler and autonomous resource manager designed to minimize provider resource costs while meeting customer performance requirements. ENSURE works by classifying incoming function requests at runtime and carefully regulating the resource usage of colocated functions on each invoker. Beyond a single invoker, ENSURE elastically scales capacity, using concepts from operations research, in response to varying workload traffic to prevent cold starts. Finally, ENSURE schedules requests by concentrating load on an adequate number of invokers to encourage reuse of active hosts (thus further avoiding cold starts) and allow unneeded capacity to provably and gracefully time out. We implement ENSURE on Apache OpenWhisk and show that, across several serverless applications and compared to existing baselines, ENSURE significantly improves resource efficiency, by as much as 52%, while providing acceptable application latency.",Amoghavarsha Suresh; Gagan Somashekar; Anandh Varadarajan; Veerendra Ramesh Kakarla; Hima Upadhyay; Anshul Gandhi,2020 IEEE International Conference on Autonomic Computing and Self-Organizing Systems (ACSOS),2020,,,,IEEE,10.1109/acsos49614.2020.00020,https://doi.org/10.1109/acsos49614.2020.00020,proceedings-article,Semantic Scholar,high,"Latency, Cost, Energy Consumption, Resource Management","cold start, resource management, serverless, latency, elasticity, reinforcement learning","Ensure on apache openwhisk and show that, across several serverless applications and compared to existing baselines, ensure significantly improves resource efficiency, by as much as 52%, while providing acceptable application latency",In the serverless computing landscape is the escalating cost of infrastructure needed to handle the growing traffic at scale
paper_009,Optimizing Resource Management in Serverless Computing: A Dynamic Adaptive Scaling Approach,"Serverless computing, recognized as Function as a Service (FaaS), represents a revolutionary shift in cloud computing, placing a focal point on code-centric development and seamless automated infrastructure management. This paper presents a novel Dynamic Adaptive Resource Scaling Model designed for serverless computing environments, addressing the need for efficient and cost-effective resource management. The model leverages real-time workload monitoring, machine learning algorithms, and predictive analytics to dynamically adjust resource allocation in response to fluctuating demand.. Our findings reveal that the proposed model not only enhances operational efficiency but also substantially reduces costs. Key metrics demonstrate up to 30% improvement in resource utilization and a 25% reduction in operational expenses. The model’s adaptability to diverse workloads makes it a robust solution for modern cloud architectures. Insights from this study are vital for developers, cloud architects, and IT managers seeking to optimize resource management in serverless environments. Future research directions include integrating advanced machine learning techniques and expanding the model’s applicability across different cloud platforms.",Tanaya Biswas; Prashant Kumar,2024 15th International Conference on Computing Communication and Networking Technologies (ICCCNT),2024,,,7-Jan,IEEE,10.1109/icccnt61001.2024.10724128,https://doi.org/10.1109/icccnt61001.2024.10724128,proceedings-article,Semantic Scholar,high,"Cost, Energy Consumption, Resource Management","autoscaling, resource management, serverless, cloud computing, reinforcement learning, prediction, monitoring","A novel dynamic adaptive resource scaling model designed for serverless computing environments, addressing the need for efficient and cost-effective resource management; Model not only enhances operational efficiency but also substantially reduces costs; 30% improvement",Also substantially reduces costs
paper_010,ATOM: AI-Powered Sustainable Resource Management for Serverless Edge Computing Environments,"Serverless edge computing decreases unnecessary resource usage on end devices with limited processing power and storage capacity. Despite its benefits, serverless edge computing's zero scalability is the major source of the cold start delay, which is yet unsolved. This latency is unacceptable for time-sensitive Internet of Things (IoT) applications like autonomous cars. Most existing approaches need containers to idle and use extra computing resources. Edge devices have fewer resources than cloud-based systems, requiring new sustainable solutions. Therefore, we propose an AI-powered, sustainable resource management framework called ATOM for serverless edge computing. ATOM utilizes a deep reinforcement learning model to predict exactly when cold start latency will happen. We create a cold start dataset using a heart disease risk scenario and deploy using Google Cloud Functions. To demonstrate the superiority of ATOM, its performance is compared with two different baselines, which use the warm-start containers and a two-layer adaptive approach. The experimental results showed that although the ATOM required more calculation time of 118.76 seconds, it performed better in predicting cold start than baseline models with an RMSE ratio of 148.76. Additionally, the energy consumption and <inline-formula><tex-math notation=""LaTeX"">$CO_{2}$</tex-math><alternatives><mml:math><mml:mrow><mml:mi>C</mml:mi><mml:msub><mml:mi>O</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math><inline-graphic xlink:href=""wu-ieq1-3348157.gif""/></alternatives></inline-formula> emission amount of these models are evaluated and compared for the training and prediction phases.",Muhammed Golec; Sukhpal Singh Gill; Felix Cuadrado; Ajith Kumar Parlikad; Minxian Xu; Huaming Wu; Steve Uhlig,IEEE Transactions on Sustainable Computing,2024,9,6,817-829,Institute of Electrical and Electronics Engineers (IEEE),10.1109/tsusc.2023.3348157,https://doi.org/10.1109/tsusc.2023.3348157,journal-article,Semantic Scholar,high,"Latency, Energy Consumption, Resource Management","cold start, warm start, resource management, serverless, containerization, cloud computing, latency, energy efficiency, reinforcement learning, prediction","An ai-powered, sustainable resource management framework called atom for serverless edge computing","The atom required more calculation time of 118; Its benefits, serverless edge computing's zero scalability is the major source of the cold start delay, which is yet unsolved"
paper_011,AQUATOPE: QoS-and-Uncertainty-Aware Resource Management for Multi-stage Serverless Workflows,"Multi-stage serverless applications, i.e., workflows with many computation and I/O stages, are becoming increasingly representative of FaaS platforms. Despite their advantages in terms of fine-grained scalability and modular development, these applications are subject to suboptimal performance, resource inefficiency, and high costs to a larger degree than previous simple serverless functions. We present Aquatope, a QoS-and-uncertainty-aware resource scheduler for end-to-end serverless workflows that takes into account the inherent uncertainty present in FaaS platforms, and improves performance predictability and resource efficiency. Aquatope uses a set of scalable and validated Bayesian models to create pre-warmed containers ahead of function invocations, and to allocate appropriate resources at function granularity to meet a complex workflow's end-to-end QoS, while minimizing resource cost. Across a diverse set of analytics and interactive multi-stage serverless workloads, Aquatope significantly outperforms prior systems, reducing QoS violations by 5X, and cost by 34% on average and up to 52% compared to other QoS-meeting methods.",Zhuangzhuang Zhou; Yanqi Zhang; Christina Delimitrou,"Proceedings of the 28th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 1",2022,,,14-Jan,ACM,10.1145/3567955.3567960,https://doi.org/10.1145/3567955.3567960,proceedings-article,Semantic Scholar,high,"QoS, Cost, Energy Consumption, Resource Management","resource management, serverless, containerization, reinforcement learning","Aquatope, a qos-and-uncertainty-aware resource scheduler for end-to-end serverless workflows that takes into account the inherent uncertainty present in faas platforms, and improves performance predictability and resource efficiency; 52% compared","Their advantages in terms of fine-grained scalability and modular development, these applications are subject to suboptimal performance, resource inefficiency, and high costs to a larger degree than previous simple serverless functions; Workflow's end-to-end qos, while minimizing resource cost"
paper_012,Joint Resource Management and Pricing for Task Offloading in Serverless Edge Computing,"We consider the problem of resource allocation, pricing and application caching for latency sensitive task offloading in serverless edge computing. We model the interaction between a profit-maximizing operator and cost-minimizing Wireless Devices (WDs) as a Stackelberg game where the operator is the leader and decides the price, resource allocation and set of applications to cache, while the WDs are the followers and decide whether to offload their tasks. We first show that the game has a Subgame Perfect Equilibrium (SPE), but computing it, is NP-hard. Importantly, we show that an SPE, which maximizes the operator's revenue, results in minimal energy consumption among the WDs. For computing an approximate SPE, we propose a linear time approximation algorithm with bounded approximation ratio for resource allocation and pricing, and we propose an efficient heuristic based on the utility density of individual applications for the joint optimization of caching, resource allocation and pricing. Our results show that the proposed algorithm outperforms state-of-the-art methods by up to an order of magnitude both in terms of revenue and total energy savings and has small computational overhead. An interesting feature of our results is that the utility of the operator is maximized by a solution that maximizes the WDs’ energy savings through computation offloading, which makes it a promising candidate for energy efficient edge cloud deployments.",Feridun Tütüncüoğlu; György Dán,IEEE Transactions on Mobile Computing,2024,23,6,7438-7452,Institute of Electrical and Electronics Engineers (IEEE),10.1109/tmc.2023.3334914,https://doi.org/10.1109/tmc.2023.3334914,journal-article,Semantic Scholar,high,"Latency, Cost, Energy Consumption, Resource Management","resource management, performance optimization, serverless, cloud computing, latency, energy efficiency, reinforcement learning","A linear time approximation algorithm with bounded approximation ratio for resource allocation and pricing, and we propose an efficient heuristic based on the utility density of individual applications for the joint optimization of caching, resource allocation and pricing; That an spe, which maximizes the operator's revenue, results in minimal energy consumption among the wds; Algorithm outperforms state-of-the-art methods by up to an order of magnitude both in terms of revenue and total energy savings and has small computational overhead","Computing it, is np-hard; Of resource allocation, pricing and application caching for latency sensitive task offloading in serverless edge computing"
paper_013,A Holistic View on Resource Management in Serverless Computing Environments: Taxonomy and Future Directions,"Serverless computing has emerged as an attractive deployment option for cloud applications in recent times. The unique features of this computing model include rapid auto-scaling, strong isolation, fine-grained billing options, and access to a massive service ecosystem, which autonomously handles resource management decisions. This model is increasingly being explored for deployments in geographically distributed edge and fog computing networks as well, due to these characteristics. Effective management of computing resources has always gained a lot of attention among researchers. The need to automate the entire process of resource provisioning, allocation, scheduling, monitoring, and scaling has resulted in the need for specialized focus on resource management under the serverless model. In this article, we identify the major aspects covering the broader concept of resource management in serverless environments and propose a taxonomy of elements that influence these aspects, encompassing characteristics of system design, workload attributes, and stakeholder expectations. We take a holistic view on serverless environments deployed across edge, fog, and cloud computing networks. We also analyse existing works discussing aspects of serverless resource management using this taxonomy. This article further identifies gaps in literature and highlights future research directions for improving capabilities of this computing model.",Anupama Mampage; Shanika Karunasekera; Rajkumar Buyya,ACM Computing Surveys,2022,54,11s,1-36,Association for Computing Machinery (ACM),10.1145/3510412,https://doi.org/10.1145/3510412,journal-article,Semantic Scholar,high,"Survey, Cost, Resource Management","autoscaling, resource management, serverless, cloud computing, reinforcement learning, monitoring, distributed systems",Novel approach to serverless computing challenges,Not explicitly mentioned
paper_014,A multi-agent deep reinforcement learning approach for optimal resource management in serverless computing,"This paper presents a Reinforcement Learning (RL) based energy market for a
prosumer dominated microgrid. The proposed market model facilitates a real-time
and demanddependent dynamic pricing environment, which reduces grid costs and
improves the economic benefits for prosumers. Furthermore, this market model
enables the grid operator to leverage prosumers storage capacity as a
dispatchable asset for grid support applications. Simulation results based on
the Deep QNetwork (DQN) framework demonstrate significant improvements of the
24-hour accumulative profit for both prosumers and the grid operator, as well
as major reductions in grid reserve power utilization.",Ashutosh Kumar Singh; Satender Kumar; Sarika Jain,Cluster Computing,2025,28,2,,Springer Science and Business Media LLC,10.1007/s10586-024-04820-w,https://doi.org/10.1007/s10586-024-04820-w,journal-article,arXiv,high,"Cost, Energy Consumption, Resource Management","resource management, serverless, energy efficiency, reinforcement learning","A reinforcement learning (rl) based energy market for a
prosumer dominated microgrid; Market model facilitates a real-time
and demanddependent dynamic pricing environment, which reduces grid costs and
improves the economic benefits for prosumers",Not explicitly mentioned
paper_015,Serverless Edge Computing Framework for Efficient Offloading Method with Time Frame Based Priority Resource Management,"With the exponential growth of data produced by ubiquitous and Internet of Things (IoT) devices, innovative methods are required to implement new IoT applications. Even though the cloud can store and process an almost infinite amount of data, low-latency applications cannot tolerate the delays that occur when sending data to and receiving it from the cloud. Bringing computation and data closer to consumers and devices, like edge computing does, seems like a promising option in this case. However, comprehensive application deployment on edge servers is limited by their limited resources. To address these issues, an edge serverless architecture is proposed in this research that makes efficient use of edge infrastructure's resources while requiring little configuration and operational overhead with reduced latency. The deployment of the system must reflect the fact that the demands of the applications must be handled at runtime, in the face of uncertainty and in a decentralized way. For the edge deployment of service-based IoT applications, a decentralized resource management technique is proposed. In this research, a Serverless Edge Computing Framework for Efficient Offloading method with Time Frame based Priority Resource Management model with Reduced Latency (SEC-TFbPRM-RL) is proposed. The goal is to make it possible for low-latency applications to run smoothly yet having a negligible effect on the edge computing environment.",Srinithya Kandukuri; Dedeepya Gayam; Sai Divya Bommisetty; Revathi Bobba; Bala Annapurna,2024 2nd International Conference on Sustainable Computing and Smart Systems (ICSCSS),2024,,,703-710,IEEE,10.1109/icscss60660.2024.10625440,https://doi.org/10.1109/icscss60660.2024.10625440,proceedings-article,Semantic Scholar,high,"Latency, Resource Management","resource management, serverless, cloud computing, latency, reinforcement learning",Novel approach to serverless computing challenges,Comprehensive application deployment on edge servers is limited by their limited resources
paper_016,"A self-adaptive batch request aggregation pattern for improving resource management, response time and costs in microservice and serverless environments","Addressing increased demand in cloud environments is typically achieved through auto-scaling the use of further resources allocated. However this comes at the trade-off of increased back-end resource stress as well as runtime costs. In this paper a request batch aggregation and management pattern is proposed and implemented, especially for cases of computational load that needs a heavyweight environment setup (such as performance prediction and AI services). The pattern acts as a preprocessing layer and accumulates requests, withholding their forwarding to the backend based on the conditions of execution (frequency of requests), in order to regulate back-end resource stress without adding extra resources. Different controlling logics are tried out for batch request release, ranging from simpler ones (batch size static regulation, time out interval) to more elaborate ones (ANN model predicting the desired batch size) for adapting the pattern configuration during runtime. Results indicate severe reduction of back-end stress through significantly reducing needed containers (therefore costs as well), enhanced response time as well as avoidance of system breakdown under heavy load. The pattern can be applied in both microservices and serverless environments, especially in Edge cases where resources are constrained.",George Kousiouris,"2021 IEEE International Performance, Computing, and Communications Conference (IPCCC)",2021,,,,IEEE,10.1109/ipccc51483.2021.9679422,https://doi.org/10.1109/ipccc51483.2021.9679422,proceedings-article,Semantic Scholar,high,"Latency, Cost, Resource Management","autoscaling, resource management, serverless, containerization, microservices, cloud computing, reinforcement learning, prediction","In this paper a request batch aggregation and management pattern is proposed and implemented, especially for cases of computational load that needs a heavyweight environment setup (such as performance prediction and ai services)",This comes at the trade-off of increased back-end resource stress as well as runtime costs
paper_017,Shared Resource Entanglement Attacks against Serverless Computing,"Serverless computing has emerged as a popular paradigm for building and deploying applications in the cloud. At the heart of this paradigm lies the concept of serverless functions, which have gained significant popularity due to their simplicity, scalability, and cost-efficiency. However, running serverless services on the same physical machine can introduce security threats and risks, primarily when identical serverless functions belong to different tenants. In this paper, we investigate the resource consumption of serverless functions and propose a shared resource entanglement (SRE) threat model. The SRE threat model enables adversaries to infer sensitive data from a victim’s serverless function by intercepting and monitoring the host kernel interacting data patterns and the data load and write rate patterns. The experiment results demonstrate that adversaries can identify patterns in the data processing of coresident serverless functions using the SRE threat model. Also, this vulnerability could lead to the leakage of sensitive data in the Kubernetes platform.",Yuwen Cui; Mingkui Wei; Zhuo Lu; Yao Liu,2024 IEEE Conference on Communications and Network Security (CNS),2024,,,9-Jan,IEEE,10.1109/cns62487.2024.10735670,https://doi.org/10.1109/cns62487.2024.10735670,proceedings-article,Semantic Scholar,high,"Reliability Security Privacy, Cost, Energy Consumption, Resource Management","serverless, cloud computing, reinforcement learning, monitoring","However, running serverless services on the same physical machine can introduce security threats and risks, primarily when identical serverless functions belong to different tenants","Running serverless services on the same physical machine can introduce security threats and risks, primarily when identical serverless functions belong to different tenants"
paper_018,Prediction-driven resource provisioning for serverless container runtimes,"In recent years Serverless Computing has emerged as a compelling cloud based model for the development of a wide range of data-intensive applications. However, rapid container provisioning introduces non-trivial challenges for FaaS cloud providers, as (i) real-world FaaS workloads may exhibit highly dynamic request patterns, (ii) applications have service-level objectives (SLOs) that must be met, and (iii) container provisioning can be a costly process. In this paper, we present SLOPE, a prediction framework for serverless FaaS platforms to address the aforementioned challenges. Specifically, it trains a neural network model that utilizes knowledge from past runs in order to estimate the number of instances required to satisfy the invocation rate requirements of the serverless applications. In cases that a priori knowledge is not available, SLOPE makes predictions using a graph edit distance approach to capture the similarities among serverless applications. Our experimental results illustrate the efficiency and benefits of our approach, which can reduce the operating costs by 66.25% on average.",Dimitrios Tomaras; Michail Tsenos; Vana Kalogeraki,2023 IEEE International Conference on Autonomic Computing and Self-Organizing Systems (ACSOS),2023,,,6-Jan,IEEE,10.1109/acsos58161.2023.00033,https://doi.org/10.1109/acsos58161.2023.00033,proceedings-article,Semantic Scholar,high,"Cost, Energy Consumption, Resource Management","serverless, containerization, cloud computing, reinforcement learning, deep learning, prediction","Slope, a prediction framework for serverless faas platforms to address the aforementioned challenges; The operating costs by 66","For faas cloud providers, as (i) real-world faas workloads may exhibit highly dynamic request patterns, (ii) applications have service-level objectives (slos) that must be met, and (iii) container provisioning can be a costly process; Rapid container provisioning introduces non-trivial challenges for faas cloud providers, as (i) real-world faas workloads may exhibit highly dynamic request patterns, (ii) applications have service-level objectives (slos) that must be met, and (iii) container provisioning can be a costly process"
paper_019,Adaptive Resource Scaling Algorithm for Serverless Computing Applications,"Serverless computing has transformed cloud-based and event-driven applications by introducing the Function-as-a-Service (FaaS) model. This model offers key benefits, including greater abstraction from underlying infrastructure, simplified management, flexible pay-as-you-go pricing, and automatic scaling and resource optimization. However, managing resources effectively in serverless environments remains challenging due to the inherent variability and unpredictability of workload demands. This paper introduces an Adaptive Resource Scaling Algorithm (ARSA) tailored for serverless applications. ARSA leverages the Auto-Regressive Integrated Moving Average (ARIMA) model to forecast workload demands. Using these predictions alongside a strategy focused on maintaining service quality, ARSA dynamically adjusts the number of container instances needed. The goal is to optimize resource usage while minimizing the occurrence of cold starts. We validated ARSA using a real-world dataset from Microsoft Azure Functions. Our evaluation compared ARSA against fixed instance settings (one, two, and three instances) and the standard Kubernetes Horizontal Pod Auto-scaler (HPA). The results demonstrate that ARSA outperforms these baseline methods by significantly reducing number of cold starts, improving CPU utilization, decreasing memory costs, reducing the number of rejected requests, and enhancing response times. These improvements underscore ARSA’s potential in efficiently managing dynamic workloads and enhancing the performance of serverless environments.",Mohammed Ali Awla; Sadoon Azizi; Ayshe Rashidi,Proceedings of the 3rd International Conference on Engineering and Innovative Technology,2025,,,,Salahaddin University-Erbil,10.31972/iceit2024.050,https://doi.org/10.31972/iceit2024.050,proceedings-article,Semantic Scholar,high,"Survey, Latency, QoS, Cost, Resource Management","cold start, autoscaling, performance optimization, serverless, containerization, cloud computing, reinforcement learning, prediction, memory management, cpu allocation",An adaptive resource scaling algorithm (arsa) tailored for serverless applications,Managing resources effectively in serverless environments remains challenging due to the inherent variability and unpredictability of workload demands
paper_020,Software Resource Disaggregation for HPC with Serverless Computing,"Aggregated HPC resources have rigid allocation systems and programming models which struggle to adapt to diverse and changing workloads. Consequently, HPC systems fail to efficiently use the large pools of unused memory and increase the utilization of idle computing resources. Prior work attempted to increase the throughput and efficiency of supercomputing systems through workload co-location and resource disaggregation. However, these methods fall short of providing a solution that can be applied to existing systems without major hardware modifications and performance losses. In this paper, we improve the utilization of supercomputers by employing the new cloud paradigm of serverless computing. We show how serverless functions provide fine-grained access to the resources of batchmanaged cluster nodes. We present an HPC-oriented Functionas-a-Service (FaaS) that satisfies the requirements of high-performance applications. We demonstrate a software resource disaggregation approach where placing functions on unallocated and underutilized nodes allows idle cores and accelerators to be utilized while retaining near-native performance.Full Paper Version: https://arxiv.org/abs/2401.10852HPC FaaS Implementation: https://github.com/spcl/rFaaS",Marcin Copik; Marcin Chrapek; Larissa Schmid; Alexandru Calotoiu; Torsten Hoefler,2024 IEEE International Parallel and Distributed Processing Symposium (IPDPS),2024,,,139-156,IEEE,10.1109/ipdps57955.2024.00021,https://doi.org/10.1109/ipdps57955.2024.00021,proceedings-article,Semantic Scholar,high,"Energy Consumption, Resource Management","serverless, cloud computing, throughput, reinforcement learning, memory management, distributed systems",An hpc-oriented functionas-a-service (faas) that satisfies the requirements of high-performance applications; How serverless functions provide fine-grained access to the resources of batchmanaged cluster nodes,These methods fall short of providing a solution that can be applied to existing systems without major hardware modifications and performance losses
paper_021,Serverless Computing: Optimizing Resource Utilization and Cost Efficiency,"Serverless computing has emerged as a transformative paradigm in cloud infrastructure, offering organizations the ability to scale their applications dynamically without the burden of managing underlying servers. By abstracting away the provisioning and scaling of infrastructure, serverless computing enables developers to focus on building and deploying their applications, while the cloud provider handles the auto- scaling, load balancing, and fault tolerance. This paper examines the key benefits and challenges of serverless computing, with a particular emphasis on optimizing resource utilization and cost efficiency. The findings suggest that serverless computing can lead to significant improvements in resource utilization and cost savings, but organizations must also address challenges related to cold starts, vendor lock-in, and monitoring complexity to fully realize the potential of this cloud computing paradigm.",Sachin Gawande; Shreya Gorde,International Journal of Innovative Science and Research Technology (IJISRT),2024,,,1061-1064,International Journal of Innovative Science and Research Technology,10.38124/ijisrt/ijisrt24oct976,https://doi.org/10.38124/ijisrt/ijisrt24oct976,journal-article,Semantic Scholar,high,"Latency, Reliability Security Privacy, Cost, Energy Consumption, Resource Management","cold start, autoscaling, serverless, cloud computing, load balancing, reinforcement learning, monitoring","By abstracting away the provisioning and scaling of infrastructure, serverless computing enables developers to focus on building and deploying their applications, while the cloud provider handles the auto- scaling, load balancing, and fault tolerance","Of serverless computing, with a particular emphasis on optimizing resource utilization and cost efficiency; Related to cold starts, vendor lock-in, and monitoring complexity to fully realize the potential of this cloud computing paradigm"
paper_022,Energy-Aware Resource Scheduling for Serverless Edge Computing,"In this paper, we present energy-aware scheduling for Serverless edge computing. Energy awareness is critical since edge nodes, in many Internet of Things (IoT) domains, are meant to be powered by renewable energy sources that are variable, making low-powered and/or overloaded (bottleneck) nodes unavailable and not operating their services. This awareness is also required since energy challenges have not been previously addressed by Serverless, largely due to its origin in cloud computing. To achieve this, we formally model an energy-aware resource scheduling problem in Serverless edge computing, given a cluster of battery-operated and renewable-energy powered nodes. Then, we devise zone-oriented and priority-based algorithms to improve the operational availability of bottleneck nodes. As assets, our algorithm coins terms “sticky offloading” and “warm scheduling” in the interest of the Quality of Service (QoS). We evaluate our proposal against well-known benchmarks using real-world implementations on a cluster of Raspberry Pis enabled with container orchestration, Kubernetes, and Serverless computing, OpenFaaS, where edge nodes are powered by real-world solar irradiation. Experimental results achieve significant improvements, up to 33%, in helping bottleneck node's operational availability while preserving the QoS. With energy awareness, now Serverless can unconditionally offer its resource efficiency and portability at the edge.",Mohammad Sadegh Aslanpour; Adel N. Toosi; Muhammad Aamir Cheema; Raj Gaire,"2022 22nd IEEE International Symposium on Cluster, Cloud and Internet Computing (CCGrid)",2022,,,190-199,IEEE,10.1109/ccgrid54584.2022.00028,https://doi.org/10.1109/ccgrid54584.2022.00028,proceedings-article,Semantic Scholar,high,"Survey, Reliability Security Privacy, QoS, Energy Consumption, Resource Management","serverless, containerization, cloud computing, energy efficiency, reinforcement learning, distributed systems",Energy-aware scheduling for serverless edge computing; Coins terms “sticky offloading” and “warm scheduling” in the interest of the quality of service (qos); 33,"Have not been previously addressed by serverless, largely due to its origin in cloud computing; In serverless edge computing, given a cluster of battery-operated and renewable-energy powered nodes"
paper_023,Network Resource Isolation in Serverless Cloud Function Service,"Serverless computing and function execution using cloud computing services are currently the subject considerable attention from both academia and industry. One of the reasons for the success of serverless computing is its straightforward interface that allows users to control the size of the memory allocated for the run-time of a function. However, this approach may result in the abstraction of too much information, and users cannot predict how their applications will perform, especially for the network resource. To address this issue, we evaluated several aspects of network resource performance. Despite the general belief, the variation of serverless applications' network performance is quite significant, and the ability to isolate network resource allocation during concurrent execution is rarely provided by service providers. Based on the results presented in this paper, we insist that network resource performance of functional execution models should be more visible and predictable, in order to expand the applications of serverless computing.",Jeongchul Kim; Jungae Park; Kyungyong Lee,2019 IEEE 4th International Workshops on Foundations and Applications of Self* Systems (FAS*W),2019,,,182-187,IEEE,10.1109/fas-w.2019.00051,https://doi.org/10.1109/fas-w.2019.00051,proceedings-article,Semantic Scholar,high,Resource Management,"resource management, serverless, cloud computing, reinforcement learning, memory management",Novel approach to serverless computing challenges,"This approach may result in the abstraction of too much information, and users cannot predict how their applications will perform, especially for the network resource; The general belief, the variation of serverless applications' network performance is quite significant, and the ability to isolate network resource allocation during concurrent execution is rarely provided by service providers"
paper_024,ProFaaS: Serverless Dynamic Resource Scheduling for Electric Grid Forecasting,"With the increasing integration of renewable energy, grid prediction tasks are facing heightened dynamics and hetero-geneity. Traditional cloud services with fixed resource allocation incur excessive costs due to resource over-provisioning. Serverless has strong resource elasticity, allowing computing resources to be used on demand, thereby improving efficiency. This paper proposes ProFaaS, an elastic forecasting system leveraging server-less computing. Our framework integrates a multi-model library and a profiler-driven dynamic scheduler to optimize task-specific Service Level Objectives (SLOs) and computational costs. A two-phase optimization mechanism is introduced: 1) Offline profiling of model performance under varying resource configurations, and 2) Online greedy algorithm selecting cost-optimal resources while meeting latency constraints. Experimental results show that ProFaaS reduces computational costs by up to 32% compared to traditional VM-based solutions. This work offers practical insights for adopting serverless architectures in energy systems, providing an efficient, scalable.",Zhaojie Wen; Yan Jiang; Feng Zhao; Yanbin Jiao; Yong Su; Zhen Qiu,2025 2nd International Conference on Smart Grid and Artificial Intelligence (SGAI),2025,,,1192-1197,IEEE,10.1109/sgai64825.2025.11009981,https://doi.org/10.1109/sgai64825.2025.11009981,proceedings-article,Semantic Scholar,high,"Latency, Cost, Energy Consumption, Resource Management","resource management, performance optimization, serverless, cloud computing, latency, elasticity, energy efficiency, reinforcement learning, prediction","Profaas, an elastic forecasting system leveraging server-less computing; Integrates a multi-model library and a profiler-driven dynamic scheduler to optimize task-specific service level objectives (slos) and computational costs; 32% compared",Not explicitly mentioned
paper_025,Heterogeneity-Aware Proactive Elastic Resource Allocation for Serverless Applications,"Serverless computing is a popular cloud computing model that offers on-demand resource allocation and pay-as-you-go application execution. However, there are still challenges in allocating resources for workflow applications: inaccurate and inefficient resource estimation, high-latency inter-function communication, and long server readiness time. Therefore, we propose the heterogeneity-aware Proactive serverLess wOrkflow Elastic Allocation method (PLOEA) to address these issues and optimize infrastructure costs for cloud service providers (CSPs) while meeting the diverse needs of developers. Specifically, we propose a resource configuration estimation method for heterogeneous workflow applications that builds an ensemble multi-task expert classifier to analyze individual and common resource usage patterns, ensuring estimation accuracy and efficiency. Further, we propose a group allocation strategy for multiple applications that optimizes the spatiotemporal distribution of instances by considering the allocation urgency, communication affinity between functions, and the multi-core architecture of servers. Furthermore, we present a proactive server elastic scaling method that senses workload features, including workload level, trend, and magnitude changes, and combines them with CSP’s attention differences to guide the server scaling size. Finally, experiments based on public datasets prove that PLOEA provides better service quality and cost efficiency than existing methods.",Binbin Feng; Zhijun Ding; Changjun Jiang,IEEE Transactions on Services Computing,2024,17,5,2473-2487,Institute of Electrical and Electronics Engineers (IEEE),10.1109/tsc.2024.3350711,https://doi.org/10.1109/tsc.2024.3350711,journal-article,Semantic Scholar,high,"Latency, QoS, Cost, Energy Consumption, Resource Management","autoscaling, resource management, serverless, cloud computing, latency, elasticity, reinforcement learning","The heterogeneity-aware proactive serverless workflow elastic allocation method (ploea) to address these issues and optimize infrastructure costs for cloud service providers (csps) while meeting the diverse needs of developers; A resource configuration estimation method for heterogeneous workflow applications that builds an ensemble multi-task expert classifier to analyze individual and common resource usage patterns, ensuring estimation accuracy and efficiency; A group allocation strategy for multiple applications that optimizes the spatiotemporal distribution of instances by considering the allocation urgency, communication affinity between functions, and the multi-core architecture of servers","In allocating resources for workflow applications: inaccurate and inefficient resource estimation, high-latency inter-function communication, and long server readiness time; There are still challenges in allocating resources for workflow applications: inaccurate and inefficient resource estimation, high-latency inter-function communication, and long server readiness time"
paper_026,Latency and resource consumption analysis for serverless edge analytics,"AbstractThe serverless computing model, implemented by Function as a Service (FaaS) platforms, can offer several advantages for the deployment of data analytics solutions in IoT environments, such as agile and on-demand resource provisioning, automatic scaling, high elasticity, infrastructure management abstraction, and a fine-grained cost model. However, in the case of applications with strict latency requirements, the cold start problem in FaaS platforms can represent an important drawback. The most common techniques to alleviate this problem, mainly based on instance pre-warming and instance reusing mechanisms, are usually not well adapted to different application profiles and, in general, can entail an extra expense of resources. In this work, we analyze the effect of instance pre-warming and instance reusing on both application latency (response time) and resource consumption, for a typical data analytics use case (a machine learning application for image classification) with different input data patterns. Furthermore, we propose extending the classical centralized cloud-based serverless FaaS platform to a two-tier distributed edge-cloud platform to bring the platform closer to the data source and reduce network latencies.",Rafael Moreno-Vozmediano; Eduardo Huedo; Rubén S. Montero; Ignacio M. Llorente,Journal of Cloud Computing,2023,12,1,,Springer Science and Business Media LLC,10.1186/s13677-023-00485-9,https://doi.org/10.1186/s13677-023-00485-9,journal-article,CrossRef,high,"Survey, Latency, Cost, Energy Consumption, Resource Management","cold start, autoscaling, serverless, cloud computing, latency, elasticity, reinforcement learning, distributed systems",Extending the classical centralized cloud-based serverless faas platform to a two-tier distributed edge-cloud platform to bring the platform closer to the data source and reduce network latencies,"In the case of applications with strict latency requirements, the cold start problem in faas platforms can represent an important drawback; In faas platforms can represent an important drawback"
paper_027,Sequence Clock: A Dynamic Resource Orchestrator for Serverless Architectures,"Function-as-a-service (FaaS) represents the next frontier in the evolution of cloud computing being an emerging paradigm that removes the burden of configuration and management issues from users. This is achieved by replacing the well-established monolithic approach with graphs of standalone, small, stateless, event-driven components called functions. At the same time, from the cloud providers’ perspective, problems such as availability, load balancing and scalability need to be resolved without being aware of the functionality, behavior or resource requirements of their tenants’ code. However, in this context, functions’ containers coexist with others inside a host of finite resources, where a passive resource allocation technique does not guarantee a well-defined quality of service (QoS) in regards to time latency. In this paper, we present Sequence Clock, an expandable latency targeting tool that actively monitors serverless invocations in a cluster and offers execution of a sequential chain of functions, also known as pipelines or sequences, while achieving the targeted time latency. Two regulation methods were utilized, with one of them achieving up to 82% decrease in the severity of time violations and in some cases even eliminating them completely.",Ioannis Fakinos; Achilleas Tzenetopoulos; Dimosthenis Masouros; Sotirios Xydis; Dimitrios Soudris,2022 IEEE 15th International Conference on Cloud Computing (CLOUD),2022,,,,IEEE,10.1109/cloud55607.2022.00024,https://doi.org/10.1109/cloud55607.2022.00024,proceedings-article,Semantic Scholar,high,"Latency, Reliability Security Privacy, QoS, Resource Management","resource management, serverless, containerization, cloud computing, latency, load balancing, reinforcement learning, distributed systems","Sequence clock, an expandable latency targeting tool that actively monitors serverless invocations in a cluster and offers execution of a sequential chain of functions, also known as pipelines or sequences, while achieving the targeted time latency; 82% decrease","In this context, functions’ containers coexist with others inside a host of finite resources, where a passive resource allocation technique does not guarantee a well-defined quality of service (qos) in regards to time latency; Such as availability, load balancing and scalability need to be resolved without being aware of the functionality, behavior or resource requirements of their tenants’ code"
paper_028,Interless: Interference-Aware Deep Resource Prediction for Serverless Computing,"Serverless is an emerging cloud computing paradigm that allows functions to share resources. However, function resource sharing introduces interference, which results in performance degradation. Existing resource prediction approaches ignore the function instance placement and interference between functions. Thus, they cannot predict the resource finely. This paper proposes Interless, an interference-aware resource prediction system for serverless computing with a sequence-to-sequence neural network. The Interless’s encoder directly learns function instance interference by the TPA-LSTM module. TPA-LSTM can also capture historical request queuing for better prediction. Interless’s decoder contains a GRU module for long-time series prediction. Long-time prediction is essential for time reservation in function scheduling and warm-up. Moreover, long-time series prediction helps Interless identify system anomalies and cyber threats by comparing monitored and predicted resource consumption. We implement Interless on top of Docker Swarm as a serverless system for resource prediction. Experimental results demonstrate that Interless reduces the MAPE, RSE, and SMAPE of prediction by 64%, 58%, and 65%, respectively, compared to the state-of-the-arts.",Ruifeng Ma; Yufeng Zhan; Tijin Yan; Yuanqing Xia; Yasir Ali,2024 36th Chinese Control and Decision Conference (CCDC),2024,,,3783-3788,IEEE,10.1109/ccdc62350.2024.10588201,https://doi.org/10.1109/ccdc62350.2024.10588201,proceedings-article,Semantic Scholar,high,"Energy Consumption, Resource Management","function placement, serverless, cloud computing, queuing, reinforcement learning, deep learning, prediction","Interless on top of docker swarm as a serverless system for resource prediction; Interless, an interference-aware resource prediction system for serverless computing with a sequence-to-sequence neural network; The mape, rse, and smape of prediction by 64%, 58%, and 65%, respectively, compared to the state-of-the-arts","Function resource sharing introduces interference, which results in performance degradation"
paper_029,"Maxwell’s Demon in Tail-tolerant, Resource-efficient Serverless Computing","Computing systems always face a “resource allocation dilemma” that shows the great difficulties in trading off resource efficiency for tail latency, due to the internal uncertainty of cluster status and execution behavior. Inspired by the imaginary “Maxwell’s demon” in thermodynamics who can reduce the uncertainty through a per-gas molecule-level control policy, we consider the “one-to-one mapping” feature of serverless computing and build a novel resource allocator, named Maxwell, that can achieve low tail latency and high resource efficiency in serverless simultaneously. Like the “Maxwell’s demon Maxwell is able to optimize the resource allocation for every request. It observes the state of each request and makes decisions about the minimum resource allocation through a reinforcement learning predictor. As the per-request-grained control incurs significant overhead, we further design a pipeline for avoiding the accumulated effect on a workflow. Experimental results show that Maxwell not only saves up to 31% CPU resources but also reduces the standard deviation of latency by 1.9×. Its time overhead is negligible and the resource overhead is also limited when the query per second $\leq$500.",Huanyu Zhang; Wenhao Huang; Laiping Zhao; Keqiu Li,2022 IEEE 28th International Conference on Parallel and Distributed Systems (ICPADS),2023,,,762-769,IEEE,10.1109/icpads56603.2022.00104,https://doi.org/10.1109/icpads56603.2022.00104,proceedings-article,Semantic Scholar,high,"Latency, Energy Consumption, Resource Management","resource management, serverless, latency, reinforcement learning, cpu allocation, distributed systems",31% cpu; The standard deviation of latency by 1,Also reduces the standard deviation of latency by 1
paper_030,MXFaaS: Resource Sharing in Serverless Environments for Parallelism and Efficiency,"Although serverless computing is a popular paradigm, current serverless environments have high overheads. Recently, it has been shown that serverless workloads frequently exhibit bursts of invocations of the same function. Such pattern is not handled well in current platforms. Supporting it efficiently can speed-up serverless execution substantially. In this paper, we target this dominant pattern with a new server-less platform design named MXFaaS. MXFaaS improves function performance by efficiently multiplexing (i.e., sharing) processor cycles, I/O bandwidth, and memory/processor state between concurrently executing invocations of the same function. MXFaaS introduces a new container abstraction called MXContainer. To enable efficient use of processor cycles, an MXContainer carefully helps schedule same-function invocations for minimal response time. To enable efficient use of I/O bandwidth, an MXContainer coalesces remote storage accesses and remote function calls from same-function invocations. Finally, to enable efficient use of memory/processor state, an MXContainer first initializes the state of its container and only later, on demand, spawns a process per function invocation, so that all invocations can share unmodified memory state and hence minimize memory footprint. We implement MXFaaS in two serverless platforms and run diverse serverless benchmarks. With MXFaaS, serverless environments are much more efficient. Compared to a state-of-the-art serverless environment, MXFaaS on average speeds-up execution by 5.2×, reduces P99 tail latency by 7.4×, and improves throughput by 4.8×. In addition, it reduces the average memory usage by 3.4×.",Jovan Stojkovic; Tianyin Xu; Hubertus Franke; Josep Torrellas,Proceedings of the 50th Annual International Symposium on Computer Architecture,2023,,,15-Jan,ACM,10.1145/3579371.3589069,https://doi.org/10.1145/3579371.3589069,proceedings-article,Semantic Scholar,high,"Survey, Latency, Energy Consumption, Resource Management","serverless, containerization, latency, throughput, reinforcement learning, memory management, cpu allocation",Mxfaas in two serverless platforms and run diverse serverless benchmarks; P99 tail latency by 7; The average memory usage by 3,"Serverless computing is a popular paradigm, current serverless environments have high overheads"
paper_031,Beyond Single Bids: Serverless Combinatorial Auctions for Efficient Resource Allocation,"In the world of cloud computing, serverless architecture has emerged as a disruptive paradigm, allowing developers to focus solely on code development while abstracting infrastructure management complexity. Nonetheless, optimizing resource allocation and price dynamics in serverless contexts is a continuing problem. This study investigates the creative incorporation of combinatorial auction processes into serverless computing, with the goal of streamlining resource allocation and pricing determinations. This paper elucidates the potential benefits of combinatorial auctions and their application to serverless systems by exploring the underlying concepts of resource allocation efficiency, cost-effectiveness, and overall performance improvement. Through an extensive review of existing literature and rigorous analysis, we demonstrate how the incorporation of combinatorial auctions can revolutionize resource utilization, alleviate vendor lock-in concerns, and catalyze the establishment of competitive pricing models in the domain of serverless computing. The findings given herein not only add to our theoretical understanding of combinatorial auctions in the context of serverless computing, but also lay the framework for actual implementation and future improvements in this field.",Vraj Nilay Shah; Raj Singh; Pritam Sarkar; Sapthak Mohajon Turjya; Sujata Swain; Anjan Bandyopadhyay,2024 2nd World Conference on Communication &amp;amp; Computing (WCONF),2024,,,6-Jan,IEEE,10.1109/wconf61366.2024.10692114,https://doi.org/10.1109/wconf61366.2024.10692114,proceedings-article,Semantic Scholar,high,"Survey, Cost, Energy Consumption, Resource Management","resource management, serverless, cloud computing, reinforcement learning","In the world of cloud computing, serverless architecture has emerged as a disruptive paradigm, allowing developers to focus solely on code development while abstracting infrastructure management complexity",Also lay the framework for actual implementation and future improvements in this field
paper_032,Optimizing Serverless Performance Through Game Theory and Efficient Resource Scheduling,"The scaler and scheduler of serverless system are the two cornerstones that ensure service quality and efficiency. However, existing scalers and schedulers are constrained by static thresholds, scaling latency, and single-dimensional optimization, making them difficult to agilely respond to dynamic workloads of functions with different characteristics. This paper proposes a game theory-based scaler and a dual-layer optimization scheduler to enhance the resource management and task allocation capabilities of serverless systems. In the scaler, we introduce the Hawkes process to quantify the “temperature” of function as an indicator of their instantaneous invocation rate. By combining dynamic thresholds and continuous monitoring, this scaler enables that scaling operations no longer lag behind changes of function instances and can even warm up beforehand. For scheduler, we refer to bin-packing strategies to optimize the distribution of containers and reduce resource fragmentation. A new concept of “CPU starvation degree” is introduced to denote the degree of CPU contention during function execution, ensuring that function requests are efficiently scheduled. Experimental analysis on ServerlessBench and Alibaba clusterdata indicates that compared to classical and state-of-the-art scalers and schedulers, the proposed scaler and scheduler achieve at least a 149% improvement in the Quality-Price Ratio, which represents the trade-off between performance and cost.",Pengwei Wang; Yi Li; Chao Fang; Yichen Zhong; Zhijun Ding,IEEE Transactions on Computers,2025,74,6,1990-2002,Institute of Electrical and Electronics Engineers (IEEE),10.1109/tc.2025.3547158,https://doi.org/10.1109/tc.2025.3547158,journal-article,Semantic Scholar,high,"Survey, Latency, QoS, Cost, Energy Consumption, Resource Management","autoscaling, resource management, performance optimization, serverless, containerization, latency, reinforcement learning, monitoring, cpu allocation, distributed systems","The hawkes process to quantify the “temperature” of function as an indicator of their instantaneous invocation rate; A game theory-based scaler and a dual-layer optimization scheduler to enhance the resource management and task allocation capabilities of serverless systems; Scaler and scheduler achieve at least a 149% improvement in the quality-price ratio, which represents the trade-off between performance and cost","Existing scalers and schedulers are constrained by static thresholds, scaling latency, and single-dimensional optimization, making them difficult to agilely respond to dynamic workloads of functions with different characteristics; To agilely respond to dynamic workloads of functions with different characteristics"
paper_033,Faashouse: Sustainable Serverless Edge Computing Through Energy-Aware Resource Scheduling,"Serverless edge computing is a specialized system design tailored for Internet of Things (IoT) applications. It leverages serverless computing to minimize operational management and enhance resource efficiency, and utilizes the concept of edge computing to allow code execution near the data sources. However, edge devices powered by renewable energy face challenges due to energy input variability, resulting in imbalances in their operational availability. As a result, high-powered nodes may waste excess energy, while low-powered nodes may frequently experience unavailability, impacting system sustainability. Addressing this issue requires energy-aware resource schedulers, but existing cloud-native serverless frameworks are energy-agnostic. To overcome this, we propose an energy-aware scheduler for sustainable serverless edge systems. We introduce a reference architecture for such systems and formally model energy-aware resource scheduling, treating the function-to-node assignment as an imbalanced energy-minimizing assignment problem. We then design an optimal offline algorithm and propose faasHouse, an online energy-aware scheduling algorithm that utilizes resource sharing through computation offloading. Lastly, we evaluate faasHouse against benchmark algorithms using real-world renewable energy traces and a practical cluster of single-board computers managed by Kubernetes. Our experimental results demonstrate significant improvements in balanced operational availability (by 46%) and throughput (by 44%) compared to the Kubernetes scheduler.",Mohammad Sadegh Aslanpour; Adel N. Toosi; Muhammad Aamir Cheema; Mohan Baruwal Chhetri,IEEE Transactions on Services Computing,2024,17,4,1533-1547,Institute of Electrical and Electronics Engineers (IEEE),10.1109/tsc.2024.3354296,https://doi.org/10.1109/tsc.2024.3354296,journal-article,Semantic Scholar,high,"Survey, Reliability Security Privacy, Energy Consumption, Resource Management","serverless, cloud computing, throughput, energy efficiency, reinforcement learning, distributed systems","An energy-aware scheduler for sustainable serverless edge systems; A reference architecture for such systems and formally model energy-aware resource scheduling, treating the function-to-node assignment as an imbalanced energy-minimizing assignment problem","Due to energy input variability, resulting in imbalances in their operational availability; Edge devices powered by renewable energy face challenges due to energy input variability, resulting in imbalances in their operational availability"
paper_034,Joint Resource Allocation for Software-Defined Serverless Service-Centric Networking,"Recently, there are significant advances in networking, computing, and caching (NCC). Nevertheless, few attempts have been made to explore the potential of the promising server-less computing paradigm in NCC integrated frameworks. In this paper, we consider a software-defined serverless service-centric networking (SD-SSCN) framework that not only dynamically orchestrates NCC by combining software-defined networking and service-centric networking technologies but also strongly focuses on the context of serverless computing. To achieve a cost-efficient green SD-SSCN system, we first formulate the joint resource allocation problem to minimize an overall average cost model. We derive this problem as a nonlinear integer programming problem, then we relax it as a quadratic programming problem and develop a primal-dual interior-point algorithm to find joint resource allocation solutions. Simulation results show that our proposed SD-SSCN framework significantly outperforms the traditional networks in terms of the average cost in the context of serverless computing.",Xiaolu Li; Renchao Xie; Tao Huang; Yunjie Liu,GLOBECOM 2022 - 2022 IEEE Global Communications Conference,2022,,,861-866,IEEE,10.1109/globecom48099.2022.10000802,https://doi.org/10.1109/globecom48099.2022.10000802,proceedings-article,Semantic Scholar,high,"Cost, Energy Consumption, Resource Management","resource management, serverless, reinforcement learning",Novel approach to serverless computing challenges,Also strongly focuses on the context of serverless computing; To minimize an overall average cost model
paper_035,Container Image Similarity-Aware Resource Provisioning for Serverless Edge Computing,"Container-enabled serverless computing has become a widely adopted approach for resource provisioning in the edge cloud. However, traffic incurred by container image pulling heavily burdens the already congested back-haul network. To relieve the problem, we do an analysis on Docker Hub, and find that instance deployment strategy has a significant impact on the back-haul traffic due to the varying similarity levels of different images. We incorporate this feature into task offloading decision and resource provisioning, and formulate the problem with a mixed integer non-linear programming (MINLP) problem. To address the challenges arising from the coupling and contradiction of instance deployment, image pulling, offloading decision, and resource allocation, we employ multi-agent deep reinforcement learning to decompose the problem into several simpler sub-problems, and design an algorithm for each sub-problem individually by exploiting convex optimization and fractional programming techniques. Simulations are conducted to validate the effectiveness of the proposed algorithm. The experiment results illustrate that our algorithm outperforms current notable solutions and improves the global utility by 13%–74%.",Ao Zhou; Sisi Li; Xiao Ma; Yiran Zhang; Shangguang Wang,2023 IEEE International Conference on Web Services (ICWS),2023,,,278-288,IEEE,10.1109/icws60048.2023.00047,https://doi.org/10.1109/icws60048.2023.00047,proceedings-article,Semantic Scholar,high,"Survey, Resource Management","resource management, performance optimization, serverless, containerization, cloud computing, reinforcement learning",Outperforms current notable solutions and improves the global utility by 13%–74%; Algorithm; The global utility by 13%–74%,"Arising from the coupling and contradiction of instance deployment, image pulling, offloading decision, and resource allocation, we employ multi-agent deep reinforcement learning to decompose the problem into several simpler sub-problems, and design an algorithm for each sub-problem individually by exploiting convex optimization and fractional programming techniques; Traffic incurred by container image pulling heavily burdens the already congested back-haul network"
paper_036,RAEF: Energy-efficient Resource Allocation through Energy Fungibility in Serverless,"Datacenters' excessive energy consumption has become an increasingly significant pain point to cloud service providers. However, existing research usually tends to focus on the server power cap to increase application throughput and do not address the rapid growth in the energy consumption of datacenters. Although the serverless architecture makes it more difficult to improve datacenter energy efficiency due to its high density and high dynamic nature, we observe that the emerging serverless workloads bring new opportunities for energy reduction. First, the energy consumption of serverless workloads during their execution time can be divided into three stages with clear boundaries: startup, runtime and idle. As the three stages have quite different energy usage patterns, we are able to reduce overall energy consumption through orchestrating the energy consumption of the stages. Second, we observe the energy fungibility phenomenon, i.e., the different combinations of multidimensional resource allocations may lead to the same latency but different energy consumption. Exploiting the balanced combination of energy consumption and performance, we can reduce the overall energy consumption without violating the latency service level agreement (SLA). Based on this, we propose RAEF, a function-level resource allocator that proactively adjusts the resources of the functions for minimizing the energy consumption with SLA guarantees. Evaluation results demonstrate that RAEF reduces energy consumption by up to 21.2 % compared to the state-of-the-art technique while guaranteeing the SLA.",Xuechao Jia; Laiping Zhao,2021 IEEE 27th International Conference on Parallel and Distributed Systems (ICPADS),2021,,,434-441,IEEE,10.1109/icpads53394.2021.00060,https://doi.org/10.1109/icpads53394.2021.00060,proceedings-article,Semantic Scholar,high,"Survey, Latency, QoS, Energy Consumption, Resource Management","resource management, serverless, cloud computing, latency, throughput, energy efficiency, reinforcement learning","Raef, a function-level resource allocator that proactively adjusts the resources of the functions for minimizing the energy consumption with sla guarantees; 21",Existing research usually tends to focus on the server power cap to increase application throughput and do not address the rapid growth in the energy consumption of datacenters; Different energy consumption
paper_037,Qora: Neural-Enhanced Interference-Aware Resource Provisioning for Serverless Computing,"Serverless is an emerging cloud paradigm that offers fine-grained resource sharing through serverless functions. However, this resource sharing can cause interference, leading to performance degradation and QoS violations. Existing white box-based approaches for serverless resource provision often demand extensive expert knowledge, which is challenging to obtain due to the complexity of interference sources. This paper proposes Qora, a neural-enhanced interference-aware resource provisioning system for serverless computing. We model the resource provisioning of serverless functions as a novel combinatorial optimization problem, wherein the constraints on the queries per second are derived from neural network performance model. By leveraging neural networks to model the nonlinear performance fluctuations under various interference sources, our approach better captures the real-world behavior of serverless functions. To solve the formulated problem efficiently, rather than adopting commercial optimizer solvers like Gurobi, we propose a two-stage-VNS algorithm that searches discrete variables more efficiently and supports Sigmoid activations, avoiding introducing redundant discrete variables. Unlike pure machine learning methods lacking theoretical optimal guarantees, our approach is rigorously proven globally optimal based on optimization theory. We implement Qora on Kubernetes as a serverless system automating resource provisioning. Experimental results demonstrate that Qora reduces the QoS violation rate by 98% while reducing up to 35% resource costs compared with the state-of-the-arts. Note to Practitioners—From the perspective of cloud service providers, this paper considers the automatic resource provisioning for serverless functions. To improve hardware utilization, cloud providers tend to co-locate serverless functions on the same server. However, co-located functions compete for shared resources (memory bandwidth, L3 cache, etc.), which causes interference and leads to performance degradation and QoS violations. We use neural networks to build the performance models of interference-prone serverless functions and form the resource allocation optimization problem with neural network performance models as constraints. Compared to white box modeling methods, our neural network modeling adapts to complex and variable interference. Compared to deep reinforcement learning methods, our combinatorial optimization methods have stronger interpretability. In order to solve this optimization problem efficiently, we design the two-stage-VNS solution algorithm. We implement Qora on Kubernetes as a serverless system, which can automatically allocate computing resources. Experiments with small-scale real clusters and large-scale simulations demonstrate the effectiveness of Qora.",Ruifeng Ma; Yufeng Zhan; Chuge Wu; Zicong Hong; Yasir Ali; Yuanqing Xia,IEEE Transactions on Automation Science and Engineering,2025,22,,10609-10624,Institute of Electrical and Electronics Engineers (IEEE),10.1109/tase.2025.3526197,https://doi.org/10.1109/tase.2025.3526197,journal-article,Semantic Scholar,high,"QoS, Cost, Resource Management","resource management, performance optimization, serverless, cloud computing, reinforcement learning, deep learning, memory management, distributed systems","A two-stage-vns algorithm that searches discrete variables more efficiently and supports sigmoid activations, avoiding introducing redundant discrete variables; The two-stage-vns solution algorithm; Qora on kubernetes as a serverless system automating resource provisioning","On the queries per second are derived from neural network performance model; This resource sharing can cause interference, leading to performance degradation and qos violations"
paper_038,A Review of Resource Reusing Paradigm in Serverless Computing System,"Serverless computing has emerged as a revolutionary paradigm in cloud computing, allowing developers to focus on code development without managing the underlying infrastructure. However, the cold start problem remains a significant challenge and can negate many of the benefits of serverless computing. This paper comprehensively reviews three different reuse techniques, namely container reuse, data caching, and function reuse, which are resource reuse paradigms in serverless computing systems, to mitigate the cold start problem and optimize performance. This review paper emphasizes the importance of resource reuse strategies in improving the efficiency and responsiveness of serverless applications, enabling wider adoption of serverless computing in more areas.",Donghyeon Kim; Mingyu Jo; Dogyun Kim; Sangoh Park,2025 International Conference on Information Networking (ICOIN),2025,,,142-145,IEEE,10.1109/icoin63865.2025.10993145,https://doi.org/10.1109/icoin63865.2025.10993145,proceedings-article,Semantic Scholar,high,"Survey, Latency, Energy Consumption, Resource Management","cold start, serverless, containerization, cloud computing, reinforcement learning","Serverless computing has emerged as a revolutionary paradigm in cloud computing, allowing developers to focus on code development without managing the underlying infrastructure",And can negate many of the benefits of serverless computing; The cold start problem remains a significant challenge and can negate many of the benefits of serverless computing
paper_039,StepConf: SLO-Aware Dynamic Resource Configuration for Serverless Function Workflows,"Function-as-a-Service (FaaS) offers a fine-grained resource provision model, enabling developers to build highly elastic cloud applications. User requests are handled by a series of serverless functions step by step, which forms a function-based workflow. The developers are required to set proper resource configuration for functions, so as to meet service level objectives (SLOs) and save cost. However, developing the resource configuration strategy is challenging. It is mainly because execution of cloud functions often suffers from cold start and performance fluctuation, which requires a dynamic configuration strategy to guarantee the SLOs. In this paper, we present StepConf, a framework that automates the resource configuration for functions as the workflow runs. StepConf optimizes memory size for each function step in the workflow and takes inter and intra-function parallelism into consideration. We evaluate StepConf on AWS Lambda. Compared with baselines, the experimental results show that StepConf can save cost up to 40.9% while ensuring the SLOs.",Zhaojie Wen; Yishuo Wang; Fangming Liu,IEEE INFOCOM 2022 - IEEE Conference on Computer Communications,2022,,,,IEEE,10.1109/infocom48880.2022.9796962,https://doi.org/10.1109/infocom48880.2022.9796962,proceedings-article,Semantic Scholar,high,"Latency, Cost, Resource Management","cold start, serverless, cloud computing, elasticity, reinforcement learning, memory management","Stepconf, a framework that automates the resource configuration for functions as the workflow runs; 40",Developing the resource configuration strategy is challenging
paper_040,SPES: Towards Optimizing Performance-Resource Trade-Off for Serverless Functions,"As an emerging cloud computing deployment paradigm, serverless computing is gaining traction due to its efficiency and ability to harness on-demand cloud resources. However, a significant hurdle remains in the form of the cold start problem, causing latency when launching new function instances from scratch. Existing solutions tend to use over-simplistic strategies for function pre-loading/unloading without full invocation pattern exploitation, rendering unsatisfactory optimization of the trade-off between cold start latency and resource waste. To bridge this gap, we propose SPES, the first differentiated scheduler for runtime cold start mitigation by optimizing serverless function provision. Our insight is that the common architecture of serverless systems prompts the concentration of certain invocation patterns, leading to predictable invocation behaviors. This allows us to categorize functions and pre-load/unload proper function instances with finer-grained strategies based on accurate invocation prediction. Experiments demonstrate the success of SPES in optimizing serverless function provision on both sides: reducing the 75th-percentile cold start rates by 49.77% and the wasted memory time by 56.43%, compared to the state-of-the-art. By mitigating the cold start issue, SPES is a promising advancement in facilitating cloud services deployed on serverless architectures.",Cheryl Lee; Zhouruixin Zhu; Tianyi Yang; Yintong Huo; Yuxin Su; Pinjia He; Michael R. Lyu,2024 IEEE 40th International Conference on Data Engineering (ICDE),2024,,,165-178,IEEE,10.1109/icde60146.2024.00020,https://doi.org/10.1109/icde60146.2024.00020,proceedings-article,Semantic Scholar,high,"Latency, Energy Consumption, Resource Management","cold start, performance optimization, serverless, cloud computing, latency, reinforcement learning, prediction, memory management","Spes, the first differentiated scheduler for runtime cold start mitigation by optimizing serverless function provision","A significant hurdle remains in the form of the cold start problem, causing latency when launching new function instances from scratch"
paper_041,KneeScale: Efficient Resource Scaling for Serverless Computing at the Edge,"Serverless computing is a promising paradigm for delivering services to the Internet of Things (IoT) applications at the edge of the network. Its event-triggered computation, as well as fine-grained and agile resource scaling, is well-suited for a resource-constrained edge computing environment. However, general-purpose auto-scalers that are predominant in the cloud settings perform poorly for serverless computing at the Edge. This is mainly due to the difficulty in quickly determining the optimal resource allocation under resource-budget constraints and dynamic workloads. In this paper, we present an adaptive auto-scaler, KneeScale, that dynamically adjusts the number of replicas for serverless functions to reach a point at which the relative cost to increase resource allocation is no longer worth the corresponding performance benefit. We have designed and implemented KneeScale as lightweight system software that utilizes Kubernetes for resource management. Experimental results with a function-as-a-service (FaaS) benchmark, FunetionBeneh, and an open-source serverless computing platform, OpenFaaS, demonstrate the superior performance and resource efficiency of KneeScale. It outperforms Kubernetes Horizontal Pod AutoScaler (HPA) and OpenFaaS built-in scheduler in terms of cumulative performance under a given resource budget by up to 32 % and 106 % respectively. KneeScale achieves higher cumulative throughput than both competing techniques, lower latencies than OpenFaaS built-in scheduler, and similar latencies compared to HPA for a variety of serverless functions.",Xue Li; Peng Kang; Jordan Molone; Wei Wang; Palden Lama,"2022 22nd IEEE International Symposium on Cluster, Cloud and Internet Computing (CCGrid)",2022,,,180-189,IEEE,10.1109/ccgrid54584.2022.00027,https://doi.org/10.1109/ccgrid54584.2022.00027,proceedings-article,Semantic Scholar,high,"Survey, Cost, Energy Consumption, Resource Management","autoscaling, resource management, serverless, cloud computing, throughput, reinforcement learning","An adaptive auto-scaler, kneescale, that dynamically adjusts the number of replicas for serverless functions to reach a point at which the relative cost to increase resource allocation is no longer worth the corresponding performance benefit; 32",And dynamic workloads; General-purpose auto-scalers that are predominant in the cloud settings perform poorly for serverless computing at the edge
paper_042,FaaSBatch: Boosting Serverless Efficiency With In-Container Parallelism and Resource Multiplexing,"With high scalability and flexibility, serverless computing is becoming the most promising computing model. Existing serverless computing platforms initiate a container for each function invocation, which leads to a huge waste of computing resources. Our examinations reveal that (i) executing invocations concurrently within a single container can provide comparable performance to that provided by multiple containers (i.e., traditional approaches); (ii) redundant resources generated within a container result in memory resource waste, which prolongs the execution time of function invocations. Motivated by these insightful observations, we propose FaaSBatch - a serverless framework that reduces invocation latency and saves scarce computing resources. In particular, FaaSBatch first classifies concurrent function requests into different function groups according to the invocation information. Next, FaaSBatch batches the invocations of each group, aiming to minimize resource utilization. Then, FaaSBatch utilizes an inline parallel policy to map each group of batched invocations into a single container. Finally, FaaSBatch expands and executes invocations of containers in parallel. To further reduce invocation latency and resource utilization, within each container, FaaSBatch reuses redundant resources created during function execution. We conduct extensive experiments based on Azure traces to evaluate the effectiveness and performance of FaaSBatch. We compare FaaSBatch with three state-of-the-art schedulers Vanilla, SFS, and Kraken. Our experimental results show that FaaSBatch effectively and remarkably slashes invocation latency and resource overhead. For instance, when executing I/O functions, FaaSBatch cuts back the invocation latency of Vanilla, SFS, and Kraken by up to 72.58%, 74.10%, and 72.62%, respectively; FaaSBatch also slashes the resource overhead of Vanilla, SFS, and Kraken by 70.2% to 98.40%, 67.74% to 98.12%, and 43.01% to 78.90%, respectively.",Zhaorui Wu; Yuhui Deng; Yi Zhou; Jie Li; Shujie Pang; Xiao Qin,IEEE Transactions on Computers,2024,73,4,1071-1085,Institute of Electrical and Electronics Engineers (IEEE),10.1109/tc.2024.3352834,https://doi.org/10.1109/tc.2024.3352834,journal-article,Semantic Scholar,high,"Latency, QoS, Energy Consumption, Resource Management","serverless, containerization, latency, reinforcement learning, memory management",Faasbatch - a serverless framework that reduces invocation latency and saves scarce computing resources; 72,Not explicitly mentioned
paper_043,Resource-Efficient DNN Inference With Early Exiting in Serverless Edge Computing,"Serverless Edge Computing (SEC) has gained widespread adoption in improving resource utilization due to its triggered event-driven model. However, deploying deep neural network (DNN) inference services directly in SEC leads to resource inefficiencies, which stem from two key factors. First, existing methods adopt model-wise function encapsulation, which requires the entire DNN model to occupy memory throughout its execution lifecycle. This increases both memory footprint and occupancy time. Second, uniform DNN inference for diversity input leads to redundant computations and additional inference time. To this end, we propose REDI, a novel framework that leverages fine-grained block-wise function encapsulation and progressive inference to provide resource-efficient DNN inference while ensuring latency requirements. REDI enables the release of memory from already inferred shallow networks and allows each request to exit early based on input data complexity, eliminating redundant computations. To fully unleash the potential, REDI jointly considers resource heterogeneity, data diversity, and environment dynamics to investigate the block-wise function placement problem. We introduce an uncertainty-aware online learning-driven algorithm with bounded regret. Finally, we conduct extensive trace-driven experiments to evaluate our methods, demonstrating that REDI achieves a significant speedup of up to <inline-formula><tex-math notation=""LaTeX"">$6.52\times$</tex-math><alternatives><mml:math><mml:mrow><mml:mn>6</mml:mn><mml:mo>.</mml:mo><mml:mn>52</mml:mn><mml:mo>×</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href=""dong-ieq1-3514993.gif""/></alternatives></inline-formula> in terms of resource usage cost compared to state-of-the-art methods.",Xiaolin Guo; Fang Dong; Dian Shen; Zhaowu Huang; Jinghui Zhang,IEEE Transactions on Mobile Computing,2025,24,5,3650-3666,Institute of Electrical and Electronics Engineers (IEEE),10.1109/tmc.2024.3514993,https://doi.org/10.1109/tmc.2024.3514993,journal-article,Semantic Scholar,high,"Latency, Cost, Resource Management","function placement, serverless, latency, reinforcement learning, deep learning, memory management","Redi, a novel framework that leverages fine-grained block-wise function encapsulation and progressive inference to provide resource-efficient dnn inference while ensuring latency requirements; An uncertainty-aware online learning-driven algorithm with bounded regret","Deploying deep neural network (dnn) inference services directly in sec leads to resource inefficiencies, which stem from two key factors"
paper_044,Efficient Serverless Resource Allocation for MapReduce Job Based on A* Algorithm,"With the development of cloud computing technology, serverless computing models have gradually emerged. The existing serverless resource allocation framework, Astrea, models the resource allocation problem as the shortest path problem in graph theory and solves it using the Dijkstra algorithm, effectively addressing resource allocation issues. However, its computational complexity can be inefficient for large-scale applications. The A* algorithm generally outperforms Dijkstra's by avoiding unnecessary paths and converging more quickly, enhancing efficiency. This paper proposes an improved A* algorithm based on the serverless job scheduling and resource allocation framework, Astrea. Implement timely budget limit checks to reduce unnecessary path exploration. Priority queues and hash tables are used to enhance data access and path query efficiency. Optimize paths with heuristic function prioritization to focus on cost-effective routes. As a result, the search space is narrowed. The Astrea framework, implemented with the A * algorithm, enhances execution efficiency. Theoretical analysis and simulation experiments confirm this, showing approximately 30% improvement compared to traditional methods. The A* algorithm is applied to serverless resource allocation. It optimizes the algorithm for large-scale MapReduce tasks. The results demonstrate the algorithm's effectiveness in this new application.",Chuanzhi Chen; Hongyan Sang; Jinquan Zhang; Hongqing Liu; Hao Chi,2024 International Conference on New Trends in Computational Intelligence (NTCI),2024,,,212-216,IEEE,10.1109/ntci64025.2024.10776065,https://doi.org/10.1109/ntci64025.2024.10776065,proceedings-article,Semantic Scholar,high,"Survey, Cost, Energy Consumption, Resource Management","resource management, serverless, cloud computing, queuing, reinforcement learning","An improved a* algorithm based on the serverless job scheduling and resource allocation framework, astrea; 30% improvement","Its computational complexity can be inefficient for large-scale applications; As the shortest path problem in graph theory and solves it using the dijkstra algorithm, effectively addressing resource allocation issues"
paper_045,"Fair, Efficient Multi-Resource Scheduling for Stateless Serverless Functions with Anubis","Although serverless platforms have been extremely popular recently, certain kinds of applications are not well-supported by these platforms. For example, they work well for workloads that transform or aggregate bulk data but not for applications where predictable response times are crucial. These workloads have fine-grained tasks and stringent service level agreements (SLAs). Current serverless platforms’ overheads and resource contention lead to variable performance, making using them for real-time online applications impossible. We demonstrate Anubis, a new platform built on top of OpenWhisk, that helps meet SLAs for response-time-sensitive serverless workloads, even when multiple concurrent workloads compete for various resource types. Anubis’s approach centers on multi-resource fair queuing. Even as stateless functions compete for CPU, storage, and network resources, Anubis ensures each gets its fair share according to its dominant resource needs. We show that when various serverless workloads are intermixed, Anubis’s approach can reduce SLA violations by 15–34%, improving max-min fairness by 2× compared to competing scheduling policies.",Amit Samanta; Ryan Stutsman,"2024 IEEE 24th International Symposium on Cluster, Cloud and Internet Computing (CCGrid)",2024,,,106-112,IEEE,10.1109/ccgrid59990.2024.00021,https://doi.org/10.1109/ccgrid59990.2024.00021,proceedings-article,Semantic Scholar,high,"Latency, QoS, Resource Management","serverless, queuing, reinforcement learning, cpu allocation","That when various serverless workloads are intermixed, anubis’s approach can reduce sla violations by 15–34%, improving max-min fairness by 2× compared to competing scheduling policies; Sla violations by 15–34%, improving max-min fairness by 2× compared to competing scheduling policies","Not for applications where predictable response times are crucial; Serverless platforms have been extremely popular recently, certain kinds of applications are not well-supported by these platforms"
paper_046,Reinforcement Learning Applicability for Resource-Based Auto-scaling in Serverless Edge Applications,"Serverless computing is an alternative deployment paradigm for cloud computing platforms, aimed to provide scalability and cost reduction without requiring any additional deployment overhead from developers. Generally, open-source serverless computing platforms rely on two auto-scaling approaches: workload-based and resource-based. In the former, a designated algorithm scales instances according to the number of incoming requests. In the latter, instances are scaled when a certain resource usage limit, such as maximum Central Processing Unit (CPU) utilization, is reached. Resource-based auto-scaling is usually implemented leveraging Kubernetes Horizontal Pod Autoscaler (HPA). In this work, we investigate the applicability of a reinforcement-based approach to resource-based auto-scaling in OpenFaaS, the most widely used open-source serverless platform. Serverless technologies are particularly convenient when dealing with edge computing on constrained devices or resource-limited machines. Our experimental analysis has been conducted on constrained Kubernetes-based nodes, to simulate such an edge application scenario. Its preliminary results show that our proposed model learns an effective scaling policy, based on CPU utilization, to provide minimal service latency within a limited number of iterations.",Priscilla Benedetti; M. Femminella; G. Reali; Kris Steenhaut,2022 IEEE International Conference on Pervasive Computing and Communications Workshops and other Affiliated Events (PerCom Workshops),2022,,,674-679,IEEE,10.1109/percomworkshops53856.2022.9767437,https://doi.org/10.1109/percomworkshops53856.2022.9767437,proceedings-article,Semantic Scholar,high,"Survey, Latency, Cost, Resource Management","autoscaling, serverless, cloud computing, latency, reinforcement learning, cpu allocation","Serverless computing is an alternative deployment paradigm for cloud computing platforms, aimed to provide scalability and cost reduction without requiring any additional deployment overhead from developers",Not explicitly mentioned
paper_047,Serving Machine Learning Workloads in Resource Constrained Environments: a Serverless Deployment Example,"Deployed AI platforms typically ship with bulky system architectures which present bottlenecks and a high risk of failure. A serverless deployment can mitigate these factors and provide a cost-effective, automatically scalable (up or down) and elastic real-time on-demand AI solution. However, deploying high complexity production workloads into serverless environments is far from trivial, e.g., due to factors such as minimal allowance for physical codebase size, low amount of runtime memory, lack of GPU support and a maximum runtime before termination via timeout. In this paper we propose a set of optimization techniques and show how these transform a codebase which was previously incompatible with a serverless deployment into one that can be successfully deployed in a serverless environment; without compromising capability or performance. The techniques are illustrated via worked examples that have been deployed live on rail data and realtime predictions on train movements on the UK rail network. The similarities of a serverless environment to other resource constrained environments (IoT, Mobile) means the techniques can be applied to a range of use cases.",Angelos Christidis; Roy Davies; Sotiris Moschoyiannis,2019 IEEE 12th Conference on Service-Oriented Computing and Applications (SOCA),2019,,,55-63,IEEE,10.1109/soca.2019.00016,https://doi.org/10.1109/soca.2019.00016,proceedings-article,Semantic Scholar,high,"Cost, Resource Management","performance optimization, serverless, elasticity, reinforcement learning, prediction, memory management",A set of optimization techniques and show how these transform a codebase which was previously incompatible with a serverless deployment into one that can be successfully deployed in a serverless environment; without compromising capability or performance,"Deploying high complexity production workloads into serverless environments is far from trivial, e"
paper_048,λGrapher: A Resource-Efficient Serverless System for GNN Serving through Graph Sharing,"Graph Neural Networks (GNNs) have been increasingly adopted for graph analysis in web applications such as social networks. Yet, efficient GNN serving remains a critical challenge due to high workload fluctuations and intricate GNN operations. Serverless computing, thanks to its flexibility and agility, offers on-demand serving of GNN inference requests. Alas, the request-centric serverless model is still too coarse-grained to avoid resource waste. Observing the significant data locality in computation graphs of requests, we propose λGrapher, a serverless system for GNN serving that achieves resource efficiency through graph sharing and fine-grained resource allocation. ""Grapher features the following designs: (1) adaptive timeout for request buffering to balance resource efficiency and inference latency, (2) graph-centric scheduling to minimize computation and memory redundancy, and (3) resource-centric function management with fine-grained resource allocation catered to the resource sensitivities of GNN operations and function orchestration optimized to hide communication latency. We implement a prototype of λGrapher based on the representative open-source serverless platform Knative and evaluate it with real-world traces from various web applications. Our results show that λGrapher can achieve an average savings of 61.5% in memory resource and 47.2% in computing resource compared with the state of the arts while ensuring GNN inference latency.",Haichuan Hu; Fangming Liu; Qiangyu Pei; Yongjie Yuan; Zichen Xu; Lin Wang,Proceedings of the ACM Web Conference 2024,2024,,,2826-2835,ACM,10.1145/3589334.3645383,https://doi.org/10.1145/3589334.3645383,proceedings-article,Semantic Scholar,high,"Survey, Latency, Energy Consumption, Resource Management","resource management, serverless, latency, reinforcement learning, deep learning, memory management","Λgrapher, a serverless system for gnn serving that achieves resource efficiency through graph sharing and fine-grained resource allocation; A prototype of λgrapher based on the representative open-source serverless platform knative and evaluate it with real-world traces from various web applications",Due to high workload fluctuations and intricate gnn operations
paper_049,Dexter: A Performance-Cost Efficient Resource Allocation Manager for Serverless Data Analytics,"Leveraging serverless platforms for the efficient execution of distributed data analytics frameworks, such as Apache Spark [3], has gained substantial interest since early 2022. The elasticity, free-of-management, and on-demand scalability of serverless have motivated the effort in deploying distributed data analytics applications to serverless platforms. However, effectively auto-scaling resources for such complex workloads so that we can fully benefit from the resource elasticity of serverless remains challenging. Mis-configuration can result in severe performance and cost issues arising from resource under- and over-provisioning. In this paper, we present Dexter, a robust resource allocation manager dynamically allocating resources at a fine-grained level to guarantee performance-cost efficiency (optimizing total runtime cost). Dexter is novel in combining predictive and reactive strategies that fully leverage the elasticity of serverless to enhance the performance-cost efficiency for workflow executions. Unlike black-box ML models, Dexter quickly reaches a sufficiently good solution, prioritizing simplicity, generality, and ease of understanding. Our experimental evaluation shows that, compared with the default serverless Spark resource allocation that dynamically requests exponentially more executors to accommodate pending tasks, our solution achieves a cost reduction of up to 4.65×, while improving performance-cost efficiency up to 3.50×. Dexter also enables a substantial resource saving, demanding up to 5.75× fewer resources.",Anna Maria Nestorov; Diego Marrón; Alberto Gutierrez-Torre; Chen Wang; Claudia Misale; Alaa Youssef; David Carrera; Josep Lluís Berral,Proceedings of the 25th International Middleware Conference,2024,,,117-130,ACM,10.1145/3652892.3700753,https://doi.org/10.1145/3652892.3700753,proceedings-article,Semantic Scholar,high,"Survey, Cost, Energy Consumption, Resource Management","autoscaling, resource management, serverless, elasticity, reinforcement learning, prediction, distributed systems","Dexter, a robust resource allocation manager dynamically allocating resources at a fine-grained level to guarantee performance-cost efficiency (optimizing total runtime cost)",Effectively auto-scaling resources for such complex workloads so that we can fully benefit from the resource elasticity of serverless remains challenging; Arising from resource under- and over-provisioning
paper_050,Optimization of Serverless Mobile Cloud Applications for Enhanced Security and Resource Efficiency,"Serverless mobile cloud applications, while highly scalable and cost-efficient, face critical challenges in terms of security vulnerabilities and inefficient resource management. These challenges are amplified by the dynamic nature of mobile environments and the reliance on third-party infrastructure. This research specifically addresses the problem of securing data transmission, managing authentication and optimizing the allocation of computing resources in serverless mobile cloud architectures. To resolve these issues, the paper proposes a novel, integrated framework that leverages machine learning to predict application resource demands and proactively scale serverless functions. The approach includes the implementation of multi-factor authentication, role-based access control, and encryption protocols to enhance data confidentiality and system integrity. This research demonstrates significant improvements in application performance, reduced infrastructure costs, better cache management, and a notable reduction in latency and miss rates. The proposed model enhances serverless mobile cloud applications' reliability, scalability, and cost-effectiveness by combining adaptive security mechanisms with intelligent resource provisioning",Tapankumar A. Kakani,"International Journal of Advanced Research in Science, Communication and Technology",2025,,,620-630,Naksh Solutions,10.48175/ijarsct-24886,https://doi.org/10.48175/ijarsct-24886,journal-article,Semantic Scholar,high,"Latency, Reliability Security Privacy, Cost, Energy Consumption, Resource Management","resource management, performance optimization, serverless, cloud computing, latency, reinforcement learning","Model enhances serverless mobile cloud applications' reliability, scalability, and cost-effectiveness by combining adaptive security mechanisms with intelligent resource provisioning",In terms of security vulnerabilities and inefficient resource management; Are amplified by the dynamic nature of mobile environments and the reliance on third-party infrastructure
paper_051,Exploiting Wide-Area Resource Elasticity With Fine-Grained Orchestration for Serverless Analytics,"With the flourishing of global services, low-latency analytics on large-volume geo-distributed data has been a regular requirement for application decision-making. Serverless computing, with its rapid function start-up and lightweight deployment, provides a compelling way for geo-distributed analytics. However, existing research focuses on elastic resource scaling at the stage granularity, struggling to heterogeneous resource demands across component functions in wide-area settings. The neglect potentially results in the cost inefficiency and Service Level Objective (SLO) violations. In this paper, we advocate for fine-grained function orchestration to exploit wide-area resource elasticity. We thereby present Demeter, a fine-grained function orchestrator that saves job execution costs for geo-distributed serverless analytics while ensuring SLO compliance. By learning from volatile and bursty environments, Demeter jointly makes per-function placement and resource allocation decisions using a well-optimized multi-agent reinforcement learning algorithm with a pruning mechanism. It prevent the irreparable performance loss by function congestion control. Ultimately, we implement Demeter and evaluate it with the realistic workloads. Experimental results reveal that Demeter outperforms the baselines by up to 46.6% on cost, while reducing SLO violation by over 23.7% and bringing it to below 15%.",Xiaofei Yue; Song Yang; Liehuang Zhu; Stojan Trajanovski; Fan Li; Xiaoming Fu,IEEE Transactions on Networking,2025,33,1,398-413,Institute of Electrical and Electronics Engineers (IEEE),10.1109/tnet.2024.3486788,https://doi.org/10.1109/tnet.2024.3486788,journal-article,Semantic Scholar,high,"Latency, Cost, Energy Consumption, Resource Management","autoscaling, resource management, function placement, serverless, latency, elasticity, reinforcement learning, distributed systems",Demeter and evaluate it with the realistic workloads; 46,"Existing research focuses on elastic resource scaling at the stage granularity, struggling to heterogeneous resource demands across component functions in wide-area settings"
paper_052,Enhancing Resource Utilization Efficiency in Serverless Education: A Stateful Approach with Rofuse,"Traditional container orchestration platforms often suffer from resource wastage in educational settings, and stateless serverless services face challenges in maintaining container state persistence during the teaching process. To address these issues, we propose a stateful serverless mechanism based on Containerd and Kubernetes, focusing on optimizing the startup process for container groups. We first implement a checkpoint/restore framework for container states, providing fundamental support for managing stateful containers. Building on this foundation, we propose the concept of “container groups” to address the challenges in educational practice scenarios characterized by a large number of similar containers on the same node. We then propose the Rofuse optimization mechanism, which employs delayed loading and block-level deduplication techniques. This enables containers within the same group to reuse locally cached file system data at the block level, thus reducing container restart latency. Experimental results demonstrate that our stateful serverless mechanism can run smoothly in typical educational practice scenarios, and Rofuse reduces the container restart time by approximately 50% compared to existing solutions. This research provides valuable exploration for serverless practices in the education domain, contributing new perspectives and methods to improve resource utilization efficiency and flexibility in teaching environments.",Xinxi Lu; Nan Li; Lijuan Yuan; Juan Zhang,Electronics,2024,13,11,2168,MDPI AG,10.3390/electronics13112168,https://doi.org/10.3390/electronics13112168,journal-article,Semantic Scholar,high,"Latency, Energy Consumption, Resource Management","performance optimization, serverless, containerization, latency, reinforcement learning","A stateful serverless mechanism based on containerd and kubernetes, focusing on optimizing the startup process for container groups; The concept of “container groups” to address the challenges in educational practice scenarios characterized by a large number of similar containers on the same node",In maintaining container state persistence during the teaching process; In educational practice scenarios characterized by a large number of similar containers on the same node
paper_053,Sustainable Serverless Computing with Cold-start Optimization and Automatic Workflow Resource Scheduling,"In recent years, serverless computing has garnered significant attention owing to its high scalability, pay-as-you-go billing model, and efficient resource management provided by cloud service providers. Optimal resource scheduling of serverless computing has become imperative to reduce energy consumption and enable sustainable computing. However, existing serverless platforms encounter two significant challenges: the cold-start problem of containers and the absence of an effective resource allocation strategy for serverless workflows. Existing pre-warm strategies are associated with high computational overhead, while current resource scheduling techniques inadequately account for the intricate structure of serverless workflows. To address these challenges, we present SSC, a pre-warming and automatic resource allocation framework designed explicitly for serverless workflows. We introduce an innovative gradient-based algorithm for pre-warming containers, significantly reducing cold start hit rates. Moreover, leveraging a critical path and priority queue-based algorithm, SSC enables efficient allocation of resources for serverless workflows. In our experimental evaluation, SSC reduces the cold start hit rate by nearly 50% and achieves substantial cost savings of approximately 30%.",Shanxing Pan; Hongyu Zhao; Zinuo Cai; Dongmei Li; Ruhui Ma; Haibing Guan,IEEE Transactions on Sustainable Computing,2024,,,12-Jan,Institute of Electrical and Electronics Engineers (IEEE),10.1109/tsusc.2023.3311197,https://doi.org/10.1109/tsusc.2023.3311197,journal-article,Semantic Scholar,high,"Survey, Latency, Cost, Energy Consumption, Resource Management","cold start, resource management, performance optimization, serverless, containerization, cloud computing, queuing, energy efficiency, reinforcement learning","An innovative gradient-based algorithm for pre-warming containers, significantly reducing cold start hit rates; Ssc, a pre-warming and automatic resource allocation framework designed explicitly for serverless workflows",Existing serverless platforms encounter two significant challenges: the cold-start problem of containers and the absence of an effective resource allocation strategy for serverless workflows; Of containers and the absence of an effective resource allocation strategy for serverless workflows
paper_054,Optimizing Multitenancy: Adaptive Resource Allocation in Serverless Cloud Environments Using Reinforcement Learning,"Efficient CPU resource allocation is essential for optimizing performance and cost in cloud environments, where workloads are dynamic and multi-tenant applications demand real-time adaptability. Traditional allocation strategies rely on static heuristics or rule-based scheduling, which often fail to scale or generalize under rapidly changing conditions. This paper proposes an autonomous CPU resource allocation framework based on reinforcement learning (RL), which dynamically learns optimal allocation policies by interacting with the cloud environment. We present a model-free deep reinforcement learning (DRL) agent capable of adjusting CPU shares across virtual machines (VMs) and containers based on workload patterns, performance feedback, and system constraints. Experimental results on both simulated and real cloud workloads demonstrate that the proposed method significantly outperforms baseline strategies in terms of utilization efficiency, task latency, and SLA compliance. The framework introduces a scalable, adaptive, and fully automated solution for CPU resource management in cloud computing.",Mohammed Naif Alatawi,Electronics,2025,14,15,3004,MDPI AG,10.3390/electronics14153004,https://doi.org/10.3390/electronics14153004,journal-article,Semantic Scholar,high,"Latency, QoS, Cost, Energy Consumption, Resource Management","resource management, serverless, containerization, cloud computing, latency, multi-tenant, reinforcement learning, cpu allocation","A model-free deep reinforcement learning (drl) agent capable of adjusting cpu shares across virtual machines (vms) and containers based on workload patterns, performance feedback, and system constraints; An autonomous cpu resource allocation framework based on reinforcement learning (rl), which dynamically learns optimal allocation policies by interacting with the cloud environment; Method significantly outperforms baseline strategies in terms of utilization efficiency, task latency, and sla compliance",Not explicitly mentioned
paper_055,ARASEC: Adaptive Resource Allocation and Model Training for Serverless Edge–Cloud Computing,"Developing and deploying resource-aware artificial intelligence (AI) models presents a compelling optimization challenge in edge computing and serverless domains. Current research focuses mainly on scalable training and inference that uses serverless frameworks to optimize operational costs. However, these approaches often overlook the challenges of heterogeneous-aware training and overall cost optimization, including computing, memory, and communication. Our work introduces a framework for a heterogeneous edge environment, focusing on the model and key performance metrics like accuracy, floating-point operations per second, number of parameters, and latency. This framework enables distributed training within a serverless architecture. Further, it explores the construction of machine learning models from existing serverless functions using a lookup table while estimating AI model training in edge, cloud, or hybrid settings. We test the framework on object detection tasks in AI model development and deployment by using serverless operations.",Dewant Katare; Eduard Marin; Nicolas Kourtellis; Marijn Janssen; Aaron Yi Ding,IEEE Internet Computing,2024,28,6,17-27,Institute of Electrical and Electronics Engineers (IEEE),10.1109/mic.2024.3514670,https://doi.org/10.1109/mic.2024.3514670,journal-article,Semantic Scholar,high,"Latency, Cost, Resource Management","resource management, performance optimization, serverless, cloud computing, latency, reinforcement learning, memory management, distributed systems",Developing and deploying resource-aware artificial intelligence (ai) models presents a compelling optimization challenge in edge computing and serverless domains,"In edge computing and serverless domains; Of heterogeneous-aware training and overall cost optimization, including computing, memory, and communication"
paper_056,QoS-Aware and Cost-Efficient Dynamic Resource Allocation for Serverless ML Workflows,"Machine Learning (ML) workflows are increasingly deployed on serverless computing platforms to benefit from their elasticity and fine-grain pricing. Proper resource allocation is crucial to achieve fast and cost-efficient execution of serverless ML workflows (specially for hyperparameter tuning and model training). Unfortunately, existing resource allocation methods are static, treat functions equally, and rely on offline prediction, which limit their efficiency. In this paper, we introduce CE-scaling – a Cost-Efficient autoscaling framework for serverless ML work-flows. During the hyperparameter tuning, CE-scaling partitions resources across stages according to their exact usage to minimize resource waste. Moreover, it incorporates an online prediction method to dynamically adjust resources during model training. We implement and evaluate CE-scaling on AWS Lambda using various ML models. Evaluation results show that compared to state-of-the-art static resource allocation methods, CE-scaling can reduce the job completion time and the monetary cost by up to 63% and 41% for hyperparameter tuning, respectively; and by up to 58% and 38% for model training.",Hao Wu; Junxiao Deng; Hao Fan; Shadi Ibrahim; Song Wu; Hai Jin,2023 IEEE International Parallel and Distributed Processing Symposium (IPDPS),2023,,,886-896,IEEE,10.1109/ipdps54959.2023.00093,https://doi.org/10.1109/ipdps54959.2023.00093,proceedings-article,Semantic Scholar,high,"Survey, QoS, Cost, Energy Consumption, Resource Management","autoscaling, resource management, serverless, elasticity, reinforcement learning, prediction",Ce-scaling – a cost-efficient autoscaling framework for serverless ml work-flows; And evaluate ce-scaling on aws lambda using various ml models; 63% and,Not explicitly mentioned
paper_057,Application of Proximal Policy Optimization for Resource Orchestration in Serverless Edge Computing,"Serverless computing is a new cloud computing model suitable for providing services in both large cloud and edge clusters. In edge clusters, the autoscaling functions play a key role on serverless platforms as the dynamic scaling of function instances can lead to reduced latency and efficient resource usage, both typical requirements of edge-hosted services. However, a badly configured scaling function can introduce unexpected latency due to so-called ""cold start"" events or service request losses. In this work, we focus on the optimization of resource-based autoscaling on OpenFaaS, the most-adopted open-source Kubernetes-based serverless platform, leveraging real-world serverless traffic traces. We resort to the reinforcement learning algorithm named Proximal Policy Optimization to dynamically configure the value of the Kubernetes Horizontal Pod Autoscaler, trained on real traffic. This was accomplished via a state space model able to take into account resource consumption, performance values, and time of day. In addition, the reward function definition promotes Service-Level Agreement (SLA) compliance. We evaluate the proposed agent, comparing its performance in terms of average latency, CPU usage, memory usage, and loss percentage with respect to the baseline system. The experimental results show the benefits provided by the proposed agent, obtaining a service time within the SLA while limiting resource consumption and service loss.",Mauro Femminella; Gianluca Reali,Computers,2024,13,9,224,MDPI AG,10.3390/computers13090224,https://doi.org/10.3390/computers13090224,journal-article,Semantic Scholar,high,"Latency, QoS, Energy Consumption, Resource Management","cold start, autoscaling, performance optimization, serverless, cloud computing, latency, reinforcement learning, memory management, cpu allocation, distributed systems","Agent, comparing its performance in terms of average latency, cpu usage, memory usage, and loss percentage with respect to the baseline system; Agent, obtaining a service time within the sla while limiting resource consumption and service loss","A badly configured scaling function can introduce unexpected latency due to so-called ""cold start"" events or service request losses"
paper_058,Amoeba: QoS-Awareness and Reduced Resource Usage of Microservices with Serverless Computing,"While microservices that have stringent Quality-of-Service constraints are deployed in the Clouds, the long-term rented infrastructures that host the microservices are under-utilized except peak hours due to the diurnal load pattern. It is resource efficient for Cloud vendors and cost efficient for service maintainers to deploy the microservices in the long-term infrastructure at high load and in the serverless computing platform at low load. However, prior work fails to take advantage of the opportunity, because the contention between microservices on the serverless platform seriously affects their response latencies.Our investigation shows that the load of a microservice, the shared resource contentions on the serverless platform, and its sensitivities to the contention together affect the response latency of the microservice on the platform. To this end, we propose Amoeba, a runtime system that dynamically switches the deployment of a microservice. Amoeba is comprised of a contention-aware deployment controller, a hybrid execution engine, and a multi-resource contention monitor. The deployment controller predicts the tail latency of a microservice based on its load and the contention on the serverless platform, and determines the appropriate deployment of the microservice. The hybrid execution engine enables the quick switch of the two deploy modes. The contention monitor periodically quantifies the contention on multiple types of shared resources. Experimental results show that Amoeba is able to significantly reduce up to 72.9% of CPU usage and up to 84.9% of memory usage compared with the traditional pure IaaS-based deployment, while ensuring the required latency target.",Zijun Li; Quan Chen; Shuai Xue; Tao Ma; Yong Yang; Zhuo Song; Minyi Guo,2020 IEEE International Parallel and Distributed Processing Symposium (IPDPS),2020,,,,IEEE,10.1109/ipdps47924.2020.00049,https://doi.org/10.1109/ipdps47924.2020.00049,proceedings-article,Semantic Scholar,high,"Latency, QoS, Cost, Resource Management","serverless, microservices, cloud computing, latency, reinforcement learning, memory management, cpu allocation","Amoeba, a runtime system that dynamically switches the deployment of a microservice; 72; 84","Are deployed in the clouds, the long-term rented infrastructures that host the microservices are under-utilized except peak hours due to the diurnal load pattern; Prior work fails to take advantage of the opportunity, because the contention between microservices on the serverless platform seriously affects their response latencies"
paper_059,With Great Freedom Comes Great Opportunity: Rethinking Resource Allocation for Serverless Functions,"Current serverless offerings give users a limited degree of flexibility for
configuring the resources allocated to their function invocations by either
coupling memory and CPU resources together or providing no knobs at all. These
configuration choices simplify resource allocation decisions on behalf of
users, but at the same time, create deployments that are resource inefficient.
  In this paper, we take a principled approach to the problem of resource
allocation for serverless functions, allowing this choice to be made in an
automatic way that leads to the best combination of performance and cost. In
particular, we systematically explore the opportunities that come with
decoupling memory and CPU resource allocations and also enabling the use of
different VM types. We find a rich trade-off space between performance and
cost. The provider can use this in a number of ways: from exposing all these
parameters to the user, to eliciting preferences for performance and cost from
users, or by simply offering the same performance with lower cost. This
flexibility can also enable the provider to optimize its resource utilization
and enable a cost-effective service with predictable performance.
  Our results show that, by decoupling memory and CPU allocation, there is
potential to have up to 40% lower execution cost than the preset coupled
configurations that are the norm in current serverless offerings. Similarly,
making the correct choice of VM instance type can provide up to 50% better
execution time. Furthermore, we demonstrate that providers can utilize
different instance types for the same functions to maximize resource
utilization while providing performance within 10-20% of the best resource
configuration for each respective function.",Muhammad Bilal; Marco Canini; Rodrigo Fonseca; Rodrigo Rodrigues,Proceedings of the Eighteenth European Conference on Computer Systems,2023,,,381-397,ACM,10.1145/3552326.3567506,https://doi.org/10.1145/3552326.3567506,proceedings-article,arXiv,high,"Latency, Cost, Resource Management","resource management, serverless, reinforcement learning, memory management, cpu allocation",40% lower; 50% better,"At the same time, create deployments that are resource inefficient; Of resource
allocation for serverless functions, allowing this choice to be made in an
automatic way that leads to the best combination of performance and cost"
paper_060,It Takes Two to Tango: Serverless Workflow Serving via Bilaterally Engaged Resource Adaptation,"Serverless platforms typically adopt an early-binding approach for function
sizing, requiring developers to specify an immutable size for each function
within a workflow beforehand. Accounting for potential runtime variability,
developers must size functions for worst-case scenarios to ensure service-level
objectives (SLOs), resulting in significant resource inefficiency. To address
this issue, we propose Janus, a novel resource adaptation framework for
serverless platforms. Janus employs a late-binding approach, allowing function
sizes to be dynamically adapted based on runtime conditions. The main challenge
lies in the information barrier between the developer and the provider:
developers lack access to runtime information, while providers lack domain
knowledge about the workflow. To bridge this gap, Janus allows developers to
provide hints containing rules and options for resource adaptation. Providers
then follow these hints to dynamically adjust resource allocation at runtime
based on real-time function execution information, ensuring compliance with
SLOs. We implement Janus and conduct extensive experiments with real-world
serverless workflows. Our results demonstrate that Janus enhances resource
efficiency by up to 34.7% compared to the state-of-the-art.",Jing Wu; Lin Wang; Quanfeng Deng; Chen Yu; Dong Zhang; Bingheng Yan; Fangming Liu,2025 IEEE International Parallel and Distributed Processing Symposium (IPDPS),2025,,,28-41,IEEE,10.1109/ipdps64566.2025.00012,https://doi.org/10.1109/ipdps64566.2025.00012,proceedings-article,arXiv,high,"Energy Consumption, Resource Management","resource management, serverless, reinforcement learning","Janus, a novel resource adaptation framework for
serverless platforms; Janus and conduct extensive experiments with real-world
serverless workflows; 34","Lies in the information barrier between the developer and the provider:
developers lack access to runtime information, while providers lack domain
knowledge about the workflow"
paper_061,FasDL: An Efficient Serverless-Based Training Architecture With Communication Optimization and Resource Configuration,"Deploying distributed training workloads of deep learning models atop serverless architecture alleviates the burden of managing servers from deep learning practitioners. However, when supporting deep model training, the current serverless architecture faces the challenges of inefficient communication patterns and rigid resource configuration that incur subpar and unpredictable training performance. In this paper, we propose FasDL, an efficient serverless-based deep learning training architecture to solve these two challenges. FasDL adopts a novel training framework K-REDUCE to release the communication overhead and accelerate the training. Additionally, FasDL builds a lightweight mathematical model for K-REDUCE training, offering predictable performance and supporting subsequent resource configuration. It achieves the optimal resource configuration by formulating an optimization problem related to system-level and application-level parameters and solving it with a pruning-based heuristic search algorithm. Extensive experiments on AWS Lambda verify a prediction accuracy over 94% and demonstrate performance and cost advantages over the state-of-art architecture LambdaML by up to 16.8% and 28.3% respectively.",Xinglei Chen; Zinuo Cai; Hanwen Zhang; Ruhui Ma; Rajkumar Buyya,IEEE Transactions on Computers,2025,74,2,468-482,Institute of Electrical and Electronics Engineers (IEEE),10.1109/tc.2024.3485202,https://doi.org/10.1109/tc.2024.3485202,journal-article,Semantic Scholar,high,"Cost, Resource Management","performance optimization, serverless, reinforcement learning, deep learning, prediction, distributed systems","Fasdl, an efficient serverless-based deep learning training architecture to solve these two challenges; 16","Of inefficient communication patterns and rigid resource configuration that incur subpar and unpredictable training performance; When supporting deep model training, the current serverless architecture faces the challenges of inefficient communication patterns and rigid resource configuration that incur subpar and unpredictable training performance"
paper_062,A Case of Multi-Resource Fairness for Serverless Workflows (Work In Progress Paper),"Serverless platforms have exploded in popularity in recent years, but, today, these platforms are still unsuitable for large classes of applications. They perform well for batch-oriented workloads that perform coarse transformations over data asynchronously, but their lack of clear service level agreements (SLAs), high per-invocation overheads, and interference make deploying online applications with stringent response time demands impractical. Our assertion is that beyond the glaring issues like cold start costs, a more fundamental shift is needed in how serverless function invocations are provisioned and scheduled in order to support these more demanding applications. Specifically, we propose a platform that leverages the observability and predictability of serverless functions to enforce multi-resource fairness. We explain why we believe interference across a spectrum of resources (CPU, network, and storage) contributes to lower resource utilization and poor response times for latency-sensitive and high-fanout serverless application patterns. Finally, we propose a new distributed and hierarchical function scheduling architecture that combines lessons from multi-resource fair scheduling, hierarchical scheduling, batch-analytics resource scheduling, and statistics to create an approach that we believe will enable tighter SLAs on serverless platforms than has been possible in the past.",Amit Samanta; Ryan Stutsman,Companion of the 2023 ACM/SPEC International Conference on Performance Engineering,2023,,,45-50,ACM,10.1145/3578245.3585033,https://doi.org/10.1145/3578245.3585033,proceedings-article,Semantic Scholar,high,"Latency, QoS, Cost, Resource Management","cold start, serverless, latency, reinforcement learning, monitoring, cpu allocation, distributed systems","A platform that leverages the observability and predictability of serverless functions to enforce multi-resource fairness; A new distributed and hierarchical function scheduling architecture that combines lessons from multi-resource fair scheduling, hierarchical scheduling, batch-analytics resource scheduling, and statistics to create an approach that we believe will enable tighter slas on serverless platforms than has been possible in the past","Their lack of clear service level agreements (slas), high per-invocation overheads, and interference make deploying online applications with stringent response time demands impractical; Like cold start costs, a more fundamental shift is needed in how serverless function invocations are provisioned and scheduled in order to support these more demanding applications"
paper_063,Resource Allocation and Pricing in Energy Harvesting Serverless Computing Internet of Things Networks,"This paper considers a resource allocation problem involving servers and mobile users (MUs) operating in a serverless edge computing (SEC)-enabled Internet of Things (IoT) network. Each MU has a fixed budget, and each server is powered by the grid and has energy harvesting (EH) capability. Our objective is to maximize the revenue of the operator that operates the said servers and the number of resources purchased by the MUs. We propose a Stackelberg game approach, where servers and MUs act as leaders and followers, respectively. We prove the existence of a Stackelberg game equilibrium and develop an iterative algorithm to determine the final game equilibrium price. Simulation results show that the proposed scheme is efficient in terms of the SEC’s profit and MU’s demand. Moreover, both MUs and SECs gain benefits from renewable energy.",Yunqi Li; Changlin Yang,Information,2024,15,5,250,MDPI AG,10.3390/info15050250,https://doi.org/10.3390/info15050250,journal-article,CrossRef,high,"Cost, Energy Consumption, Resource Management","resource management, serverless, energy efficiency, reinforcement learning","A stackelberg game approach, where servers and mus act as leaders and followers, respectively; Scheme is efficient in terms of the sec’s profit and mu’s demand",Involving servers and mobile users (mus) operating in a serverless edge computing (sec)-enabled internet of things (iot) network
paper_064,AI-based Resource Allocation: Reinforcement Learning for Adaptive Auto-scaling in Serverless Environments,"Serverless computing has emerged as a compelling new paradigm of cloud computing models in recent years. It promises the user services at large scale and low cost while eliminating the need for infrastructure management. On cloud provider side, flexible resource management is required to meet fluctuating demand. It can be enabled through automated provisioning and deprovisioning of resources. A common approach among both commercial and open source serverless computing platforms is workload-based auto-scaling, where a designated algorithm scales instances according to the number of incoming requests. In the recently evolving serverless framework Knative a request-based policy is proposed, where the algorithm scales resources by a configured maximum number of requests that can be processed in parallel per instance, the so-called concurrency. As we show in a baseline experiment, this predefined concurrency level can strongly influence the performance of a serverless application. However, identifying the concurrency configuration that yields the highest possible quality of service is a challenging task due to various factors, e.g. varying workload and complex infrastructure characteristics, influencing throughput and latency. While there has been considerable research into intelligent techniques for optimizing auto-scaling for virtual machine provisioning, this topic has not yet been discussed in the area of serverless computing. For this reason, we investigate the applicability of a reinforcement learning approach to request-based auto-scaling in a serverless framework. Our results show that within a limited number of iterations our proposed model learns an effective scaling policy per workload, improving the performance compared to the default auto-scaling configuration.",Lucia Schuler; Somaya Jamil; Niklas Kuhl,"2021 IEEE/ACM 21st International Symposium on Cluster, Cloud and Internet Computing (CCGrid)",2021,,,,IEEE,10.1109/ccgrid51090.2021.00098,https://doi.org/10.1109/ccgrid51090.2021.00098,proceedings-article,Semantic Scholar,high,"Latency, QoS, Cost, Resource Management","autoscaling, resource management, serverless, cloud computing, latency, throughput, reinforcement learning","In a baseline experiment, this predefined concurrency level can strongly influence the performance of a serverless application","Identifying the concurrency configuration that yields the highest possible quality of service is a challenging task due to various factors, e; Infrastructure characteristics, influencing throughput and latency"
paper_065,ComboFunc: Joint Resource Combination and Container Placement for Serverless Function Scaling With Heterogeneous Container,"Serverless computing provides developers with a maintenance-free approach to resource usage, but it also transfers resource management responsibility to the cloud platform. However, the fine granularity of serverless function resources can lead to performance bottlenecks and resource fragmentation on nodes when creating many function containers. This poses challenges in effectively scaling function resources and optimizing node resource allocation, hindering overall agility. To address these challenges, we have introduced ComboFunc, an innovative resource scaling system for serverless platforms. ComboFunc associates function with heterogeneous containers of varying specifications and optimizes their resource combination and placement. This approach not only selects appropriate nodes for container creation, but also leverages the new feature of Kubernetes In-place Pod Vertical Scaling to enhance resource scaling agility and efficiency. By allowing a single function to correspond to heterogeneous containers with varying resource specifications and providing the ability to modify the resource specifications of existing containers in place, ComboFunc effectively utilizes fragmented resources on nodes. This, in turn, enhances the overall resource utilization of the entire cluster and improves scaling agility. We also model the problem of combining and placing heterogeneous containers as an NP-hard problem and design a heuristic solution based on a greedy algorithm that solves it in polynomial time. We implemented a prototype of ComboFunc on the Kubernetes platform and conducted experiments using real traces on a local cluster. The results demonstrate that, compared to existing strategies, ComboFunc achieves up to 3.01 × faster function resource scaling and reduces resource costs by up to 42.6%.",Zhaojie Wen; Qiong Chen; Quanfeng Deng; Yipei Niu; Zhen Song; Fangming Liu,IEEE Transactions on Parallel and Distributed Systems,2024,35,11,1989-2005,Institute of Electrical and Electronics Engineers (IEEE),10.1109/tpds.2024.3454071,https://doi.org/10.1109/tpds.2024.3454071,journal-article,Semantic Scholar,high,"Cost, Energy Consumption, Resource Management","autoscaling, resource management, function placement, serverless, containerization, cloud computing, reinforcement learning, distributed systems",42,"In effectively scaling function resources and optimizing node resource allocation, hindering overall agility; The fine granularity of serverless function resources can lead to performance bottlenecks and resource fragmentation on nodes when creating many function containers"
paper_066,BeeFlow: Behavior tree-based Serverless workflow modeling and scheduling for resource-constrained edge clusters,"Serverless computing has gained popularity in edge computing due to its
flexible features, including the pay-per-use pricing model, auto-scaling
capabilities, and multi-tenancy support. Complex Serverless-based applications
typically rely on Serverless workflows (also known as Serverless function
orchestration) to express task execution logic, and numerous application- and
system-level optimization techniques have been developed for Serverless
workflow scheduling. However, there has been limited exploration of optimizing
Serverless workflow scheduling in edge computing systems, particularly in
high-density, resource-constrained environments such as system-on-chip clusters
and single-board-computer clusters. In this work, we discover that existing
Serverless workflow scheduling techniques typically assume models with limited
expressiveness and cause significant resource contention. To address these
issues, we propose modeling Serverless workflows using behavior trees, a novel
and fundamentally different approach from existing directed-acyclic-graph- and
state machine-based models. Behavior tree-based modeling allows for easy
analysis without compromising workflow expressiveness. We further present
observations derived from the inherent tree structure of behavior trees for
contention-free function collections and awareness of exact and empirical
concurrent function invocations. Based on these observations, we introduce
BeeFlow, a behavior tree-based Serverless workflow system tailored for
resource-constrained edge clusters. Experimental results demonstrate that
BeeFlow achieves up to 3.2X speedup in a high-density, resource-constrained
edge testbed and 2.5X speedup in a high-profile cloud testbed, compared with
the state-of-the-art.",Ke Luo; Tao Ouyang; Zhi Zhou; Xu Chen,Journal of Systems Architecture,2023,143,,102968,Elsevier BV,10.1016/j.sysarc.2023.102968,https://doi.org/10.1016/j.sysarc.2023.102968,journal-article,arXiv,high,"Survey, Cost, Resource Management","autoscaling, performance optimization, serverless, cloud computing, reinforcement learning, distributed systems","Modeling serverless workflows using behavior trees, a novel
and fundamentally different approach from existing directed-acyclic-graph- and
state machine-based models","There has been limited exploration of optimizing
serverless workflow scheduling in edge computing systems, particularly in
high-density, resource-constrained environments such as system-on-chip clusters
and single-board-computer clusters; Serverless-based applications
typically rely on serverless workflows (also known as serverless function
orchestration) to express task execution logic, and numerous application- and
system-level optimization techniques have been developed for serverless
workflow scheduling"
paper_067,Darly: Deep Reinforcement Learning for QoS-aware scheduling under resource heterogeneity Optimizing serverless video analytics,"Today, video analytics are becoming extremely popular due to the increasing need for extracting valuable information from videos available in public sharing services through camera-driven streams. Typically, video analytics are organized as a set of separate tasks, each of which has different resource requirements (e.g., computational- vs. memory-intensive tasks). The serverless computing paradigm forms a very promising approach for mapping such types of applications, as it enables fine-grained deployment and management in a per-function manner. However, modern serverless frameworks suffer from performance variability issues, due to i) the interference introduced due to co-location of third-party workloads with the serverless funcations and ii) the increasing hardware heterogeneity introduced in public clouds. To this end, this work introduces Darly, a QoS- and heterogeneity-aware Deep Reinforcement Learning-based Scheduler for serverless video analytics deployments. The proposed framework incorporates a DRL agent which exploits low-level performance counters to identify the levels of interference and the degree of heterogeneity in the underlying infrastructure and combines this information along with user-defined QoS requirements to dynamically optimize resource allocations by deciding the placement, migration, or horizontal scaling of serverless functions. Promising results are produced withing our experiments, which are accompanied with the intent to further build upon this groundwork.",Dimitrios Giagkos; Achilleas Tzenetopoulos; Dimosthenis Masouros; Dimitrios Soudris; Sotirios Xydis,2023 IEEE 16th International Conference on Cloud Computing (CLOUD),2023,,,3-Jan,IEEE,10.1109/cloud60044.2023.00079,https://doi.org/10.1109/cloud60044.2023.00079,proceedings-article,Semantic Scholar,high,"QoS, Resource Management","autoscaling, resource management, function placement, serverless, cloud computing, reinforcement learning, memory management","Framework incorporates a drl agent which exploits low-level performance counters to identify the levels of interference and the degree of heterogeneity in the underlying infrastructure and combines this information along with user-defined qos requirements to dynamically optimize resource allocations by deciding the placement, migration, or horizontal scaling of serverless functions","Modern serverless frameworks suffer from performance variability issues, due to i) the interference introduced due to co-location of third-party workloads with the serverless funcations and ii) the increasing hardware heterogeneity introduced in public clouds"
paper_068,Autonomous scheduling mechanism based on energy awareness for improving resource allocation in serverless IoT edge,"The energy-aware scheduling mechanism in serverless computing enables systems to be allocated to IoT devices connected to the network’s edge efficiently based on the energy status of active nodes. In this approach, resource allocation is performed in real-time and according to the energy changes of the nodes, the complexity of which arises from the direct dependence of the energy level on the capacity to respond to requests. This choice is complex since allocating the necessary resources to process requests depends on the energy available in the active nodes. Therefore, to optimize resource allocation and increase access time, selecting and executing pre-schedulers is necessary based on the prediction of the energy level of the active nodes. In this article, we introduce a scheduler selection mechanism called an autonomous energy-aware scheduler, whose design is based on the energy position of the active nodes in the network. In addition, a mechanism for improving system uptime is proposed to increase the duration of the energy reduction of active nodes. The efficiency of the proposed approach was evaluated utilizing three separate load distribution patterns (exponential, Poisson, and exponential-Poisson), and the results indicate the prevention of energy waste and an average reduction of 1.66% in energy consumption. Also, the network uptime is improved by 8.6% compared to other methods. In addition, the proposed method has maintained performance continuity while ensuring failure resistance in all situations. The results demonstrate the high efficiency of the proposed approach in optimizing energy consumption and enhancing the resilience and stability of serverless systems.",Mohsen Ghorbian; Mostafa Ghobaei-Arani; Leila Esmaeili,Scientific Reports,2025,15,1,,Springer Science and Business Media LLC,10.1038/s41598-025-04214-x,https://doi.org/10.1038/s41598-025-04214-x,journal-article,Semantic Scholar,high,"Energy Consumption, Resource Management","resource management, serverless, load balancing, energy efficiency, reinforcement learning, prediction","A scheduler selection mechanism called an autonomous energy-aware scheduler, whose design is based on the energy position of the active nodes in the network; Approach was evaluated utilizing three separate load distribution patterns (exponential, poisson, and exponential-poisson), and the results indicate the prevention of energy waste and an average reduction of 1; Method has maintained performance continuity while ensuring failure resistance in all situations",Since allocating the necessary resources to process requests depends on the energy available in the active nodes
paper_069,A Joint Resource Allocation and Request Dispatch Scheme for Performing Serverless Computing over Edge and Cloud,"Serverless computing functions typically execute in the cloud. However, the high latency of accessing the cloud may require running them on edge servers, which have limited computing power and memory availability. This paper proposes a joint resource allocation and request dispatch scheme to execute serverless computing functions over edge and cloud collaboratively. This new scheme explicitly considers how to allocate server memory and operation budget for concurrent serverless computing requests considering the cold-start latency in design. The proposed scheme has been evaluated through extensive simulations. Its effectiveness has been proved by comparison with the upper-bound results.",Meenakshi Sethunath; Yang Peng,2021 IEEE 7th World Forum on Internet of Things (WF-IoT),2021,,,575-580,IEEE,10.1109/wf-iot51360.2021.9595769,https://doi.org/10.1109/wf-iot51360.2021.9595769,proceedings-article,Semantic Scholar,high,"Survey, Latency, Reliability Security Privacy, Cost, Energy Consumption, Resource Management","cold start, resource management, serverless, cloud computing, latency, reinforcement learning, memory management",A joint resource allocation and request dispatch scheme to execute serverless computing functions over edge and cloud collaboratively; Scheme has been evaluated through extensive simulations,"The high latency of accessing the cloud may require running them on edge servers, which have limited computing power and memory availability"
paper_070,Serverless computing: a security perspective,"In this article we review the current serverless architectures, abstract and categorize their founding principles, and provide an in-depth security analysis. In particular, we: show the security shortcomings of the analyzed serverless architectural paradigms; point to possible countermeasures; and, highlight several research directions for practitioners, Industry, and Academia.",Eduard Marin; Diego Perino; Roberto Di Pietro,Journal of Cloud Computing,2022,11,1,,Springer Science and Business Media LLC,10.1186/s13677-022-00347-w,https://doi.org/10.1186/s13677-022-00347-w,journal-article,Semantic Scholar,high,"Survey, Reliability Security Privacy","serverless, reinforcement learning","In particular, we: show the security shortcomings of the analyzed serverless architectural paradigms; point to possible countermeasures; and, highlight several research directions for practitioners, industry, and academia",Not explicitly mentioned
paper_071,Security Issues in Serverless Computing Architecture,"Serverless computing allows a company to run its backend services on an as-used basis. Precisely, could providers are offering business the chance to pay for cloud computing based on their computation needs without the need to reserve a certain number of servers or secure a fixed amount of bandwidth. While offering flexibility through paying for computing power rather than fixed server space and bandwidth, serverless computing presents unique security challenges and issues not characteristic of classic cloud computing. The purpose of this paper is to bring to light these security issues and challenges in addition to developing a proposed framework to solve it.",Sanaa Sharaf,International Journal of Emerging Trends in Engineering Research,2020,8,2,539-544,The World Academy of Research in Science and Engineering,10.30534/ijeter/2020/43822020,https://doi.org/10.30534/ijeter/2020/43822020,journal-article,Semantic Scholar,high,"Reliability Security Privacy, Energy Consumption","serverless, cloud computing, reinforcement learning","While offering flexibility through paying for computing power rather than fixed server space and bandwidth, serverless computing presents unique security challenges and issues not characteristic of classic cloud computing",And issues not characteristic of classic cloud computing; In addition to developing a proposed framework to solve it
paper_072,Serverless Computing Security: Protecting Application Logic,"Serverless computing enables organisations to avail of the inherent and unlimited flexibility and scalability that serverless provides, without having to consider the underlying infrastructure. However, there are security considerations that are unique to serverless architectures, that if not included early in application design, can lead to vulnerabilities which could be exposed to common attack vectors. While cloud service providers manage the security of the underlying infrastructure, it is up to the consumer to ensure that serverless applications are fully protected. We go on to discuss common attack vectors, the risks associated with misconfiguration within security and application setup, how attackers target vulnerabilities within the workflow logic of serverless applications and their functions to focus their attacks, and how consumers can implement measures to protect their applications within a serverless architecture.",Wesley O'Meara; Ruth G. Lennon,2020 31st Irish Signals and Systems Conference (ISSC),2020,,,,IEEE,10.1109/issc49989.2020.9180214,https://doi.org/10.1109/issc49989.2020.9180214,proceedings-article,Semantic Scholar,high,Reliability Security Privacy,"serverless, cloud computing, reinforcement learning",Novel approach to serverless computing challenges,"There are security considerations that are unique to serverless architectures, that if not included early in application design, can lead to vulnerabilities which could be exposed to common attack vectors"
paper_073,Serverless Service Architectures and Security Minimals,"The Serverless subject is an emerging new world within technology scope. Although it seems to be by name a specific and a circumscriptive topic, it is a vast and complex subject that has an ongoing study and not a standardized use to be promoted as a technology standard. There are a variety of complex offers, platforms, products, applications, and ways to use, but, like other emerging and essential technologies, it has not yet been broadly accepted as architecture, and for cybersecurity, it’s complex to configure. This doesn't mean it is not usable or defective; it is only an anticipated conclusion and analysis of the factual and present panorama. This research has the objective of demonstrating the pontification of the use of Serverless architectures and the base security measures and risks to consider. This research reviewed prominent research articles from IEEE Journals and interviews with developers that are in contact with this technology, clarifying the central aspect of Serverless, its overall architecture as secure technology-usable-results cross platforms. This research aimed at the principal types of usage, security aspects within the mobile, its applications and networks parts and within the Cloud, the applications, filesystems, and possible other main uses. The study scope of these systems is circumscribed to the technology, tendencies, best and worst of its model, and lastly, its usage.",Nuno Mateus-Coelho; Manuela Cruz-Cunha,2022 10th International Symposium on Digital Forensics and Security (ISDFS),2022,,,6-Jan,IEEE,10.1109/isdfs55398.2022.9800779,https://doi.org/10.1109/isdfs55398.2022.9800779,proceedings-article,Semantic Scholar,high,"Survey, Reliability Security Privacy","serverless, cloud computing, reinforcement learning",Novel approach to serverless computing challenges,"It seems to be by name a specific and a circumscriptive topic, it is a vast and complex subject that has an ongoing study and not a standardized use to be promoted as a technology standard; Subject that has an ongoing study and not a standardized use to be promoted as a technology standard"
paper_074,Security Issues in Serverless Cloud Computing Architectures,"Serverless Computing has gained popularity lately as they are simple to manage, lightweight and does scaling by itself. It gives developers a relaxation of not maintaining the server as the server is managed by the cloud service provider itself. This paper provides literature survey on serverless computing, further illustrating areas of serverless computing and its security issues, threat model and possible attacks on serverless computing and framework, technique used till now for providing security to both consumer and cloud service provider in serverless computing. Next section of this proposed work consists of architecture of serverless computing with conclusive statements.",Ankit Bhatt; Sachin Sharma; Shuchi Bhadula,"2024 IEEE International Conference on Computing, Power and Communication Technologies (IC2PCT)",2024,,,39-43,IEEE,10.1109/ic2pct60090.2024.10486369,https://doi.org/10.1109/ic2pct60090.2024.10486369,proceedings-article,Semantic Scholar,high,"Survey, Reliability Security Privacy, Resource Management","autoscaling, serverless, cloud computing, reinforcement learning",It gives developers a relaxation of not maintaining the server as the server is managed by the cloud service provider itself,Not explicitly mentioned
paper_075,EXPLORING SERVERLESS SECURITY: IDENTIFYING SECURITY RISKS AND IMPLEMENTING BEST PRACTICES,"FaaS or Serverless computing extends the
existing cloud computing by removing or
abstracting the notion of a server and the need to
scale up and down on demand. This paper seeks
to discuss the security issues that are associated
with serverless architecture, with special focus on
authentication, data encryption, compliance
issues and those risks that are unique to different
vendors. It compares existing security
architectures and measures and current industry
benchmarks originating from premier cloud
platforms such as AWS Lambda, Azure
Functions, Google Cloud Functions. Some of the
critical risks including injection attacks, insecure
deployments, and operational monitoring have
similar threat proneness models accompanied by
secure coding, IAM integration, DevOps rules,
and recommendations.
Keywords - DevOps, IAM, Serverless
Architectures, injection attacks, monitoring,
FaaS.",Ramasankar Molleti; Anirudh Khanna,INTERANTIONAL JOURNAL OF SCIENTIFIC RESEARCH IN ENGINEERING AND MANAGEMENT,2025,9,1,7-Jan,Indospace Publications,10.55041/ijsrem6995,https://doi.org/10.55041/ijsrem6995,journal-article,Semantic Scholar,high,"Survey, Reliability Security Privacy","serverless, cloud computing, reinforcement learning, monitoring",Novel approach to serverless computing challenges,"That are associated
with serverless architecture, with special focus on
authentication, data encryption, compliance
issues and those risks that are unique to different
vendors"
paper_076,Improved Encryption Towards Data Security in Serverless Computing,"Serverless computing is growing rapidly due to its rapid adoption by the cloud providers and tenants in terms of its scalability, elasticity, flexibility and ease of deployment. Such increase in deployment of serverless computing makes the research to rethink on its security aspects.
 Since, the serverless security computing may undergo problems due to malicious users or hackers. In this paper, a secure and an efficient access control system is designed for serverless security computing for both knowledge and resource sharing using attributed based encryption. Initially,
 the data is encrypted using user attributes; further the data is split into cipher text. It is finally decrypted using a decryption algorithm and then the shares of the cipher text are distributed in the network and the encapsulated texts are stored in the serverless system. The performance
 on security analysis shows that the proposed method achieves improved data security in serverless environment than the existing methods.",A. Arulprakash; K. SampathKumar,Journal of Computational and Theoretical Nanoscience,2020,17,12,5256-5260,American Scientific Publishers,10.1166/jctn.2020.9417,https://doi.org/10.1166/jctn.2020.9417,journal-article,Semantic Scholar,high,"Survey, Reliability Security Privacy, Resource Management","serverless, cloud computing, elasticity, reinforcement learning, distributed systems",Method achieves improved data security in serverless environment than the existing methods,Due to malicious users or hackers
paper_077,Security Enhancement in Multi Clouds Using Serverless Computing Approach,"Nowadays, in any application specific domain security plays a vital role in the service access environment. Because customers needs to make use of distinct services and resources in an attacks free surface. In cloud computing environment, the security services and portal systems have been highly progressed based on the user requirements. However, cloud offers plenty of resources through the service vendor globally; still the multi clouds problems are not resolved completely. So, it is very essential to protect the data and other resources from the intruders are a most primary factor. The proposed work will establish a security layer on the multiple cloud environments by introducing the concept of “Serverless Computing”. The serverless computing is a kind of cloud computing execution model through which the cloud service provider (CSP) can manage the allocation of system resources in a dynamic manner. This mechanism will follow the property of utility computing. This approach can be used to hide the operations on entire cloud server management end and capacity planning decisions and also uses no provisioned services. Any type of vulnerabilities is taken care of by the cloud service provider. In this process, attacks rate are compared with the traditional security architectures and each component is an entry point to the serverless application. With this approach, customers can control and monitor the workloads by using IDS / IPS technique.",R. Poorvadevi,Internet of Things and Cloud Computing,2018,6,1,12,Science Publishing Group,10.11648/j.iotcc.20180601.12,https://doi.org/10.11648/j.iotcc.20180601.12,journal-article,Semantic Scholar,high,"Reliability Security Privacy, Resource Management","serverless, cloud computing, reinforcement learning",Work will establish a security layer on the multiple cloud environments by introducing the concept of “serverless computing”,Cloud offers plenty of resources through the service vendor globally; still the multi clouds problems are not resolved completely; Are not resolved completely
paper_078,Challenges and Solutions in Network Security for Serverless Computing,"This research study explores the challenges and solutions related to serverless computing so that the computer systems connected to the network can be protected. Serverless computing can be defined as a method of managing computer services without the need to have fixed servers. The qualitative research method is used by this research study, which does not include any numerical data and involves the examination of non-number data so that the network security challenges can be identified in detail. In the literature review, the past studies from 2019 to 2023 are reviewed to identify study gaps so that the foundation for investigating serverless network security. The literature review is based on thematic analysis, so all the data can be organized into meaningful themes. The findings of this research study include the solutions to the challenges like data privacy, insecure dependencies and limited control. The strategies to overcome these challenges include encryption, strong monitoring and other relevant strategies. This research study also suggests the use of blockchain technology and Artificial Intelligence. In short, this research study provides insights to improve serverless computing security and also guides future researchers to innovate creative solutions for developing security challenges.",Sina Ahmadi,International Journal of Current Science Research and Review,2024,7,1,,Everant Journals,10.47191/ijcsrr/v7-i1-23,https://doi.org/10.47191/ijcsrr/v7-i1-23,journal-article,Semantic Scholar,high,"Survey, Reliability Security Privacy","serverless, reinforcement learning, monitoring",Novel approach to serverless computing challenges,And solutions related to serverless computing so that the computer systems connected to the network can be protected; Can be identified in detail
paper_079,Function Scheduling with Data Security in Serverless Computing Systems,"In serverless computing, the service provider takes full responsibility for function management. However, serverless computing has many challenges regarding data security and function scheduling. To address these challenges, we have proposed a system to secure the data of an end-user. We also aim to meet the quality of service (QoS) for the end-user requests. This work presents a Simulated Annealing-based optimization algorithm for function placement. Also, we have Hyperledger Fabric, a blockchain framework in the system architecture for securing the data of an end-user. We have conducted experiments in Amazon Elastic Compute Cloud (EC2) taking virtual machine instances. The experiments in Amazon EC2 indicate that the proposed system secures the data and enhances the end-user’s QoS.",Srestha Saha; Arvind Pandey; Sourav Kanti Addya; Shubha Brata Nath,2025 17th International Conference on COMmunication Systems and NETworks (COMSNETS),2025,,,921-925,IEEE,10.1109/comsnets63942.2025.10885582,https://doi.org/10.1109/comsnets63942.2025.10885582,proceedings-article,Semantic Scholar,high,"Reliability Security Privacy, QoS, Resource Management","function placement, performance optimization, serverless, cloud computing, elasticity, reinforcement learning",System secures the data and enhances the end-user’s qos,Regarding data security and function scheduling; Serverless computing has many challenges regarding data security and function scheduling
paper_080,Serverless Security: Best Practices for Protecting Functions-as-a-Service,": This paper explores the unique security challenges and best practices associated with serverless computing, particularly Functions-as-a-Service (FaaS) architectures. It examines the ephemeral nature of serverless functions, the shared responsibility model, and the expanded attack surface that characterize these environments. The study delves into common security threats specific to serverless applications, including function event data injection, insecure deployment configurations, broken authentication and authorization, and sensitive data exposure. A comprehensive set of best practices for securing serverless functions is presented, focusing on implementing least privilege access, secure coding practices, data encryption, effective monitoring and logging strategies, and regular security audits. The paper also discusses future trends in serverless security, emphasizing the need for automated tools, advanced isolation techniques, and industry-wide security standards. Through case studies and expert insights, this research provides actionable recommendations for organizations adopting serverless architectures, aiming to balance the benefits of serverless computing with robust security measures.",Yamini Kannan,International Journal of Science and Research (IJSR),2024,13,7,1190-1194,International Journal of Science and Research,10.21275/sr24723103837,https://doi.org/10.21275/sr24723103837,journal-article,Semantic Scholar,high,Reliability Security Privacy,"serverless, reinforcement learning, monitoring",Novel approach to serverless computing challenges,"And best practices associated with serverless computing, particularly functions-as-a-service (faas) architectures"
paper_081,Enhancing Advanced Model Architecture in Serverless Architecture to Improve Security,"Serverless architecture presents unique security challenges, requiring the adoption of advanced model architecture to improve security. This research paper examines the security concerns related to serverless architecture and explores the advancements made in the advanced model architecture to enhance security. The paper discusses the challenges posed by serverless architecture, including data protection, access control, insecure configurations, and vulnerability to attacks. The key areas of focus in enhancing the serverless architecture model are secure deployment, zero-trust security model, runtime security, and identity and access management. The paper recommends implementing secure deployment practices, enforcing a zero-trust security model, ensuring runtime security, and managing identity and access to improve security in serverless architecture. The paper presents a comprehensive literature review of the existing research on serverless architecture and security concerns.",Surya A; R. Nathiya,2025 8th International Conference on Trends in Electronics and Informatics (ICOEI),2025,,,653-659,IEEE,10.1109/icoei65986.2025.11013761,https://doi.org/10.1109/icoei65986.2025.11013761,proceedings-article,Semantic Scholar,high,"Survey, Reliability Security Privacy","serverless, reinforcement learning","Serverless architecture presents unique security challenges, requiring the adoption of advanced model architecture to improve security","Posed by serverless architecture, including data protection, access control, insecure configurations, and vulnerability to attacks"
paper_082,The Rise of Serverless Architectures: Security Challenges and Best Practices,"The field of serverless computing has had significant growth and recognition in the past decade. This emerging area has garnered attention because to its notable impact on cost reduction, latency reduction, scalability improvement, and elimination of server-side management, among other benefits. Nevertheless, there is still a dearth of comprehensive study that would facilitate developers and academics in gaining a more profound comprehension of the importance of serverless computing in many scenarios. Therefore, it is imperative to provide scholarly study data that has been published within this particular field. This study conducted a comprehensive analysis of 275 scholarly articles retrieved from reputable literature sources, with the aim of extracting valuable insights pertaining to serverless computing. Subsequently, the acquired data underwent analysis in order to address many study inquiries pertaining to the contemporary advancements in serverless computing, encompassing its fundamental principles, available platforms, and patterns of utilization, among other relevant aspects. In addition, we analyze the current obstacles confronting serverless computing and explore potential avenues for future research to facilitate its deployment and utilization.",Burak Cinar,Asian Journal of Research in Computer Science,2023,16,4,194-210,Sciencedomain International,10.9734/ajrcos/2023/v16i4382,https://doi.org/10.9734/ajrcos/2023/v16i4382,journal-article,Semantic Scholar,high,"Survey, Latency, Reliability Security Privacy, Cost, Resource Management","serverless, latency, reinforcement learning","Nevertheless, there is still a dearth of comprehensive study that would facilitate developers and academics in gaining a more profound comprehension of the importance of serverless computing in many scenarios",Not explicitly mentioned
paper_083,Elevating Cloud Security via Serverless Computing: An in Depth Exploration,"The research aims to elucidate the transformative potential of serverless architecture in enhancing cloud security, addressing common threats, and mitigating vulnerabilities. Through a systematic review of existing literature, empirical experiments, and case studies, the study delves into the underlying principles of serverless architecture, explores its advantages, challenges, and practical applications, and evaluates its performance and scalability compared to traditional computing models. The findings underscore the scalability, cost-effectiveness, and simplicity of serverless computing, while also highlighting challenges such as cold start latency and vendor lock-in. Moreover, the research identifies key recommendations and best practices for designing, deploying, and managing serverless applications, offering valuable insights for industry practitioners, researchers, and policymakers. Overall, the study contributes to a deeper understanding of serverless computing and its role in shaping the future of cloud-native application development",Lakshay Bhardwaj; Nitin Mishra; Ashima Mehta,"International Journal of Advanced Research in Science, Communication and Technology",2024,,,108-114,Naksh Solutions,10.48175/ijarsct-17618,https://doi.org/10.48175/ijarsct-17618,journal-article,Semantic Scholar,high,"Survey, Latency, Reliability Security Privacy, Cost","cold start, serverless, cloud computing, latency, reinforcement learning",Novel approach to serverless computing challenges,Such as cold start latency and vendor lock-in
paper_084,SCIFFS: Enabling Secure Third-Party Security Analytics using Serverless Computing,"Third-party security analytics allow companies to outsource threat monitoring tasks to teams of experts and avoid the costs of in-house security operations centers. By analyzing telemetry data from many clients these services are able to offer enhanced insights, identifying global trends and spotting threats before they reach most customers. Unfortunately, the aggregation that drives these insights simultaneously risks exposing sensitive client data if it is not properly sanitized and tracked. In this work, we present SCIFFS, an automated information flow monitoring framework for preventing sensitive data exposure in third-party security analytics platforms. SCIFFS performs decentralized information flow control over customer data it in a serverless setting, leveraging the innate polyinstantiated nature of serverless functions to assure precise and lightweight tracking of data flows. Evaluating SCIFFS against a proof-of-concept security analytics framework on the widely-used OpenFaaS platform, we demonstrate that our solution supports common analyst workflows data ingestion, custom dashboards, threat hunting) while imposing just 3.87% runtime overhead on event ingestion and the overhead on aggregation queries grows linearly with the number of records in the database (e.g., 18.75% for 50,000 records and 104.27% for 500,000 records) as compared to an insecure baseline. Thus, SCIFFS not only establishes a privacy-respecting model for third-party security analytics, but also highlights the opportunities for security-sensitive applications in the serverless computing model.",Isaac Polinsky; Pubali Datta; Adam Bates; William Enck,Proceedings of the 26th ACM Symposium on Access Control Models and Technologies,2021,,,175-186,ACM,10.1145/3450569.3463567,https://doi.org/10.1145/3450569.3463567,proceedings-article,Semantic Scholar,high,"Reliability Security Privacy, Cost","serverless, reinforcement learning, monitoring","Sciffs, an automated information flow monitoring framework for preventing sensitive data exposure in third-party security analytics platforms",Also highlights the opportunities for security-sensitive applications in the serverless computing model
paper_085,GRASP: Hardening Serverless Applications through Graph Reachability Analysis of Security Policies,"Serverless computing is supplanting past versions of cloud computing as the easiest way to rapidly prototype and deploy applications. However, the reentrant and ephemeral nature of serverless functions only exacerbates the challenge of correctly specifying security policies. Unfortunately, with role-based access control solutions like Amazon Identity and Access Management (IAM) already suffering from pervasive misconfiguration problems, the likelihood of policy failures in serverless applications is high. In this work, we introduce GRASP, a graph-based analysis framework for modeling serverless access control policies as queryable reachability graphs. GRASP generates reusable models that represent the principals of a serverless application and the interactions between those principals. We implement GRASP for Amazon IAM in Prolog, then deploy it on a corpus of 731 open source Amazon Lambda applications. We find that serverless policies tend to be short and highly permissive, e.g., 92% of surveyed policies are comprised of just 10 statements and 30% exhibit full reachability between all application functions and resources. We then use GRASP to identify potential attack vectors permitted by these policies, including hundreds of sensitive access channels, a dozen publicly-exposed resources, and four channels that may permit an attacker to exfiltrate an application's private resources through one of its public resources. These findings demonstrate GRASP's utility as a means of identifying opportunities for hardening application policies and highlighting potential exfiltration channels.",Isaac Polinsky; Pubali Datta; Adam Bates; William Enck,Proceedings of the ACM Web Conference 2024,2024,,,1644-1655,ACM,10.1145/3589334.3645436,https://doi.org/10.1145/3589334.3645436,proceedings-article,Semantic Scholar,high,"Survey, Reliability Security Privacy, Resource Management","serverless, cloud computing, reinforcement learning","Grasp, a graph-based analysis framework for modeling serverless access control policies as queryable reachability graphs; Grasp for amazon iam in prolog, then deploy it on a corpus of 731 open source amazon lambda applications",Of correctly specifying security policies; The reentrant and ephemeral nature of serverless functions only exacerbates the challenge of correctly specifying security policies
paper_086,Serverless computing and advanced security framework integration: From implementation to future trends,"The integration of serverless computing and Function-as-a-Service (FaaS) with advanced security frameworks represents a transformative shift in cloud-native application development. This comprehensive analysis explores the evolution of serverless architectures, examining their impact on real-time data processing, API development, microservices implementation, and machine learning applications. The article investigates the synergy between serverless computing and cybersecurity measures, particularly focusing on Zero-Trust Architecture implementation across healthcare, retail, and supply chain sectors. Furthermore, it evaluates the future trajectory of serverless computing, analyzing its convergence with edge computing, AI-driven automation, and blockchain technologies, while addressing the challenges and opportunities in maintaining security and compliance in distributed cloud environments.",Siva Prakash Bikka,International Journal of Science and Research Archive,2025,14,1,1751-1757,GSC Online Press,10.30574/ijsra.2025.14.1.0267,https://doi.org/10.30574/ijsra.2025.14.1.0267,journal-article,Semantic Scholar,high,"Survey, Reliability Security Privacy","serverless, microservices, cloud computing, reinforcement learning, distributed systems",The integration of serverless computing and function-as-a-service (faas) with advanced security frameworks represents a transformative shift in cloud-native application development,And opportunities in maintaining security and compliance in distributed cloud environments
paper_087,"Serverless Architectures and Function-As-A-Service (Faas): Scalability, Cost Efficiency, And Security Challenges",": Serverless computing and Function-as-a-Service (FaaS) have become the new “new hotness” in cloud computing. Since FaaS completely abstracts away the infrastructure, developers are left with having to write only their app logic — a very cost-effective and scalable solution for modern workloads. This paper looks at the rise of serverless architectures through these key platforms. We get answers on the benefits of the scalability and elasticity models and cost implications compared with traditional server-based infrastructures. The case study demonstrates how the pay-per-execution model can prevent resource waste and some problems developers might face in implementing this way of working, such as cold-start latency and informal ecosystems. We further present three case studies on serverless machine learning workloads, which show the practical benefits of serverless computing.",Bhanuprakash Madupati,SSRN Electronic Journal,2025,,,,Elsevier BV,10.2139/ssrn.5076665,https://doi.org/10.2139/ssrn.5076665,journal-article,Semantic Scholar,high,"Latency, Reliability Security Privacy, Cost, Energy Consumption, Resource Management","cold start, serverless, cloud computing, latency, elasticity, reinforcement learning","Since faas completely abstracts away the infrastructure, developers are left with having to write only their app logic — a very cost-effective and scalable solution for modern workloads","Developers might face in implementing this way of working, such as cold-start latency and informal ecosystems"
paper_088,"A Review on Data Security and Privacy in Serverless Computing: Key Strategies,  Emerging Challenges","Serverless computing has revolutionized cloud-based application development by eliminating the need for developers to manage infrastructure. Cloud providers take care of provisioning, scalability, and security fixes, freeing developers to concentrate entirely on code composition. Serverless architectures, primarily driven by Function-as-a-Service (FaaS) and Backend-as-a-Service (BaaS), offer advantages such as cost efficiency, scalability, and reduced operational overhead. However, these benefits come with significant data security and privacy challenges, including authentication weaknesses, data exposure risks, and vendor lock-in. This paper explores the fundamentals of serverless computing, its key security concerns, and mitigation strategies. Analyzing existing literature and emerging trends provides insights into best practices for enhancing security and privacy in serverless environments. Their study also examines compliance requirements, encryption techniques, and architectural advancements that address these challenges.",Bharath Kumar Reddy Janumpally,International Journal of Innovative Science and Research Technology,2025,,,118-126,International Journal of Innovative Science and Research Technology,10.38124/ijisrt/25mar023,https://doi.org/10.38124/ijisrt/25mar023,journal-article,Semantic Scholar,high,"Survey, Reliability Security Privacy, Cost, Energy Consumption, Resource Management","serverless, cloud computing, reinforcement learning",Serverless computing has revolutionized cloud-based application development by eliminating the need for developers to manage infrastructure,"These benefits come with significant data security and privacy challenges, including authentication weaknesses, data exposure risks, and vendor lock-in"
paper_089,TrapShield: Enhancing Security and Privacy in Serverless Workflows using Honeypots by Robust Adversary Penalization,"The marked shift of application developers to serverless computing has led to an increase in the number of cyberattacks and privacy concerns, thus prompting the need for secure serverless workflows. We propose TrapShield, a honeypots-based, secure and privacy preserving framework to protect serverless computing applications from insider and outsider attacks. It utilizes honeypots to deceive the attackers and penalize them by redirecting to a random set of dummy functions forming a cycle. Evaluations on Google Cloud Platform and Amazon Web Services for three popular serverless applications show TrapShield’s effectiveness in reducing costs for thwarting attacks while maintaining high runtime performance (approximately 1.3 seconds for an airline booking application).",Surabhi Garg; Maithri Suresh; Meena Singh Dilip Thakur; M A Rajan; Pankaj Sahu; Mangesh Gharote; Manju Ramesh; Sachin Lodha,2024 IEEE International Conference on Cloud Engineering (IC2E),2024,,,245-246,IEEE,10.1109/ic2e61754.2024.00034,https://doi.org/10.1109/ic2e61754.2024.00034,proceedings-article,Semantic Scholar,high,"Survey, Reliability Security Privacy, Cost","serverless, cloud computing, reinforcement learning","Trapshield, a honeypots-based, secure and privacy preserving framework to protect serverless computing applications from insider and outsider attacks",Not explicitly mentioned
paper_090,Comprehensive Security Framework for Serverless Computing: Integrating DevSecOps Practices in Aws Lambda and Azure Functions,"Serverless computing has fundamentally transformed application architecture by abstracting infrastructure management, yet this paradigm shift introduces distinctive security challenges that conventional tools struggle to address. The ephemeral nature of serverless functions creates visibility gaps that leave organizations vulnerable to configuration drift, runtime attacks, and compliance violations. This article presents a comprehensive security framework that addresses these challenges through systematic integration of protection mechanisms across the entire serverless lifecycle. The framework encompasses static code analysis tailored for function-based architectures, automated configuration scanning that adapts to rapid deployment cycles, and agentless runtime monitoring that maintains performance efficiency. By embedding Policy as Code within CI/CD pipelines and implementing lightweight instrumentation techniques, organizations can achieve continuous compliance with standards such as PCI-DSS and CIS benchmarks while maintaining developer agility. The proposed model demonstrates how security controls can be seamlessly integrated without impeding deployment velocity, utilizing automated compliance checks and real-time threat detection to minimize both misconfiguration risks and runtime vulnerabilities. This holistic approach enables organizations to leverage the benefits of serverless computing while maintaining robust security postures across their AWS Lambda and Azure Functions deployments.",Naresh Kiran Kumar Reddy Yelkoti,World Journal of Advanced Engineering Technology and Sciences,2025,15,3,1393-1401,GSC Online Press,10.30574/wjaets.2025.15.3.1052,https://doi.org/10.30574/wjaets.2025.15.3.1052,journal-article,Semantic Scholar,high,"Survey, Reliability Security Privacy, Energy Consumption","serverless, reinforcement learning, monitoring","Model demonstrates how security controls can be seamlessly integrated without impeding deployment velocity, utilizing automated compliance checks and real-time threat detection to minimize both misconfiguration risks and runtime vulnerabilities",That conventional tools struggle to address; Through systematic integration of protection mechanisms across the entire serverless lifecycle
paper_091,Serverless Edge Pattern with Amazon CloudFront Functions in the Banking Industry: Enhancing Performance and Security,"This paper examines the serverless edge pattern using Amazon CloudFront Functions in the U.S. banking industry, focusing on its role in improving performance and security. By executing lightweight JavaScript functions at CloudFront’s edge locations, banks can enhance content delivery, reduce latency, and bolster security through authentication and header validation. Benefits include serverless support, layered network strategies, and multi-language flexibility, demonstrated via U.S.-specific implementations. Challenges such as execution constraints, integration complexity, and regulatory compliance are addressed with practical solutions. Incorporating trends up to December 2024, including surging digital adoption and cyber threats, this study illustrates how CloudFront Functions enable U.S. banks to provide secure, efficient services in a competitive digital landscape.",Saikrishna Garlapati -,International Journal of Leading Research Publication,2025,6,6,,Sky Research Publication and Journals,10.70528/ijlrp.v6.i6.1613,https://doi.org/10.70528/ijlrp.v6.i6.1613,journal-article,Semantic Scholar,high,"Latency, Reliability Security Privacy","serverless, cloud computing, latency, reinforcement learning",Novel approach to serverless computing challenges,"Such as execution constraints, integration complexity, and regulatory compliance are addressed with practical solutions"
paper_092,Characterizing browser-based medical imaging AI with serverless edge computing: towards addressing clinical data security constraints,"Artificial intelligence (AI) has been widely introduced to various medical imaging applications ranging from disease visualization to medical decision support. However, data privacy has become an essential concern in clinical practice of deploying the deep learning algorithms through cloud computing. The sensitivity of patient health information (PHI) commonly limits network transfer, installation of bespoke desktop software, and access to computing resources. Serverless edge-computing shed light on privacy preserved model distribution maintaining both high flexibility (as cloud computing) and security (as local deployment). In this paper, we propose a browser-based, cross-platform, and privacy preserved medical imaging AI deployment system working on consumer-level hardware via serverless edge-computing. Briefly we implement this system by deploying a 3D medical image segmentation model for computed tomography (CT) based lung cancer screening. We further curate tradeoffs in model complexity and data size by characterizing the speed, memory usage, and limitations across various operating systems and browsers. Our implementation achieves a deployment with (1) a 3D convolutional neural network (CNN) on CT volumes (256×256×256 resolution), (2) an average runtime of 80 seconds across Firefox v.102.0.1/Chrome v.103.0.5060.114/Microsoft Edge v.103.0.1264.44 and 210 seconds on Safari v.14.1.1, and (3) an average memory usage of 1.5 GB on Microsoft Windows laptops, Linux workstation, and Apple Mac laptops. In conclusion, this work presents a privacy-preserved solution for medical imaging AI applications that minimizes the risk of PHI exposure. We characterize the tools, architectures, and parameters of our framework to facilitate the translation of modern deep learning methods into routine clinical care.",Chenxi Dong; Thomas Z. Li; Kaiwen Xu; Zekun Wang; Fabien Maldonado; Kim Sandler; Bennett A. Landman; Yuankai Huo,"Medical Imaging 2023: Imaging Informatics for Healthcare, Research, and Applications",2023,,,5,SPIE,10.1117/12.2653626,https://doi.org/10.1117/12.2653626,proceedings-article,Semantic Scholar,high,"Reliability Security Privacy, QoS, Resource Management","serverless, cloud computing, reinforcement learning, deep learning, memory management","A browser-based, cross-platform, and privacy preserved medical imaging ai deployment system working on consumer-level hardware via serverless edge-computing; This system by deploying a 3d medical image segmentation model for computed tomography (ct) based lung cancer screening; To facilitate the translation of modern deep learning methods into routine clinical care",Across various operating systems and browsers; Data privacy has become an essential concern in clinical practice of deploying the deep learning algorithms through cloud computing
paper_093,"Comparative Security and Compliance Analysis of Serverless Computing Platforms: AWS Lambda, Azure Functions, and Google Cloud Functions","Serverless computing has revolutionized cloud services by abstracting infrastructure management, enabling developers to focus on application logic. This research examines the security and compliance features of three major serverless platforms: AWS Lambda, Azure Functions, and Google Cloud Functions. By evaluating authentication mechanisms, data encryption practices, vulnerability management, and compliance certifications, we aim to provide a comparative analysis that informs businesses and developers on the most secure and compliant platform for their needs. Keywords: Serverless Computing, Security, Compliance, AWS Lambda, Azure Functions, Google Cloud Functions, Cloud Security Alliance, Cloud Controls Matrix",Dibya Darshan Khanal; Sushil Maharjan,INTERANTIONAL JOURNAL OF SCIENTIFIC RESEARCH IN ENGINEERING AND MANAGEMENT,2024,8,8,13-Jan,Indospace Publications,10.55041/ijsrem36979,https://doi.org/10.55041/ijsrem36979,journal-article,Semantic Scholar,high,"Survey, Reliability Security Privacy","serverless, cloud computing, reinforcement learning","Serverless computing has revolutionized cloud services by abstracting infrastructure management, enabling developers to focus on application logic",Not explicitly mentioned
paper_094,Benchmarking Serverless Computing,"With the increasing adoption of serverless computing, there is a need for a benchmark. The aim of this paper is to present such a benchmark based on performance and usability testing to better understand serverless services as well as help practitioners to select between two major clouds, namely, Amazon and Azure. Jmeter tool and system usability scale are used to conduct performance and usability testing, respectively. In addition, a replication package is provided to increase the validity and reliability of the results. The main findings revealed that the serverless platforms are different in their architecture. Even though both of them support the same serverless concept, they differ considerably in structure, development, and creations of services. Overall, both the cloud vendors under study provide the same core capabilities one would expect but, there are some differences too. In particular, usability could be improved to extend the market and capture more customers.",Mubashra Sadaqat; Mary Sánchez-Gordón; Ricardo Colomo-Palacios,Journal of Information Technology Research,2022,15,1,17-Jan,IGI Global,10.4018/jitr.299374,https://doi.org/10.4018/jitr.299374,journal-article,Semantic Scholar,high,"Survey, Reliability Security Privacy","serverless, cloud computing, reinforcement learning","The aim of this paper is to present such a benchmark based on performance and usability testing to better understand serverless services as well as help practitioners to select between two major clouds, namely, amazon and azure",Not explicitly mentioned
paper_095,Benchmarking Serverless Workloads on Kubernetes,"As a disruptive paradigm in the cloud landscape, Serverless Computing is attracting attention because of its unique value propositions to reduce operating costs and outsource infrastructure management. Nevertheless, enterprise Functionas-a-Service (FaaS) platforms may pose significant risks such as vendor lock-in, lack of security control due to multi-tenancy, complicated pricing models, and legal and regulatory compliance— particularly in mobile computing scenarios. This work proposes a production-grade fault-tolerant serverless architecture based on a highly-available Kubernetes topology using an open-source framework, deployed on OpenStack instances, and benchmarked with a realistic scaled-down Azure workload traces dataset. By measuring success rate, throughput, latency, and auto scalability, we have managed to assess not only resilience but also sustained performance under a logistic model for three distinct representative workloads. Our test executions show, with 95%–confidence, that between 70 and 90 concurrent users can access the system while experiencing acceptable performance. Beyond the breaking point identified (i.e. 91 transactions per second), the Kubernetes cluster has to be scaled-up or scaled out to meet the QoS and availability requirements.",Hima Govind; Horacio GonzaleznVelez,"2021 IEEE/ACM 21st International Symposium on Cluster, Cloud and Internet Computing (CCGrid)",2021,,,,IEEE,10.1109/ccgrid51090.2021.00085,https://doi.org/10.1109/ccgrid51090.2021.00085,proceedings-article,Semantic Scholar,high,"Survey, Latency, Reliability Security Privacy, QoS, Cost","serverless, cloud computing, latency, throughput, reinforcement learning, distributed systems","This work proposes a production-grade fault-tolerant serverless architecture based on a highly-available kubernetes topology using an open-source framework, deployed on openstack instances, and benchmarked with a realistic scaled-down azure workload traces dataset",Also sustained performance under a logistic model for three distinct representative workloads
paper_096,EdgeFaaSBench: Benchmarking Edge Devices Using Serverless Computing,"Due to the development of small-size, energy-efficient, and powerful CPUs and GPUs for single board computers, various edge devices are widely adopted for hosting real-world applications, including real-time object detection, autonomous driving, and sensor stream processing. At the same time, serverless computing receives increasing attention as a new application deployment model because of its simplicity, scalability, event-driven processing, and short-lived computation. Therefore, there is a growing demand for applying serverless computing to edge computing environments. However, due to the lack of characterization of serverless edge computing (e.g., application performance and impact from resource heterogeneity), researchers and practitioners have to conduct tedious measurements to understand the performance of serverless applications on edge devices in non-systematic ways.We create EdgeFaaSBench, a novel benchmark suite for serverless computing on edge devices, to bridge this gap. EdgeFaaSBench is developed on top of Apache OpenFaaS with Docker Swarm and can run various serverless benchmark workloads on edge devices with different hardware specifications (e.g., GPUs). EdgeFaaSBench contains 14 different benchmark workloads running on heterogeneous edge devices and captures various system-level, application-level, and serverless-specific metrics, including system utilization, response time, cold/warm start times, and impact of concurrent function executions. Experimental studies are conducted on two widely used edge devices, Raspberry Pi 4B and Jetson Nano, to show EdgeFaaSBench’s capabilities to benchmark serverless computing on edge devices.",Kaustubh Rajendra Rajput; Chinmay Dilip Kulkarni; Byungjin Cho; Wei Wang; In Kee Kim,2022 IEEE International Conference on Edge Computing and Communications (EDGE),2022,,,93-103,IEEE,10.1109/edge55608.2022.00024,https://doi.org/10.1109/edge55608.2022.00024,proceedings-article,Semantic Scholar,high,"Survey, Latency, Energy Consumption, Resource Management","warm start, serverless, energy efficiency, reinforcement learning, cpu allocation","Due to the development of small-size, energy-efficient, and powerful cpus and gpus for single board computers, various edge devices are widely adopted for hosting real-world applications, including real-time object detection, autonomous driving, and sensor stream processing",Due to the lack of characterization of serverless edge computing (e
paper_097,Benchmarking the Data Layer Across Serverless Platforms,"The use of highly scalable serverless platforms for web microservices and IoT applications is well known. However, their use for data-intensive applications is restricted due to the stateless nature of serverless functions. Any data retrieval, storage, and the peer-to-peer communication requirement of an application in serverless deployment is satisfied using cloud storage services such as object storage, database, cache, etc. The heterogeneous cloud storage services offered by different cloud service providers have unique deliverable performance. One key challenge is to find the maximum achievable data transfer rate from serverless platforms to cloud storage services. In this work, we evaluate the performance of storage systems available for use with serverless platforms from multiple cloud vendors. Additionally, we examine the effect of cloud service characteristics and configurations on accelerating the data transfer between them. The experimental data provides some key insights to assist with designing application architecture using serverless platforms and cloud storage services.",Surya Chaitanya Palepu; Dheeraj Chahal; Manju Ramesh; Rekha Singhal,Proceedings of the 2nd Workshop on High Performance Serverless Computing,2022,,,7-Mar,ACM,10.1145/3526060.3535460,https://doi.org/10.1145/3526060.3535460,proceedings-article,Semantic Scholar,high,Survey,"serverless, microservices, cloud computing, reinforcement learning",Novel approach to serverless computing challenges,Is to find the maximum achievable data transfer rate from serverless platforms to cloud storage services; Their use for data-intensive applications is restricted due to the stateless nature of serverless functions
paper_098,SeBS-Flow: Benchmarking Serverless Cloud Function Workflows,"Serverless computing has emerged as a prominent paradigm, with a significant adoption rate among cloud customers. While this model offers advantages such as abstraction from the deployment and resource scheduling, it also poses limitations in handling complex use cases due to the restricted nature of individual functions. Serverless workflows address this limitation by orchestrating multiple functions into a cohesive application. However, existing serverless workflow platforms exhibit significant differences in their programming models and infrastructure, making fair and consistent performance evaluations difficult in practice. To address this gap, we propose the first serverless workflow benchmarking suite SeBS-Flow, providing a platform-agnostic workflow model that enables consistent benchmarking across various platforms. SeBS-Flow includes six real-world application benchmarks and four microbenchmarks representing different computational patterns. We conduct comprehensive evaluations on three major cloud platforms, assessing performance, cost, scalability, and runtime deviations. We make our benchmark suite open-source, enabling rigorous and comparable evaluations of serverless workflows over time. Implementation: https://github.com/spcl/serverless-benchmarks Artifact: https://github.com/spcl/sebs-flow-artifact",Larissa Schmid; Marcin Copik; Alexandru Calotoiu; Laurin Brandner; Anne Koziolek; Torsten Hoefler,Proceedings of the Twentieth European Conference on Computer Systems,2025,,,902-920,ACM,10.1145/3689031.3717465,https://doi.org/10.1145/3689031.3717465,proceedings-article,Semantic Scholar,high,"Survey, Cost, Resource Management","serverless, cloud computing, reinforcement learning","The first serverless workflow benchmarking suite sebs-flow, providing a platform-agnostic workflow model that enables consistent benchmarking across various platforms",In handling complex use cases due to the restricted nature of individual functions; By orchestrating multiple functions into a cohesive application
paper_099,"Benchmarking, analysis, and optimization of serverless function snapshots","Serverless computing has seen rapid adoption due to its high scalability and flexible, pay-as-you-go billing model. In serverless, developers structure their services as a collection of functions, sporadically invoked by various events like clicks. High inter-arrival time variability of function invocations motivates the providers to start new function instances upon each invocation, leading to significant cold-start delays that degrade user experience. To reduce cold-start latency, the industry has turned to snapshotting, whereby an image of a fully-booted function is stored on disk, enabling a faster invocation compared to booting a function from scratch. This work introduces vHive, an open-source framework for serverless experimentation with the goal of enabling researchers to study and innovate across the entire serverless stack. Using vHive, we characterize a state-of-the-art snapshot-based serverless infrastructure, based on industry-leading Containerd orchestration framework and Firecracker hypervisor technologies. We find that the execution time of a function started from a snapshot is 95% higher, on average, than when the same function is memory-resident. We show that the high latency is attributable to frequent page faults as the function's state is brought from disk into guest memory one page at a time. Our analysis further reveals that functions access the same stable working set of pages across different invocations of the same function. By leveraging this insight, we build REAP, a light-weight software mechanism for serverless hosts that records functions' stable working set of guest memory pages and proactively prefetches it from disk into memory. Compared to baseline snapshotting, REAP slashes the cold-start delays by 3.7x, on average.",Dmitrii Ustiugov; Plamen Petrov; Marios Kogias; Edouard Bugnion; Boris Grot,Proceedings of the 26th ACM International Conference on Architectural Support for Programming Languages and Operating Systems,2021,,,559-572,ACM,10.1145/3445814.3446714,https://doi.org/10.1145/3445814.3446714,proceedings-article,Semantic Scholar,high,"Survey, Latency, QoS, Cost, Resource Management","cold start, performance optimization, serverless, containerization, latency, reinforcement learning, memory management",That the high latency is attributable to frequent page faults as the function's state is brought from disk into guest memory one page at a time,Not explicitly mentioned
paper_100,PanOpticon: A Comprehensive Benchmarking Tool for Serverless Applications,"Serverless computing manifests as the FaaS offering where clients submit code to be managed and run by the service provider in the place of hiring and managing VMs for this purpose. Multiple Cloud Service providers have come up with their own implementations of FaaS infrastructure providing end-users with a multitude of choices. Each such platform provides a non-overlapping set of features which satisfies a subset of users. Further the design of the platform dictates the performance overheads of triggering the function. A tool that automates capturing how a function behaves under different configurations of a platform and across platforms will, therefore, be useful for end-users intending to deploy applications as a collection of FaaS units. In spite of the presence of a few benchmarking tools for FaaS offerings, they lack the comprehensive breadth required to understand the performance aspects of the design choices made by the end-users. Most tools focus on tuning resource parameters like memory, CPU requirements and measure metrics like execution time. They lack the option to measure the effects of features such as function chaining and choice of function triggers. We present PanOpticon - a tool that automates the deployment of FaaS applications on different platforms under a set of tunable configuration choices and presents the users with performance measurements for each configuration and platform.",Nikhila Somu; Nilanjan Daw; Umesh Bellur; Purushottam Kulkarni,2020 International Conference on COMmunication Systems &amp; NETworkS (COMSNETS),2020,,,,IEEE,10.1109/comsnets48256.2020.9027346,https://doi.org/10.1109/comsnets48256.2020.9027346,proceedings-article,Semantic Scholar,high,"Survey, Latency, Resource Management","serverless, cloud computing, reinforcement learning, memory management, cpu allocation",Panopticon - a tool that automates the deployment of faas applications on different platforms under a set of tunable configuration choices and presents the users with performance measurements for each configuration and platform,Not explicitly mentioned
paper_101,Benchmarking Cloud Providers on Serverless IoT Back-End Infrastructures,"Internet of Things (IoT) is one of the trending topics in the technological revolution of the last decade. The huge amount of sensors composing IoT systems implies the need for powerful back-end infrastructures that find a perfect habitat in cloud services. Nowadays, many players offer cloud services and it is thus essential for the user to consciously learn which one mostly fits his needs. Among cloud providers, three conquered a leader position in the sector: 1) Amazon Web services; 2) Google cloud platform; and 3) Microsoft azure. In this article, we thoroughly test these providers to highlight their strengths and weaknesses. To produce relevant results, we stress a back-end infrastructure designed to handle a national-sized network of IoT nodes. Our analysis is not limited to the cloud provider performance as a whole, while it also investigates and compares several cloud components separately. As part of the contribution, we also test different time-series databases and we discuss the advantages of such kind of technologies. Finally, an in-depth pricing analysis is conducted to better understand the differences between each platform from an economic perspective.",Luca Calderoni; Dario Maio; Lorenzo Tullini,IEEE Internet of Things Journal,2022,9,16,15255-15269,Institute of Electrical and Electronics Engineers (IEEE),10.1109/jiot.2022.3147860,https://doi.org/10.1109/jiot.2022.3147860,journal-article,Semantic Scholar,high,"Survey, Cost, Energy Consumption","serverless, cloud computing, reinforcement learning",Novel approach to serverless computing challenges,Not explicitly mentioned
paper_102,Engineering and Experimentally Benchmarking a Serverless Edge Computing System,"Thanks to the latest advances in containerization, the serverless edge computing model is becoming close to reality. Serverless at the edge is expected to enable low latency applications with fast autoscaling mechanisms, all running on heteroge-neous and resource-constrained devices. In this work, we engineer and experimentally benchmark a serverless edge computing system architecture. We deploy a decentralized edge computing platform for serverless applications providing processing, storage, and communication capabilities using only open-source software, running over heterogeneous resources (e.g., virtual machines, Raspberry Pis, or bare metal servers, etc). To achieve that, we provision an overlay-network based on Nebula network agnostic technology, running over private or public networks, and use K3s to provide hardware abstraction. We benchmark the system in terms of response times, throughput and scalability using different hardware devices connected through the public Internet. The results show that while serverless is feasible on heterogeneous devices showing a good performance on constrained devices, such as Raspberry Pis, the lack of support when determining computational power and network characterization leaves much room for imopovement in edge environments.",Francisco Carpio; Marc Michalke; Admela Jukan,2021 IEEE Global Communications Conference (GLOBECOM),2021,,,6-Jan,IEEE,10.1109/globecom46510.2021.9685235,https://doi.org/10.1109/globecom46510.2021.9685235,proceedings-article,Semantic Scholar,high,"Survey, Latency, Energy Consumption, Resource Management","autoscaling, serverless, containerization, latency, throughput, reinforcement learning",Novel approach to serverless computing challenges,Not explicitly mentioned
paper_103,BenchFaaS: Benchmarking Serverless Functions in an Edge Computing Network Testbed,"The serverless computing model has evolved as one of the key solutions in the cloud for fast autoscaling and capacity planning. In edge computing environments, however, the serverless model is challenged by the system heterogeneity and performance variability. In this paper, we introduce BenchFaaS, an open-source edge computing network testbed which automates the deployment and benchmarking of serverless functions. Our edge computing network considers a cluster of virtual machines and Raspberry Pis, and is designed to benchmark serverless functions under different hardware and network conditions. We measure and evaluate: (i) overhead incurred by testbed, (ii) performance of compute intensive tasks, (iii) impact of application payload size, (iv) scalability, and (v) performance of chained serverless functions. We share the lessons learnt in engineering and implementing the testbed. We present the measurement results and analyze the impact of networked infrastructure on serverless performance. The measurements indicate that a properly dimensioned edge computing network can effectively serve as a serverless infrastructure.",Francisco Carpio; Marc Michalke; Admela Jukan,IEEE Network,2023,37,5,81-88,Institute of Electrical and Electronics Engineers (IEEE),10.1109/mnet.125.2200294,https://doi.org/10.1109/mnet.125.2200294,journal-article,Semantic Scholar,high,"Survey, Resource Management","autoscaling, serverless, cloud computing, reinforcement learning, distributed systems","Benchfaas, an open-source edge computing network testbed which automates the deployment and benchmarking of serverless functions; The measurement results and analyze the impact of networked infrastructure on serverless performance",The serverless model is challenged by the system heterogeneity and performance variability
paper_104,Benchmarking Deep Neural Network Inference Performance on Serverless Environments With MLPerf,We provide a novel decomposition methodology from the current MLPerf benchmark to the serverless function execution model. We have tested our approach in Amazon Lambda to benchmark the processing capabilities of OpenCV and OpenVINO inference engines.,Unai Elordi; Luis Unzueta; Jon Goenetxea; Sergio Sanchez-Carballido; Ignacio Arganda-Carreras; Oihana Otaegui,IEEE Software,2021,38,1,81-87,Institute of Electrical and Electronics Engineers (IEEE),10.1109/ms.2020.3030199,https://doi.org/10.1109/ms.2020.3030199,journal-article,Semantic Scholar,high,Survey,"serverless, reinforcement learning, deep learning",In amazon lambda to benchmark the processing capabilities of opencv and openvino inference engines,Not explicitly mentioned
paper_105,CrossFit: Fine-grained Benchmarking of Serverless Application Performance across Cloud Providers,"Serverless computing emerged as a promising cloud computing paradigm for deploying cloud-native applications but raises new performance challenges. Existing performance evaluation studies focus on micro-benchmarking to measure an individual aspect of serverless functions, such as CPU speed, but lack an in-depth analysis of differences in application performance across cloud providers. This paper presents CrossFit, an approach for detailed and fair cross-provider performance benchmarking of serverless applications based on a providerindependent tracing model. Our case study demonstrates how detailed distributed tracing enables drill-down analysis to explain performance differences between two leading cloud providers, AWS and Azure. The results for an asynchronous application show that trigger time contributes most delay to the end-to-end latency and explains the main performance difference between cloud providers. Our results further reveal how increasing and bursty workloads affect performance stability, median latency, and tail latency.",Joel Scheuner; Rui Deng; Jan-Philipp Steghöfer; Philipp Leitner,2022 IEEE/ACM 15th International Conference on Utility and Cloud Computing (UCC),2022,,,51-60,IEEE,10.1109/ucc56403.2022.00016,https://doi.org/10.1109/ucc56403.2022.00016,proceedings-article,Semantic Scholar,high,"Survey, Latency","serverless, cloud computing, latency, reinforcement learning, cpu allocation, distributed systems","Crossfit, an approach for detailed and fair cross-provider performance benchmarking of serverless applications based on a providerindependent tracing model",Raises new performance challenges; Lack an in-depth analysis of differences in application performance across cloud providers
paper_106,A Distributed Analysis and Benchmarking Framework for Apache OpenWhisk Serverless Platform,"Serverless computing simplifies the life cycle of scalable web applications, through delegating most of the operational concerns to the cloud providers. One prominent serverless platform is Apache OpenWhisk which is employed by IBM Cloud. Despite the apparent benefits of serverless computing, some limitations of the serverless platform, such as the state-less nature of serverless functions, can introduce scalability bottlenecks. In this work, we propose an analysis and benchmarking approach for investigating potential bottlenecks and limitations of Apache OpenWhisk serverless platform.",Aleksandr Kuntsevich; Pezhman Nasirifard; Hans-Arno Jacobsen,Proceedings of the 19th International Middleware Conference (Posters),2018,,,4-Mar,ACM,10.1145/3284014.3284016,https://doi.org/10.1145/3284014.3284016,proceedings-article,Semantic Scholar,high,Survey,"serverless, cloud computing, reinforcement learning, distributed systems",An analysis and benchmarking approach for investigating potential bottlenecks and limitations of apache openwhisk serverless platform,"Of the serverless platform, such as the state-less nature of serverless functions, can introduce scalability bottlenecks; Of apache openwhisk serverless platform"
paper_107,WebAssembly at the Edge: Benchmarking a Serverless Platform for Private Edge Cloud Systems,"FunLess is a function-as-a-service (FaaS) platform tailored for private edge cloud systems. FunLess leverages WebAssembly as its runtime environment for performance, function isolation, and support for heterogeneous devices, crucial for extending the coverage of serverless computing to private edge cloud systems. We benchmark FunLess against three production-ready, widely adopted open source FaaS platforms—OpenFaaS, Fission, and Knative—under different deployment scenarios, characterized by the presence/absence of constrained-resource devices (Raspberry Pi 3B+) and the (in)accessibility of container orchestration technologies—Kubernetes. Our results confirm that FunLess is a suitable solution for FaaS private edge cloud systems since it achieves performance comparable to the considered FaaS alternatives while it is the only fully deployable alternative on constrained-resource devices.",Giuseppe De Palma; Saverio Giallorenzo; Jacopo Mauro; Matteo Trentin; Gianluigi Zavattaro,IEEE Internet Computing,2024,28,6,37-44,Institute of Electrical and Electronics Engineers (IEEE),10.1109/mic.2024.3513035,https://doi.org/10.1109/mic.2024.3513035,journal-article,Semantic Scholar,high,"Survey, Resource Management","serverless, containerization, cloud computing, reinforcement learning",Novel approach to serverless computing challenges,Not explicitly mentioned
paper_108,Benchmarking elasticity of FaaS platforms as a foundation for objective-driven design of serverless applications,"Application providers have to solve the trade-off between performance and deployment costs by selecting the ""right"" amount of provisioned computing resources for their application. The high value of changing this trade-off decision at runtime fueled a decade of combined efforts by industry and research to develop elastic applications. Despite these efforts, the development of elastic applications still demands significant time and expertise from application providers. To address this demand, FaaS platforms shift responsibilities associated with elasticity from the application developer to the cloud provider. While this shift is highly promising, FaaS platforms do not quantify elasticity; thus, application developers are unaware of how elastic FaaS platforms are. This lack of knowledge significantly impairs effective objective-driven design of serverless applications. In this paper, we present an experiment design and corresponding toolkit for quantifying elasticity and its associated trade-offs with latency, reliability, and execution costs. We present results for the evaluation of four popular FaaS platforms by AWS, Google, IBM, Microsoft, and show significant differences between the service offers. Based on our results, we assess the applicability of the individual FaaS platforms in three scenarios under different objectives: web serving, online data analysis, and offline batch processing.",Jörn Kuhlenkamp; Sebastian Werner; Maria C. Borges; Dominik Ernst; Daniel Wenzel,Proceedings of the 35th Annual ACM Symposium on Applied Computing,2020,,,1576-1585,ACM,10.1145/3341105.3373948,https://doi.org/10.1145/3341105.3373948,proceedings-article,Semantic Scholar,high,"Survey, Latency, Reliability Security Privacy, Cost, Resource Management","serverless, cloud computing, latency, elasticity, reinforcement learning","An experiment design and corresponding toolkit for quantifying elasticity and its associated trade-offs with latency, reliability, and execution costs; Results for the evaluation of four popular faas platforms by aws, google, ibm, microsoft, and show significant differences between the service offers","These efforts, the development of elastic applications still demands significant time and expertise from application providers"
paper_109,MPC-Based Privacy-Preserving Serverless Federated Learning,"Federated learning (FL) enables multiple users to collaboratively train a global model by keeping their data sets local. Since a single server is used, traditional FL faces the single point of failure problem. An available approach is to adopt a serverless architecture. However, most of existing serverless FL schemes fail to protect gradient privacy, except for a few schemes that adopt differential privacy (DP) where the global model accuracy will decrease. To address these problems, we propose a privacy-preserving serverless FL scheme based on secure multiparty computation (MPC). Combining multiple cryptographic primitives (e.g., key agreement and symmetric encryption), our scheme protects gradient privacy in FL and it is accuracy-lossless. By secret sharing, our scheme supports users to quit an FL task in each round during training.",Liangyu Zhong; Lei Zhang; Lin Xu; Lulu Wang,"2022 3rd International Conference on Big Data, Artificial Intelligence and Internet of Things Engineering (ICBAIE)",2022,,,493-497,IEEE,10.1109/icbaie56435.2022.9985933,https://doi.org/10.1109/icbaie56435.2022.9985933,proceedings-article,Semantic Scholar,high,Reliability Security Privacy,"serverless, reinforcement learning",A privacy-preserving serverless fl scheme based on secure multiparty computation (mpc),"Most of existing serverless fl schemes fail to protect gradient privacy, except for a few schemes that adopt differential privacy (dp) where the global model accuracy will decrease"
paper_110,PrivFlow: Secure and Privacy Preserving Serverless Workflows on Cloud,"The recent advancement of serverless computing in the widespread deployment of applications prompts the need to protect serverless workflows against cloud vulnerabilities and threats. We propose PrivFlow, a workflow-centric, privacy preserving framework to protect the information flow in serverless computing applications in semi-honest (S-PrivFlow) and malicious (M-PrivFlow) adversarial settings. An Authenticated Data Structure is used to store the valid workflows encoded in the proposed format. The validation of workflows is performed in a privacy preserving manner that leaks no sensitive information to any unauthorized user. We focus on the two most prevalent attacks on the serverless cloud platforms, namely the Denial-of-Wallet and Wrong Function Invocation attacks. We demonstrate that PrivFlow mitigates both of these attacks. Further, we evaluate PrivFlow on the popular benchmark application- Hello Retail, and a customized scaled application. Though the comparison with the state-of-the-art approaches in terms of the runtime performance shows a latency of 1.6 times for S-PrivFlow and 8 times for M-PrivFlow, the PrivFlow provides high security and privacy. PrivFlow acts as a wrapper to the application resulting in no change to the source code.",Surabhi Garg; Meena Singh Dilip Thakur; Rajan M A; Lakshmi Padmaja Maddali; Vigneswaran Ramachandran,"2023 IEEE/ACM 23rd International Symposium on Cluster, Cloud and Internet Computing (CCGrid)",2023,,,447-458,IEEE,10.1109/ccgrid57682.2023.00049,https://doi.org/10.1109/ccgrid57682.2023.00049,proceedings-article,Semantic Scholar,high,"Survey, Latency, Reliability Security Privacy","serverless, cloud computing, latency, reinforcement learning","Privflow, a workflow-centric, privacy preserving framework to protect the information flow in serverless computing applications in semi-honest (s-privflow) and malicious (m-privflow) adversarial settings; Format",Not explicitly mentioned
paper_111,Privacy-Preserving Serverless Computing Using Federated Learning for Smart Grids,"The smart power grid is a critical energy infrastructure where real-time electricity usage data is collected to predict future energy requirements. The existing prediction models focus on the centralized frameworks, where the collected data from various home area networks (HANs) are forwarded to a central server. This process leads to cybersecurity threats. This article proposes a federated learning based model with privacy preservation of smart grids data using serverless cloud computing. The model considers the blockchain-enabled dew servers in each HAN for local data storage and local model training. Advanced perturbation and normalization techniques are used to reduce the inverse impact of irregular workload on the training results. The experiment conducted on benchmarks datasets demonstrates that the proposed model minimizes the computation and communication costs, attacking probability, and improves the test accuracy. Overall, the proposed model enables smart grids with robust privacy preservation and high accuracy.",Parminder Singh; Mehedi Masud; M. Shamim Hossain; Avinash Kaur; Ghulam Muhammad; Ahmed Ghoneim,IEEE Transactions on Industrial Informatics,2022,18,11,7843-7852,Institute of Electrical and Electronics Engineers (IEEE),10.1109/tii.2021.3126883,https://doi.org/10.1109/tii.2021.3126883,journal-article,Semantic Scholar,high,"Survey, Reliability Security Privacy, Cost, Energy Consumption","serverless, cloud computing, energy efficiency, reinforcement learning, prediction","Model minimizes the computation and communication costs, attacking probability, and improves the test accuracy; Model enables smart grids with robust privacy preservation and high accuracy",Not explicitly mentioned
paper_112,ROBY: A Byzantine-Robust and Privacy-Preserving Serverless Federated Learning Framework,"Federated Learning (FL) allows multiple data owners to jointly train machine learning models by sharing local models instead of raw private data, alleviating data privacy concerns. However, as the local computation of data owners is unpredictable, it increases its vulnerability to Byzantine attacks, where compromised data owners submit abnormal local models that can severely degrade global model accuracy. Existing Byzantine-robust FL methods depend on a semi-honest server executing predefined Byzantine-robust aggregation rules (ByRules) to filter out abnormal local models, but these methods fail when the server is compromised. Although recent serverless Byzantine-robust FL approaches mitigate the risk of a compromised server, they suffer from challenges in achieving consensus on ByRules and impose a heavy burden on privacy protection. In this paper, we propose ROBY, a novel serverless FL framework that extends existing ByRules to a decentralized setting, effectively defending against Byzantine attacks and ensuring privacy protection for local models. ROBY introduces a shared, dynamically updated consensus dataset that serves as a reliable benchmark for applying ByRules and enabling efficient consensus on ByRules among decentralized data owners. Moreover, we design a dual-layer privacy shielding strategy in ROBY to protect local model privacy without sacrificing global model accuracy or incurring extra computational and communication overhead. Extensive evaluations demonstrate that ROBY substantially enhances both Byzantine robustness and privacy protection compared to server-based FL methods.",Xiangyun Tang; Minyang Li; Meng Shen; Jiawen Kang; Liehuang Zhu; Zhiquan Liu; Guomin Yang; Dusit Niyato; Robert H. Deng,IEEE Transactions on Information Forensics and Security,2025,20,,7824-7838,Institute of Electrical and Electronics Engineers (IEEE),10.1109/tifs.2025.3589066,https://doi.org/10.1109/tifs.2025.3589066,journal-article,Semantic Scholar,high,"Survey, Reliability Security Privacy","serverless, reinforcement learning","Roby, a novel serverless fl framework that extends existing byrules to a decentralized setting, effectively defending against byzantine attacks and ensuring privacy protection for local models; A dual-layer privacy shielding strategy in roby to protect local model privacy without sacrificing global model accuracy or incurring extra computational and communication overhead","In achieving consensus on byrules and impose a heavy burden on privacy protection; As the local computation of data owners is unpredictable, it increases its vulnerability to byzantine attacks, where compromised data owners submit abnormal local models that can severely degrade global model accuracy"
paper_113,Privacy-Preserving Serverless Edge Learning With Decentralized Small-Scale Mobile Data,"In next-generation (i.e., 6G) networking systems, the data-driven approach will play an essential role, being an efficient tool for networking system management and bringing popular user applications. With those unprecedented and novel usages, existing frameworks fail to consider the complex nature of the next-generation networking system and consequently fail to be applied to future communication systems directly. Moreover, existing frameworks also fail to support popular privacy-preserving learning strategies efficiently by presenting special designs to respond to the resource-demanding nature of the aforementioned strategies. To fill this gap, this paper extends conventional serverless platforms with serverless edge learning architectures, providing a mature and efficient distributed training framework by fully exploiting limited wireless communication and edge computation resources in the considered networking system with the following three features. Firstly, this framework dynamically orchestrates resources among heterogeneous physical units to efficiently fulfill privacy-preserving learning objectives. The design jointly considers learning task requests and underlying infrastructure heterogeneity, including last-mile transmissions, computation abilities of edge and cloud computing centers, and loading status of infrastructure. Secondly, the proposed framework can easily work with data-driven approaches to improve network management efficiency, realizing AI for network promise of next-generation networking systems to provide efficient network automation. Lastly, to significantly reduce distributed training overheads, small-scale data training is proposed by integrating with a general, simple data classifier. This low-load enhancement can seamlessly work with various distributed deep models in the proposed framework to improve communications and computation efficiencies during the training phase. Based on the above innovations, open challenges, and future research directions encourage the research community to develop efficient privacy-preserving learning techniques.",Shih-Chun Lin; Chia-Hung Lin; Myungjin Lee,IEEE Network,2024,38,2,264-271,Institute of Electrical and Electronics Engineers (IEEE),10.1109/mnet.135.2200611,https://doi.org/10.1109/mnet.135.2200611,journal-article,Semantic Scholar,high,"Reliability Security Privacy, Energy Consumption, Resource Management","serverless, cloud computing, reinforcement learning, distributed systems","Framework can easily work with data-driven approaches to improve network management efficiency, realizing ai for network promise of next-generation networking systems to provide efficient network automation; Framework to improve communications and computation efficiencies during the training phase",Nature of the next-generation networking system and consequently fail to be applied to future communication systems directly
paper_114,Privacy Preserving and Serverless Homomorphic-Based Searchable Encryption as a Service (SEaaS),"Serverless computing has seen rapid growth, thanks to its adaptability, elasticity, and deployment agility, embraced by both cloud providers and users. However, this surge in serverless adoption has prompted a reevaluation of security concerns and thus, searchable encryption has emerged as a crucial technology. This paper explores the Searchable Encryption as a Service (SEaaS) and introduces an innovative privacy-preserving Multiple Keyword Searchable Encryption (MKSE) scheme within a serverless cloud environment, addressing previously unmet security goals. The proposed scheme employs probabilistic encryption and leverages fully homomorphic encryption to enable operations on ciphertext, facilitating searches on encrypted data. Its core innovation lies in the use of probabilistic encryption for private multi-keyword searches. To validate its practicality, we deploy the scheme on the public cloud infrastructure, “Contabo,” and conduct rigorous testing on a real-world dataset. The results demonstrate that our novel scheme successfully preserves the privacy of search queries and access patterns, achieving robust security. This research contributes to the field of serverless cloud security, particularly in the context of searchable encryption, by providing a refined solution for safeguarding data while maintaining usability in a serverless computing landscape.",Musfirah Ihtesham; Shahzaib Tahir; Hasan Tahir; Anum Hasan; Aiman Sultan; Saqib Saeed; Omer Rana,IEEE Access,2023,11,,115204-115218,Institute of Electrical and Electronics Engineers (IEEE),10.1109/access.2023.3324817,https://doi.org/10.1109/access.2023.3324817,journal-article,Semantic Scholar,high,"Survey, Reliability Security Privacy","serverless, cloud computing, elasticity, reinforcement learning","Scheme employs probabilistic encryption and leverages fully homomorphic encryption to enable operations on ciphertext, facilitating searches on encrypted data","This surge in serverless adoption has prompted a reevaluation of security concerns and thus, searchable encryption has emerged as a crucial technology"
paper_115,SPEI-FL: Serverless Privacy Edge Intelligence-Enabled Federated Learning in Smart Healthcare Systems,"Smart healthcare systems promise significant benefits for fast and accurate medical decisions. However, working with personal health data presents new privacy issues and constraints that must be solved from a cybersecurity perspective. Edge intelligence-enabled federated learning is a new scheme that utilises decentralised computing that allows data analytics to be carried out at the edge of a network, enhancing data privacy. However, this scheme suffers from privacy attacks, including inference, free-riding, and man-in-the-middle attacks, especially with serverless computing for allocating resources to user needs. Edge intelligence-enabled federated learning requires client data insertion and deletion to authenticate genuine clients and a serverless computing capability to ensure the security of collaborative machine learning models. This work introduces a serverless privacy edge intelligence-based federated learning (SPEI-FL) framework to address these issues. SPEI-FL includes a federated edge aggregator and authentication method to improve the data privacy of federated learning and allow client adaptation and removal without impacting the overall learning processes. It also can classify intruders through serverless computing processes. The proposed framework was evaluated with the unstructured COVID-19 medical chest x-rays and MNIST digit datasets, and the structured BoT-IoT dataset. The performance of the framework is comparable with existing authentication methods and reported a higher accuracy than comparable methods (approximately 90% as compared with the 81% reported by peer methods). The proposed authentication method prevents the exposure of sensitive patient information during medical device authentication and would become the cornerstone of the next generation of medical security with serverless computing.",Mahmuda Akter; Nour Moustafa; Benjamin Turnbull,Cognitive Computation,2024,16,5,2626-2641,Springer Science and Business Media LLC,10.1007/s12559-024-10310-3,https://doi.org/10.1007/s12559-024-10310-3,journal-article,Semantic Scholar,high,"Reliability Security Privacy, Resource Management","serverless, reinforcement learning","Framework was evaluated with the unstructured covid-19 medical chest x-rays and mnist digit datasets, and the structured bot-iot dataset; Authentication method prevents the exposure of sensitive patient information during medical device authentication and would become the cornerstone of the next generation of medical security with serverless computing",That must be solved from a cybersecurity perspective; Working with personal health data presents new privacy issues and constraints that must be solved from a cybersecurity perspective
paper_116,PRICELESS: Privacy enhanced AI‐driven scalable framework for <scp>IoT</scp> applications in serverless edge computing environments,"Serverless edge computing has emerged as a new paradigm that integrates the serverless and edge computing. By bringing processing power closer to the edge of the network, it provides advantages such as low latency by quickly processing data for time‐sensitive Internet of Things (IoT) applications. Additionally, serverless edge computing also brings inherent problems of edge and serverless computing such as cold start, security and privacy that are still waiting to be solved. In this paper, we propose a new Blockchain‐based AI‐driven scalable framework called PRICELESS, to offer security and privacy in serverless edge computing environments while performing cold start prediction. In PRICELESS framework, we used deep reinforcement learning for the cold start latency prediction. For experiments, a cold start dataset is created using a heart disease risk‐based IoT application and deployed using Google Cloud Functions. Experimental results show the additional delay that the blockchain module brings to cold start latency and its impact on cold start prediction performance. Additionally, the performance of PRICELESS is compared with the current state‐of‐the‐art method based on energy cost, computation time and cold start prediction. Specifically, it has been observed that PRICELESS causes 19 ms of external latency, 358.2 watts for training, and 3.6 watts for prediction operations, resulting in additional energy consumption at the expense of security and privacy.",Muhammed Golec; Mustafa Golec; Minxian Xu; Huaming Wu; Sukhpal Singh Gill; Steve Uhlig,Internet Technology Letters,2025,8,1,,Wiley,10.1002/itl2.510,https://doi.org/10.1002/itl2.510,journal-article,Semantic Scholar,high,"Latency, Reliability Security Privacy, Cost, Energy Consumption","cold start, serverless, cloud computing, latency, energy efficiency, reinforcement learning, prediction","A new blockchain‐based ai‐driven scalable framework called priceless, to offer security and privacy in serverless edge computing environments while performing cold start prediction","Of edge and serverless computing such as cold start, security and privacy that are still waiting to be solved"
paper_117,SDN Traffic Flows in a Serverless Environment: a Categorization of Energy Consumption,"The widespread adoption of Software Defined Networks (SDN) in Information and Communication Technology (ICT) sectors has positioned it as a crucial technology due to its flexibility and modularity, which results from shifting control from physical network devices to software controllers. However, this shift has led to several challenges, including increasing energy consumption. Serverless computing can effectively support SDN to address various issues, such as energy efficiency, yet lacks an energy-aware scheduling framework designed for such an environment. This research investigates the key factors influencing serverless energy consumption in SDN by examining the correlations between the energy usage of serverless applications and traffic flow patterns, as such correlations can play a critical role in developing an energy-aware scheduling framework. The findings reveal that several traffic patterns strongly or moderately impact energy consumption in serverless environment.",Abdulaziz Alhindi; Karim Djemame,2024 IEEE/ACM 17th International Conference on Utility and Cloud Computing (UCC),2024,,,447-452,IEEE,10.1109/ucc63386.2024.00069,https://doi.org/10.1109/ucc63386.2024.00069,proceedings-article,Semantic Scholar,high,"Energy Consumption, Resource Management","serverless, energy efficiency, reinforcement learning",Novel approach to serverless computing challenges,"This shift has led to several challenges, including increasing energy consumption"
paper_118,An autoscalable approach to optimize energy consumption using smart meters data in serverless computing,"Serverless computing has evolved as a prominent paradigm within cloud computing, providing on-demand resource provisioning and capabilities crucial to Science and Technology for Energy Transition (STET) applications. Despite the efficiency of auto-scalable approaches in optimizing performance and cost in distributed systems, their potential remains underutilized in serverless computing due to the lack of comprehensive approaches. So an auto-scalable approach has been designed using Q-learning, which
enables optimal resource scaling decisions. This approach proves useful for adjusting resources dynamically to maximize resource utilization by automatically scaling up or down resources as needed. Further, the proposed approach has been validated using AWS Lambda with key performance metrics such as probability of cold start, average response time, idle instance count, energy consumption etc. The experimental results demonstrate that the proposed approach performs better than the existing approach by considering the above parameters. Finally, the proposed approach has also been validated to optimize the energy consumption of smart meters data",Jasmine Kaur; Inderveer Chana; Anju Bala,Science and Technology for Energy Transition,2024,79,,83,EDP Sciences,10.2516/stet/2024078,https://doi.org/10.2516/stet/2024078,journal-article,Semantic Scholar,high,"Latency, Cost, Energy Consumption, Resource Management","cold start, autoscaling, serverless, cloud computing, energy efficiency, reinforcement learning, distributed systems","Approach has been validated using aws lambda with key performance metrics such as probability of cold start, average response time, idle instance count, energy consumption etc; Approach performs better than the existing approach by considering the above parameters; Approach has also been validated to optimize the energy consumption of smart meters data","The efficiency of auto-scalable approaches in optimizing performance and cost in distributed systems, their potential remains underutilized in serverless computing due to the lack of comprehensive approaches"
paper_119,Cost minimization for deploying serverless functions,"The costs of serverless functions increase proportional to the amount of memory reserved on the deployed server. However, increasing the amount of memory decreases the function execution time, which is also a factor that contributes to cost. We propose an automated approach for optimizing the amount of memory reserved for serverless functions. First, we measure the running time of a given function in various memory settings and derive a regression model. Then, we define an objective function and a set of constraints based on this regression model and the configuration space. Finally, we determine the optimal memory setting for minimizing cost. Our industrial case study shows that significant cost reductions can be achieved by accurate estimations of the impact of memory settings on runtime performance.",Özgür Sedefoğlu; Hasan Sözer,Proceedings of the 36th Annual ACM Symposium on Applied Computing,2021,,,83-85,ACM,10.1145/3412841.3442069,https://doi.org/10.1145/3412841.3442069,proceedings-article,Semantic Scholar,high,"Latency, Cost","serverless, reinforcement learning, memory management",An automated approach for optimizing the amount of memory reserved for serverless functions,"Based on this regression model and the configuration space; Increasing the amount of memory decreases the function execution time, which is also a factor that contributes to cost"
paper_120,Low-Cost Serverless SIEM in the Cloud,"Security systems such as the Security Information and Event Management (SIEMs) have been used to monitor logs and correlate data to quickly detect and respond to incidents. Despite their advantages, SIEMs are expensive to deploy and maintain, requiring extra budget and specialized staff. Another concern is the event retention period, which events are stored for a short period of time, missing important information about how threats may have affected the company infrastructure in the past. This thesis aims to improve these issues by using low-cost cloud services to correlate and store security events. We will investigate techniques to index, compress and store events in the cloud in a cost-efficient and safe way for a long time. We will create a cloud correlation engine using a serverless platform, such as Amazon Lambda. This approach can minimize the complexity of managing SIEMs in place, charging the customer only for the time actually spent processing events. Finally, we will integrate the storage and correlation engine into a cloud SIEM, providing also a monitoring tool, building a complete and innovative low-cost cloud-based security monitoring solution.",Adriano Serckumecka; Iberia Medeiros; Alysson Bessani,2019 38th Symposium on Reliable Distributed Systems (SRDS),2019,,,,IEEE,10.1109/srds47363.2019.00057,https://doi.org/10.1109/srds47363.2019.00057,proceedings-article,Semantic Scholar,high,"Reliability Security Privacy, Cost","serverless, cloud computing, reinforcement learning, monitoring",Novel approach to serverless computing challenges,"Their advantages, siems are expensive to deploy and maintain, requiring extra budget and specialized staff; By using low-cost cloud services to correlate and store security events"
paper_121,Serverless Scheduling Policies based on Cost Analysis,"Current proprietary and open-source serverless platforms follow opinionated, hardcoded scheduling policies to deploy the functions to be executed over the available workers. Such policies may decrease the performance and the security of the application due to locality issues (e.g., functions executed by workers far from the databases to be accessed). These limitations are partially overcome by the adoption of APP, a new platform-agnostic declarative language that allows serverless platforms to support multiple scheduling logics. Defining the""right""scheduling policy in APP is far from being a trivial task since it often requires rounds of refinement involving knowledge of the underlying infrastructure, guesswork, and empirical testing. In this paper, we start investigating how information derived from static analysis could be incorporated into APP scheduling function policies to help users select the best-performing workers at function allocation. We substantiate our proposal by presenting a pipeline able to extract cost equations from functions' code, synthesising cost expressions through the usage of off-the-shelf solvers, and extending APP allocation policies to consider this information.",Giuseppe De Palma; Saverio Giallorenzo; Cosimo Laneve; Jacopo Mauro; Matteo Trentin; Gianluigi Zavattaro,Electronic Proceedings in Theoretical Computer Science,2023,392,,40-52,Open Publishing Association,10.4204/eptcs.392.3,https://doi.org/10.4204/eptcs.392.3,journal-article,Semantic Scholar,high,"Survey, Reliability Security Privacy, Cost, Resource Management","serverless, reinforcement learning",Novel approach to serverless computing challenges,"Are partially overcome by the adoption of app, a new platform-agnostic declarative language that allows serverless platforms to support multiple scheduling logics; (e"
paper_122,Serverless revolution: Redefining application scalability and cost efficiency,"Serverless computing has become a novel wave in application development as it provides the best of both worlds- flexibility and affordable solutions. Because it gets rid of servers completely, and developers code and let cloud providers take care of the rest that fluctuates. This model enables businesses to manage costs effectively by charging only for the amount of usage and also eliminates the problem of processing unpredictable workloads, proving rather great for e-commerce, media, and IoT industries. However, this paper also looks at some issues accompanying serverless computing, such as Cold start latency, Vendor lock-in, and Execution constraints. With case studies and a subject matter expert's comparative evaluation of the traditional and serverless approaches, this article discusses the advantages and limitations of serverless architecture. The research delivers implementable solutions to optimize serverless architecture capabilities while lessening its challenges for organizations and developers who evaluate using it as a platform.",Bangar Raju Cherukuri,World Journal of Advanced Research and Reviews,2019,2,30,039-053,GSC Online Press,10.30574/wjarr.2019.2.3.0093,https://doi.org/10.30574/wjarr.2019.2.3.0093,journal-article,Semantic Scholar,high,"Survey, Latency, Cost, Energy Consumption","cold start, serverless, cloud computing, latency, reinforcement learning",Serverless computing has become a novel wave in application development as it provides the best of both worlds- flexibility and affordable solutions,Of serverless architecture; For organizations and developers who evaluate using it as a platform
paper_123,Understanding the Neglected Cost of Serverless Cluster Management,"Serverless computing enables the cloud platform to optimize resource management under the hood to improve performance and resource-efficiency. However, today's serverless cluster managers are designed by simply retrofitting legacy workload orchestration systems, despite the unique characteristics of serverless workloads. We study Knative-on-K8s as a representative state-of-the-art cluster manager for serverless and show that it can cause second-scale delays and contribute to over 65% of end-to-end latency for function invocations experiencing cold starts. These overheads occur when the cluster experiences high sandbox churn, which is common in production serverless deployments. We analyze the root cause of current cluster manager overheads for serverless workloads and propose a set of design principles to improve end-to-end latency and peak throughput by rethinking the cluster manager system architecture.",Lazar Cvetković; Rodrigo Fonseca; Ana Klimovic,Proceedings of the 4th Workshop on Resource Disaggregation and Serverless,2023,,,22-28,ACM,10.1145/3605181.3626286,https://doi.org/10.1145/3605181.3626286,proceedings-article,Semantic Scholar,high,"Latency, Cost, Energy Consumption, Resource Management","cold start, resource management, serverless, cloud computing, latency, throughput, reinforcement learning, distributed systems",We study knative-on-k8s as a representative state-of-the-art cluster manager for serverless and show that it can cause second-scale delays and contribute to over 65% of end-to-end latency for function invocations experiencing cold starts,"Today's serverless cluster managers are designed by simply retrofitting legacy workload orchestration systems, despite the unique characteristics of serverless workloads; The unique characteristics of serverless workloads"
paper_124,Cloud Computing Based (Serverless computing) using Serverless architecture for Dynamic Web Hosting and cost Optimization,"Serverless is a cloud-based code execution model where cloud carrie copes with servers and computing useful resource control instead of builders. There are not any virtual machines or bodily servers: they’re deployed routinely inside the cloud by companies. Cloud carriers cope with provisioning, keeping, and scaling the serverless architecture. What’s more, the serverless structure permits launching apps as wished: you don’t pay for ‘constantly-on’ server components to run your app when it’s no longer getting used. Instead, on a few occasiotriggerers app code, and the resources are dynamically allocated for that code. You forestall paying as quickly as the code is carried out. So, in a nutshell, serverless architecture is a manner to construct your cloud-primarily based software without coping with infrastructure. It eliminates the want for ordinary duties like protection patches, ability control, load balancing, scaling, and many others. Still, serverless does not mean there are no servers in any respect. The time period is truly elusive. Servers are definitely removed from the app development seeing that they are managed by the companies.",Rakesh Veuvolu; Anirudh Suryadevar; T. Vignesh; Nikhil Reddy Avthu,2023 International Conference on Computer Communication and Informatics (ICCCI),2023,,,6-Jan,IEEE,10.1109/iccci56745.2023.10128286,https://doi.org/10.1109/iccci56745.2023.10128286,proceedings-article,Semantic Scholar,high,"Cost, Resource Management","autoscaling, performance optimization, serverless, cloud computing, load balancing, reinforcement learning",Novel approach to serverless computing challenges,Not explicitly mentioned
paper_125,Cost efficiency under mixed serverless and serverful deployments,"Function as a Service (FaaS) is an integral part of the serverless computing paradigm. It offers a true pay-per-use billing model and releases developers from the burden of managing the application stack. A discussion on whether and when this model is more appropriate for cloud computing users in terms of accruing costs compared to the more ""traditional"" delivery models has already been started by existing works. However, by treating this subject as a regular service selection problem, these approaches fail to exploit the space created by distributing the load between simultaneous FaaS and non-FaaS deployments of an application in a hybrid deployment model. This work aims to provide the means for application owners to decide which deployment scenario is cost optimal for their needs. In case this scenario is a hybrid deployment, the proposed approach also determines the optimal number of virtual machines that will need to be provisioned. An extensible and configurable FaasSimulator open source tool is presented for these purposes.",Anja Reuter; Timon Back; Vasilios Andrikopoulos,2020 46th Euromicro Conference on Software Engineering and Advanced Applications (SEAA),2020,,,,IEEE,10.1109/seaa51224.2020.00049,https://doi.org/10.1109/seaa51224.2020.00049,proceedings-article,Semantic Scholar,high,"Cost, Energy Consumption","serverless, cloud computing, reinforcement learning",Approach also determines the optimal number of virtual machines that will need to be provisioned,"By treating this subject as a regular service selection problem, these approaches fail to exploit the space created by distributing the load between simultaneous faas and non-faas deployments of an application in a hybrid deployment model"
paper_126,Cost Minimization in Serverless Computing with Energy Harvesting SECs,"With an increasing number of Mobile Users (MUs), Multi-access edge computing (MEC) has become a bottleneck in resource limitation. Serverless edge computing (SEC) is a promising approach to effectively alleviate the shortage of MEC. However, existing research on SEC focus on the operating mode of the SEC server, they ignore the interaction between SEC and MU. To this end, we propose a Stackelberg game approach to maximize the utility of each MU. We present the model of the Stackelberg game and propose an iterative algorithm as the solution. We also consider the impact of the function resource pool and using renewable energy on SEC. In particular, when a function that required by a MU is not stored in this SEC, it downloads the function from could with extra cost. Meanwhile, the SEC has a lower cost by using harvested energy rather than purchasing from the grid. Simulation results show that the proposed scheme is efficient in terms of SEC’s profit and MU’s demand. Moreover, both MUs and SECs gain benefits from renewable energy.",Yunqi Li; Jing Liu; Bin Jiang; Changlin Yang; Qingtian Wang,2023 IEEE International Symposium on Broadband Multimedia Systems and Broadcasting (BMSB),2023,,,7-Jan,IEEE,10.1109/bmsb58369.2023.10211170,https://doi.org/10.1109/bmsb58369.2023.10211170,proceedings-article,Semantic Scholar,high,"Cost, Energy Consumption, Resource Management","serverless, energy efficiency, reinforcement learning",A stackelberg game approach to maximize the utility of each mu; The model of the stackelberg game and propose an iterative algorithm as the solution; Scheme is efficient in terms of sec’s profit and mu’s demand,"Existing research on sec focus on the operating mode of the sec server, they ignore the interaction between sec and mu"
paper_127,Leveraging Serverless Computing for Scalable and Cost-Effective Architectures,"Serverless computing heralds a new way of designing applications as the application developers are relieved of the task of having to deal with servers. This
paradigm allows scalability, economy, and virtually effortless management of the system through the utilization of event-driven, stateless functions. The
architecture of serverless computing is well-aligned with microservices, where applications are broken down into small, fine-grained services that self-scale
according to the traffic. The advantages of this model include a lack of scale-up requirements, a lack of over-provisioning, and, more importantly, the payper-go concept, which makes operations much cheaper. The serverless approach not only reduces resource complexity but also provides flexibility since
it reduces the time required to deploy features by organizations. However, there are problems like using only one vendor’s services, security issues, or the
division of functions between services for which solutions have to be found for the best application of microservices. This work examines the nature of
serverless computing and its effects on the current adaptive architectures of microservices and cloud-native. Then, it discusses how serverless architecture
creates system flexibility, reduces cost, and benefits from development flexibility. Further, the literature review explores the prospect of serverless computing
for enterprise applications and the resulting patterns of adoption and scalability, as well as the economic model of serverless computing itself. By so doing,
the research hopes to offer potential insights into how serverless computing can transform application development, enabling organizations to deliver more
efficient and scalable solutions. Therefore, the research findings provide insight into the discussion on serverless computing and its relevance for defining
the further development of cloud architectures.",Ashwin Chavan,Journal of Artificial Intelligence &amp; Cloud Computing,2022,,,10-Jan,Scientific Research and Community Ltd,10.47363/jaicc/2022(1)e265,https://doi.org/10.47363/jaicc/2022(1)e265,journal-article,Semantic Scholar,high,"Survey, Reliability Security Privacy, Cost, Resource Management","serverless, microservices, cloud computing, reinforcement learning",Serverless computing heralds a new way of designing applications as the application developers are relieved of the task of having to deal with servers,"There are problems like using only one vendor’s services, security issues, or the
division of functions between services for which solutions have to be found for the best application of microservices; Also provides flexibility since
it reduces the time required to deploy features by organizations"
paper_128,Time‐cost efficient memory configuration for serverless workflow applications,"Recently, workflow applications are increasingly migrated to Function‐as‐a‐Service platforms which are easy to manage, highly‐scalable, and pay‐as‐you‐go. Meanwhile, users face challenges in migration of serverless applications because of the lack of efficient algorithm for workflow memory configuration to optimize the performance. To this end, this article proposes a heuristic urgency‐based algorithm UWC and a meta‐heuristic hybrid algorithm BPSO to tackle the time‐cost tradeoff. UWC sorts functions and allocates each function an appropriate memory size by greedy strategy. BPSO hybridizes particle swarm optimization as well as beetle antennae search algorithm to guide particles to search directionally and utilizes nonlinear inertia weight to avoid local premature convergence. Extensive experiments with classical serverless application demonstrate that UWC and BPSO are very competitive in comparison with existing algorithms as they can find the optimal workflow memory configuration.",Zengpeng Li; Huiqun Yu; Guisheng Fan,Concurrency and Computation: Practice and Experience,2022,34,27,,Wiley,10.1002/cpe.7308,https://doi.org/10.1002/cpe.7308,journal-article,Semantic Scholar,high,"Survey, Cost","performance optimization, serverless, reinforcement learning, memory management","To this end, this article proposes a heuristic urgency‐based algorithm uwc and a meta‐heuristic hybrid algorithm bpso to tackle the time‐cost tradeoff",In migration of serverless applications because of the lack of efficient algorithm for workflow memory configuration to optimize the performance
paper_129,A Survey of Cost Optimization in Serverless Cloud Computing,"Recently serverless cloud computing which was proposed by Amazon in 2015 is getting more favored by developers because of its charging model of pay-by-usage, applicability for fine-grained services and transparency of the servers to developers. Although a lot of study has proved that the performance and cost of serverless platform is more ideal than the traditional cloud computing service, the new metering model of serverless which depends on execution time, usage count and memory footprint is still unfamiliar to most developers and researchers. In this paper, we firstly make an introduction to the new metering model and the advantages of serverless over traditional cloud services. Then according to the cost affecting factors, we make a comprehensive survey of some constraints that mainly impact the cost of serverless and related methods to reduce cost in three levels—function level, container level and cloud platform level. Based on the analysis, we also propose some directions worthy of in-depth study in the future.",Zhe Li; Yusong Tan; Bao Li; Jianfeng Zhang; Xiaochuan Wang,Journal of Physics: Conference Series,2021,1802,3,32070,IOP Publishing,10.1088/1742-6596/1802/3/032070,https://doi.org/10.1088/1742-6596/1802/3/032070,journal-article,Semantic Scholar,high,"Survey, Latency, Cost","performance optimization, serverless, containerization, cloud computing, reinforcement learning, memory management","Recently serverless cloud computing which was proposed by amazon in 2015 is getting more favored by developers because of its charging model of pay-by-usage, applicability for fine-grained services and transparency of the servers to developers","That mainly impact the cost of serverless and related methods to reduce cost in three levels—function level, container level and cloud platform level; A lot of study has proved that the performance and cost of serverless platform is more ideal than the traditional cloud computing service, the new metering model of serverless which depends on execution time, usage count and memory footprint is still unfamiliar to most developers and researchers"
paper_130,Cost-efficiency and Performance Robustness in Serverless Data Exchange,"Enterprises increasingly store their sporadically used data on cheap, elastic cloud storage to save costs. Analytical workloads on that data often appear in infrequent bursts presenting a high disparity in input data sizes. Using conservatively over-provisioned compute resources for this class of workloads is not cost-efficient as a fixed amount of resources only matches steady demand. Elastic query processors with a serverless architecture resolve this issue by running workers in cloud functions [3][9][10]. These systems can start thousands of functions within seconds, enabling elasticity down to query pipeline granularity. Moreover, serverless query processors come at no cost for idle times.",David Justen,Proceedings of the 2022 International Conference on Management of Data,2022,,,2506-2508,ACM,10.1145/3514221.3520248,https://doi.org/10.1145/3514221.3520248,proceedings-article,Semantic Scholar,high,"Cost, Energy Consumption, Resource Management","serverless, cloud computing, elasticity, reinforcement learning, cpu allocation",Analytical workloads on that data often appear in infrequent bursts presenting a high disparity in input data sizes,By running workers in cloud functions [3][9][10]
paper_131,XFaaS: Hyperscale and Low Cost Serverless Functions at Meta,"Function-as-a-Service (FaaS) has become a popular programming paradigm in Serverless Computing. As the responsibility of resource provisioning shifts from users to cloud providers, the ease of use of FaaS for users may come at the expense of extra hardware costs for cloud providers. Currently, there is no report on how FaaS platforms address this challenge and the level of hardware utilization they achieve. This paper presents the FaaS platform called XFaaS in Meta's hyperscale private cloud. XFaaS currently processes trillions of function calls per day on more than 100,000 servers. We describe a set of optimizations that help XFaaS achieve a daily average CPU utilization of 66%. Based on our anecdotal knowledge, this level of utilization might be several times higher than that of typical FaaS platforms. Specifically, to eliminate the cold start time of functions, XFaaS strives to approximate the effect that every worker can execute every function immediately. To handle load spikes without over-provisioning resources, XFaaS defers the execution of delay-tolerant functions to off-peak hours and globally dispatches function calls across datacenter regions. To prevent functions from overloading downstream services, XFaaS uses a TCP-like congestion-control mechanism to pace the execution of functions.",Alireza Sahraei; Soteris Demetriou; Amirali Sobhgol; Haoran Zhang; Abhigna Nagaraja; Neeraj Pathak; Girish Joshi; Carla Souza; Bo Huang; Wyatt Cook; Andrii Golovei; Pradeep Venkat; Andrew Mcfague; Dimitrios Skarlatos; Vipul Patel; Ravinder Thind; Ernesto Gonzalez; Yun Jin; Chunqiang Tang,Proceedings of the 29th Symposium on Operating Systems Principles,2023,,,231-246,ACM,10.1145/3600006.3613155,https://doi.org/10.1145/3600006.3613155,proceedings-article,Semantic Scholar,high,"Latency, Cost, Resource Management","cold start, performance optimization, serverless, cloud computing, latency, reinforcement learning, cpu allocation",The faas platform called xfaas in meta's hyperscale private cloud,And the level of hardware utilization they achieve
paper_132,Cost-effective Deployment of BERT Models in Serverless Environment,"In this study, we demonstrate the viability of deploying BERT-style models to AWS Lambda in a production environment. Since the freely available pre-trained models are too large to be deployed in this environment, we utilize knowledge distillation and fine-tune the models on proprietary datasets for two real-world tasks: sentiment analysis and semantic textual similarity. As a result, we obtain models that are tuned for a specific domain and deployable in the serverless environment. The subsequent performance analysis shows that this solution does not only report latency levels acceptable for production use but that it is also a cost-effective alternative to small-to-medium size deployments of BERT models, all without any infrastructure overhead.",Marek Suppa; Katarína Benešová; Andrej Švec,Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies: Industry Papers,2021,,,187-195,Association for Computational Linguistics,10.18653/v1/2021.naacl-industry.24,https://doi.org/10.18653/v1/2021.naacl-industry.24,proceedings-article,Semantic Scholar,high,"Survey, Latency, Cost","serverless, latency, reinforcement learning",Novel approach to serverless computing challenges,"That it is also a cost-effective alternative to small-to-medium size deployments of bert models, all without any infrastructure overhead"
paper_133,ACTS: Autonomous Cost-Efficient Task Orchestration for Serverless Analytics,"Serverless computing has become increasingly popular for cloud applications, due to its compelling properties of high-level abstractions, lightweight runtime, high elasticity and pay-per-use billing. In this revolutionary computing paradigm shift, challenges arise when adapting data analytics applications to the serverless environment, due to the lack of support for efficient state sharing, which attract ever-growing research attention. In this paper, we aim to exploit the advantages of task-level orchestration and fine-grained resource provisioning for data analytics on serverless platforms, with the hope of fulfilling the promise of serverless deployment to the maximum extent. To this end, we present ACTS, an autonomous cost-efficient task orchestration framework for serverless analytics. ACTS judiciously schedules and coordinates function tasks to mitigate cold-start latency and state sharing overhead. In addition, ACTS explores the optimization space of fine-grained workload distribution and function resource configuration for cost efficiency. We have deployed and implemented ACTS on AWS Lambda, evaluated with various data analytics workloads. Results from extensive experiments demonstrate that ACTS achieves up to 98% monetary cost reduction while maintaining superior job completion time performance, in comparison with the state-of-the-art baselines.",Jananie Jarachanthan; Li Chen; Fei Xu,2023 IEEE/ACM 31st International Symposium on Quality of Service (IWQoS),2023,,,10-Jan,IEEE,10.1109/iwqos57198.2023.10188782,https://doi.org/10.1109/iwqos57198.2023.10188782,proceedings-article,Semantic Scholar,high,"Survey, Latency, Cost, Energy Consumption, Resource Management","cold start, performance optimization, serverless, cloud computing, latency, elasticity, load balancing, reinforcement learning","Acts, an autonomous cost-efficient task orchestration framework for serverless analytics; 98% monetary","Arise when adapting data analytics applications to the serverless environment, due to the lack of support for efficient state sharing, which attract ever-growing research attention"
paper_134,MLLess: Achieving cost efficiency in serverless machine learning training,"Function-as-a-Service (FaaS) has raised a growing interest in how to ""tame""
serverless computing to enable domain-specific use cases such as data-intensive
applications and machine learning (ML), to name a few. Recently, several
systems have been implemented for training ML models. Certainly, these research
articles are significant steps in the correct direction. However, they do not
completely answer the nagging question of when serverless ML training can be
more cost-effective compared to traditional ""serverful"" computing. To help in
this endeavor, we propose MLLess, a FaaS-based ML training prototype built atop
IBM Cloud Functions. To boost cost-efficiency, MLLess implements two innovative
optimizations tailored to the traits of serverless computing: on one hand, a
significance filter, to make indirect communication more effective, and on the
other hand, a scale-in auto-tuner, to reduce cost by benefiting from the FaaS
sub-second billing model (often per 100ms). Our results certify that MLLess can
be 15X faster than serverful ML systems at a lower cost for sparse ML models
that exhibit fast convergence such as sparse logistic regression and matrix
factorization. Furthermore, our results show that MLLess can easily scale out
to increasingly large fleets of serverless workers.",Pablo Gimeno Sarroca; Marc Sánchez-Artigas,Journal of Parallel and Distributed Computing,2024,183,,104764,Elsevier BV,10.1016/j.jpdc.2023.104764,https://doi.org/10.1016/j.jpdc.2023.104764,journal-article,arXiv,high,"Cost, Energy Consumption","performance optimization, serverless, cloud computing, reinforcement learning","Mlless, a faas-based ml training prototype built atop
ibm cloud functions","They do not
completely answer the nagging question of when serverless ml training can be
more cost-effective compared to traditional ""serverful"" computing"
paper_135,Scalable and Cost-effective Serverless Architecture for Information Extraction Workflows,"Information extraction from an image or scanned document is a complex and challenging process since it involves recognizing various visual structures such as tables, boxes, logos, text, charts, etc. Hence, the content extraction applications contain a pipeline of multiple computer vision algorithms, APIs, and models. Deploying such applications for document processing requires a resilient system to deliver high performance. Such applications can be deployed on cloud to leverage the flexible infrastructure and multiple supporting services available there. In this paper, we discuss a scalable and high performance architecture using a serverless platform for deploying information extraction workflows consisting of multiple APIs and computer vision models. Our experiments show that the use of a serverless platform results in a scalable, cost-effective, and low latency deployment of such workflows. Moreover, we discuss the performance and cost trade-offs while choosing cloud services and their configuration. We also show that the use of workload characterization-based performance and cost models to find the optimal serverless instance configuration results in a significant deployment cost reduction.",Dheeraj Chahal; Surya Chaitanya Palepu; Rekha Singhal,Proceedings of the 2nd Workshop on High Performance Serverless Computing,2022,,,15-23,ACM,10.1145/3526060.3535458,https://doi.org/10.1145/3526060.3535458,proceedings-article,Semantic Scholar,high,"Latency, Cost","serverless, cloud computing, latency, reinforcement learning",Novel approach to serverless computing challenges,"And challenging process since it involves recognizing various visual structures such as tables, boxes, logos, text, charts, etc"
paper_136,Cost-Effective Scaling of Machine Learning Model using Serverless Architecture,"Machine learning algorithms are resource intensive processes that require large computing resources. The increasing demand for these resources has highlighted the need for a cost-effective solution in the domain of cloud computing. Traditional systems require manual monitoring and updating of servers and have fixed resources allocated to them that leads to higher costs and underutilization of resources. Serverless architectures like AWS Lambda offer an efficient way for the dynamic scaling of machine learning model deployments without the need for a dedicated team managing servers. Servers are scaled automatically based on traffic and load that results in efficient resource utilization. The study demonstrates how serverless architecture can be utilized for cost-efficient scaling of machine learning deployments, especially for the MNIST dataset. The goal is to compare the performance and cost-efficiency of traditional deployment techniques with serverless architecture. By analyzing key performance metrics like latency, cost per invocation, and resource utilization, the study aims to highlight the advantages of a serverless architecture in handling dynamic user loads. Serverless functions have been found to reduce costs significantly by scaling models layers independently while maintaining the performance of the model. The research also identifies the scenarios where serverless architecture outperforms traditional deployment methods in terms of cost and flexibility.",Premanand Ghadekar; Nandini Gulhane; Harsh Patil; Ishita Ramdasi; Gaurav Hote; Siddhant Ghodke,2025 Third International Conference on Augmented Intelligence and Sustainable Systems (ICAISS),2025,,,964-970,IEEE,10.1109/icaiss61471.2025.11041847,https://doi.org/10.1109/icaiss61471.2025.11041847,proceedings-article,Semantic Scholar,high,"Latency, Cost, Energy Consumption, Resource Management","autoscaling, serverless, cloud computing, latency, reinforcement learning, monitoring",Novel approach to serverless computing challenges,Not explicitly mentioned
paper_137,DeepBAT: Performance and Cost Optimization of Serverless Inference Using Transformers,"Serverless computing is an autoscaling pay-as-yougo paradigm that can efficiently support machine learning inference especially under bursty workload conditions. Within the serverless paradigm, batching ML inference requests before serving them is widely adopted. Thanks to its parallelism properties, batching can highly improve inference performance while reducing the monetary cost of serverless. Identifying the correct serverless parameterization to simultaneously meet conflicting targets (i.e., keep monetary cost at a minimum while meeting pre-defined service level objectives, SLO) may be cast as a resource allocation problem. In this paper, we illustrate that a deep surrogate model can quickly discover optimized serverless configurations by learning the relationship among the workload patterns and achieve performance measures. We develop DeepBAT, an SLO-aware framework that leverages the Transformer encoder and multi-head attention mechanism to optimize the performance of serverless inference subject to bursty and previously unobserved workloads. We illustrate the effectiveness of DeepBAT on a set of case studies and show that for the problem of inference serving on AWS Lambda, DeepBAT can speed up the solution time of state-of-the-art analytic solutions by over 55 times while generalizing remarkably well on unseen workloads.",Bowen Sun; Riccardo Pinciroli; Giuliano Casale; Evgenia Smirni,2025 IEEE International Parallel and Distributed Processing Symposium (IPDPS),2025,,,335-346,IEEE,10.1109/ipdps64566.2025.00037,https://doi.org/10.1109/ipdps64566.2025.00037,proceedings-article,Semantic Scholar,high,"Cost, Resource Management","autoscaling, resource management, performance optimization, serverless, reinforcement learning","Deepbat, an slo-aware framework that leverages the transformer encoder and multi-head attention mechanism to optimize the performance of serverless inference subject to bursty and previously unobserved workloads","Of inference serving on aws lambda, deepbat can speed up the solution time of state-of-the-art analytic solutions by over 55 times while generalizing remarkably well on unseen workloads"
paper_138,Towards a Scalable and Cost Efficient Serverless Scheduler for Dask,"HPC workflows run either on supercomputers, shared through queues, or Cloud virtual machines, allocated for the experiment. Both options are ill-suited for exploration scenarios, where the user explores the dataset by applying small computations to parts of a much bigger dataset and analyzing the result, either because of the queue time present on supercomputers or costs generated even when idle on traditional IaaS cloud offerings. We propose FaaS-Dask, a runtime for Dask that is capable of running on FaaS offerings, providing the same tailored experience as cloud virtual machines but billing only for executed computation. We will explore current FaaS challenges and optimizations available, and compare execution on our environment with traditional cloud Dask clusters, showing that FaaS-Dask is cheaper in some scenarios, but there is still work to be done to make it as fast as current options.",Carlos Eduardo Millani; Carlos A. Astudillo; Edson Borin,2024 IEEE/ACM 17th International Conference on Utility and Cloud Computing (UCC),2024,,,366-371,IEEE,10.1109/ucc63386.2024.00057,https://doi.org/10.1109/ucc63386.2024.00057,proceedings-article,Semantic Scholar,high,Cost,"performance optimization, serverless, cloud computing, queuing, reinforcement learning, distributed systems","Faas-dask, a runtime for dask that is capable of running on faas offerings, providing the same tailored experience as cloud virtual machines but billing only for executed computation","And optimizations available, and compare execution on our environment with traditional cloud dask clusters, showing that faas-dask is cheaper in some scenarios, but there is still work to be done to make it as fast as current options; Billing only for executed computation"
paper_139,An Efficient Serverless-VM Switching Mechanism for Cloud Cost Optimization,"This research introduces an efficient switching mechanism between serverless architecture and traditional Virtual Machines within a cloud environment. Serverless computing, especially Function-as-a-Service, is gaining prominence due to its scalability, flexibility, and cost-effectiveness. This study presents a methodology that leverages the strengths of both serverless architecture and VMs to minimize operational costs and optimize performance. In this paper, to combines the benefits of serverless computing and VMs to enhance the utilization of cloud resources for switching mechanism. The algorithm promotes efficient resource allocation based on various metrics, including traffic load, cost, and execution time. Additionally, we employ a PID controller for facilitating seamless transitions between serverless and VM environments. Through in-depth analysis using large-scale data processing scenarios, we demonstrate how adopting a serverless architecture can lead to cost savings and improved resource utilization.",Seol Roh; Hong-Ju Jeong; Hacksung Boo; Eui-Nam Huh,Proceedings of the 2024 9th International Conference on Intelligent Information Technology,2024,,,482-486,ACM,10.1145/3654522.3654594,https://doi.org/10.1145/3654522.3654594,proceedings-article,Semantic Scholar,high,"Survey, Latency, Cost, Resource Management","resource management, performance optimization, serverless, cloud computing, reinforcement learning",This research introduces an efficient switching mechanism between serverless architecture and traditional virtual machines within a cloud environment,Not explicitly mentioned
paper_140,Predicting Performance and Cost of Serverless Computing Functions with SAAF,"Next generation software built for the cloud recently has embraced serverless computing platforms that use temporary infrastructure to host microservices offering building blocks for resilient, loosely coupled systems that are scalable, easy to manage, and extend. Serverless architectures enable decomposing software into independent components packaged and run using isolated containers or microVMs. This decomposition approach enables application hosting using very fine-grained cloud infrastructure enabling cost savings as deployments are billed granularly for resource use. Adoption of serverless platforms promise reduced hosting costs while achieving high availability, fault tolerance, and dynamic elasticity. These benefits are offset by pricing obfuscation, as performance variance from CPU heterogeneity, multitenancy, and provisioning variation obscure the true cost of hosting applications with serverless platforms. Where determining hosting costs for traditional VM-based application deployments simply involves accounting for the number of VMs and their uptime, predicting hosting costs for serverless applications can be far more complex. To address these challenges, we introduce the Serverless Application Analytics Framework (SAAF), a tool that allows profiling FaaS workload performance, resource utilization, and infrastructure to enable accurate performance predictions. We apply Linux CPU time accounting principles and multiple regression to estimate FaaS function runtime. We predict runtime using a series of increasingly variant compute bound workloads that execute across heterogeneous CPUs, different memory settings, and to alternate FaaS platforms evaluating our approach for 77 different scenarios. We found that the mean absolute percentage error of our runtime predictions for these scenarios was just ~3.49% resulting in an average cost error of $6.46 for 1-million FaaS function workloads averaging $150.45 in price.",Robert Cordingly; Wen Shu; Wes J. Lloyd,"2020 IEEE Intl Conf on Dependable, Autonomic and Secure Computing, Intl Conf on Pervasive Intelligence and Computing, Intl Conf on Cloud and Big Data Computing, Intl Conf on Cyber Science and Technology Congress (DASC/PiCom/CBDCom/CyberSciTech)",2020,,,640-649,IEEE,10.1109/dasc-picom-cbdcom-cyberscitech49142.2020.00111,https://doi.org/10.1109/dasc-picom-cbdcom-cyberscitech49142.2020.00111,proceedings-article,Semantic Scholar,high,"Reliability Security Privacy, Cost, Resource Management","serverless, containerization, microservices, cloud computing, elasticity, reinforcement learning, prediction, memory management, cpu allocation","The serverless application analytics framework (saaf), a tool that allows profiling faas workload performance, resource utilization, and infrastructure to enable accurate performance predictions; For 77 different scenarios",Not explicitly mentioned
paper_141,Astra: Autonomous Serverless Analytics with Cost-Efficiency and QoS-Awareness,"With the ability to simplify the code deployment with one-click upload and lightweight execution, serverless computing has emerged as a promising paradigm with increasing popularity. However, there remain open challenges when adapting data-intensive analytics applications to the serverless context, in which users of serverless analytics encounter with the difficulty in coordinating computation across different stages and provisioning resources in a large configuration space. This paper presents our design and implementation of Astra, which configures and orchestrates serverless analytics jobs in an autonomous manner, while taking into account flexibly-specified user requirements. Astra relies on the modeling of performance and cost which characterizes the intricate interplay among multi-dimensional factors (e.g., function memory size, degree of parallelism at each stage). We formulate an optimization problem based on user-specific requirements towards performance enhancement or cost reduction, and develop a set of algorithms based on graph theory to obtain optimal job execution. We deploy Astra in the AWS Lambda platform and conduct real-world experiments over three representative benchmarks with different scales. Results demonstrate that Astra can achieve the optimal execution decision for serverless analytics, by improving the performance of 21% to 60% under a given budget constraint, and resulting in a cost reduction of 20% to 80% without violating performance requirement, when compared with three baseline configuration algorithms.",Jananie Jarachanthan; Li Chen; Fei Xu; Bo Li,2021 IEEE International Parallel and Distributed Processing Symposium (IPDPS),2021,,,756-765,IEEE,10.1109/ipdps49936.2021.00085,https://doi.org/10.1109/ipdps49936.2021.00085,proceedings-article,Semantic Scholar,high,"Survey, QoS, Cost, Energy Consumption, Resource Management","performance optimization, serverless, reinforcement learning, memory management","Our design and implementation of astra, which configures and orchestrates serverless analytics jobs in an autonomous manner, while taking into account flexibly-specified user requirements","When adapting data-intensive analytics applications to the serverless context, in which users of serverless analytics encounter with the difficulty in coordinating computation across different stages and provisioning resources in a large configuration space; There remain open challenges when adapting data-intensive analytics applications to the serverless context, in which users of serverless analytics encounter with the difficulty in coordinating computation across different stages and provisioning resources in a large configuration space"
paper_142,Modeling and Optimization of Performance and Cost of Serverless Applications,"Function-as-a-Service (FaaS) and serverless applications have proliferated significantly in recent years because of their high scalability, ease of resource management, and pay-as-you-go pricing model. However, cloud users are facing practical problems when they migrate their applications to the serverless pattern, which are the lack of analytical performance and billing model and the trade-off between limited budget and the desired quality of service of serverless applications. In this article, we fill this gap by proposing and answering two research questions regarding the prediction and optimization of performance and cost of serverless applications. We propose a new construct to formally define a serverless application workflow, and then implement analytical models to predict the average end-to-end response time and the cost of the workflow. Consequently, we propose a heuristic algorithm named Probability Refined Critical Path Greedy algorithm (PRCP) with four greedy strategies to answer two fundamental optimization questions regarding the performance and the cost. We extensively evaluate the proposed models by conducting experimentation on AWS Lambda and Step Functions. Our analytical models can predict the performance and cost of serverless applications with more than 98 percent accuracy. The PRCP algorithms can achieve the optimal configurations of serverless applications with 97 percent accuracy on average.",Changyuan Lin; Hamzeh Khazaei,IEEE Transactions on Parallel and Distributed Systems,2021,32,3,615-632,Institute of Electrical and Electronics Engineers (IEEE),10.1109/tpds.2020.3028841,https://doi.org/10.1109/tpds.2020.3028841,journal-article,Semantic Scholar,high,"Latency, QoS, Cost, Resource Management","resource management, performance optimization, serverless, cloud computing, reinforcement learning, prediction","A new construct to formally define a serverless application workflow, and then implement analytical models to predict the average end-to-end response time and the cost of the workflow; A heuristic algorithm named probability refined critical path greedy algorithm (prcp) with four greedy strategies to answer two fundamental optimization questions regarding the performance and the cost; Models by conducting experimentation on aws lambda and step functions","Cloud users are facing practical problems when they migrate their applications to the serverless pattern, which are the lack of analytical performance and billing model and the trade-off between limited budget and the desired quality of service of serverless applications; When they migrate their applications to the serverless pattern, which are the lack of analytical performance and billing model and the trade-off between limited budget and the desired quality of service of serverless applications"
paper_143,PULSE: Using Mixed-Quality Models for Reducing Serverless Keep-Alive Cost,"This paper addresses a key challenge with using serverless computing for machine learning (ML) inference which is cold starts that occur during initial invocations and container inactivity. Fixed keep-alive policies, like the commonly adopted 10-minute strategy, have been implemented by cloud providers to alleviate cold start issues. However, the substantial size of ML models poses a significant hurdle, leading to elevated keep-alive costs and potential strain on system resources. In response to these challenges, we introduce PULSE, a dynamic 10-minute keep-alive mechanism that employs ML model variants to optimize the balance between keep-alive costs, accuracy, and service time while avoiding peaks in keep-alive memory consumption. Our evaluation, using real-world serverless workloads and commonly used machine learning models, demonstrates reduced keep-alive costs compared to the fixed policy. Additionally, we observe that integrating PULSE improves the performance of existing state-of-the-art serverless function warm-up strategies.",Kausalya Sankaranarayanan; Rohan Basu Roy; Devesh Tiwari,"SC24-W: Workshops of the International Conference for High Performance Computing, Networking, Storage and Analysis",2024,,,99-109,IEEE,10.1109/scw63240.2024.00021,https://doi.org/10.1109/scw63240.2024.00021,proceedings-article,Semantic Scholar,high,"Survey, Latency, Cost, Energy Consumption, Resource Management","cold start, serverless, containerization, cloud computing, reinforcement learning, memory management","Pulse, a dynamic 10-minute keep-alive mechanism that employs ml model variants to optimize the balance between keep-alive costs, accuracy, and service time while avoiding peaks in keep-alive memory consumption","With using serverless computing for machine learning (ml) inference which is cold starts that occur during initial invocations and container inactivity; The substantial size of ml models poses a significant hurdle, leading to elevated keep-alive costs and potential strain on system resources"
paper_144,Demystifying the Cost of Serverless Computing: Towards a Win-Win Deal,"Serverless is an emerging computing paradigm that greatly simplifies the development, deployment, and maintenance of cloud applications. However, due to potential cost issues brought by the widely adopted pricing, it is difficult to answer how to use and operate serverless computing services from the perspectives of users and providers. To demystify the cost of serverless computing, we present one of the first studies that develops an analytical model for serverless cost from the perspectives of users and providers, by comparing it to Infrastructure-as-a-Service. Based on the model, driven by real-world traces, extensive simulation results verify the following cost issues: 1) For the users, serverless is not always cost-saving, even possibly leading to expense explosion; 2) The serverless providers are in urgent need of widening use scenarios to improve resource utilization and raise revenue; 3) The prevailing pricing fails to neither reduce the risk of expense explosion nor meet the need of attracting more workloads. To remove the cost barrier, we propose future function, auction-based pricing for serverless, to offer discounts to the users as well as boost profit for the providers. Experimental results show the duration price of functions can be reduced by 57.5% on average for 13.5% of users yet without harming the revenue of providers.",Fangming Liu; Yipei Niu,IEEE Transactions on Parallel and Distributed Systems,2024,35,1,59-72,Institute of Electrical and Electronics Engineers (IEEE),10.1109/tpds.2023.3330849,https://doi.org/10.1109/tpds.2023.3330849,journal-article,Semantic Scholar,high,"Cost, Resource Management","serverless, cloud computing, reinforcement learning","Future function, auction-based pricing for serverless, to offer discounts to the users as well as boost profit for the providers; One of the first studies that develops an analytical model for serverless cost from the perspectives of users and providers, by comparing it to infrastructure-as-a-service","Due to potential cost issues brought by the widely adopted pricing, it is difficult to answer how to use and operate serverless computing services from the perspectives of users and providers; Brought by the widely adopted pricing, it is difficult to answer how to use and operate serverless computing services from the perspectives of users and providers"
paper_145,Costless: Optimizing Cost of Serverless Computing through Function Fusion and Placement,"Serverless computing has recently experienced significant adoption by several applications, especially Internet of Things (IoT) applications. In serverless computing, rather than deploying and managing dedicated virtual machines, users are able to deploy individual functions, and pay only for the time that their code is actually executing. However, since serverless platforms are relatively new, they have a completely different pricing model that depends on the memory, duration, and the number of executions of a sequence/workflow of functions. In this paper we present an algorithm that optimizes the price of serverless applications in AWS Lambda. We first describe the factors affecting price of serverless applications which include: (1) fusing a sequence of functions, (2) splitting functions across edge and cloud resources, and (3) allocating the memory for each function. We then present an efficient algorithm to explore different function fusion-placement solutions and find the solution that optimizes the application's price while keeping the latency under a certain threshold. Our results on image processing workflows show that the algorithm can find solutions optimizing the price by more than 35%-57% with only 5%-15% increase in latency. We also show that our algorithm can find non-trivial memory configurations that reduce both latency and price.",Tarek Elgamal; Atul Sandur; Klara Nahrstedt; Gul Agha,2018 IEEE/ACM Symposium on Edge Computing (SEC),2018,,,300-312,IEEE,10.1109/sec.2018.00029,https://doi.org/10.1109/sec.2018.00029,proceedings-article,Semantic Scholar,high,"Latency, Cost, Resource Management","function placement, serverless, cloud computing, latency, reinforcement learning, memory management",An algorithm that optimizes the price of serverless applications in aws lambda; Can find non-trivial memory configurations that reduce both latency and price; 15% increase,"Since serverless platforms are relatively new, they have a completely different pricing model that depends on the memory, duration, and the number of executions of a sequence/workflow of functions"
paper_146,AMPS-Inf: Automatic Model Partitioning for Serverless Inference with Cost Efficiency,"The salient pay-per-use nature of serverless computing has driven its continuous penetration as an alternative computing paradigm for various workloads. Yet, challenges arise and remain open when shifting machine learning workloads to the serverless environment. Specifically, the restriction on the deployment size over serverless platforms combining with the complexity of neural network models makes it difficult to deploy large models in a single serverless function. In this paper, we aim to fully exploit the advantages of the serverless computing paradigm for machine learning workloads targeting at mitigating management and overall cost while meeting the response-time Service Level Objective (SLO). We design and implement AMPS-Inf, an autonomous framework customized for model inferencing in serverless computing. Driven by the cost-efficiency and timely-response, our proposed AMPS-Inf automatically generates the optimal execution and resource provisioning plans for inference workloads. The core of AMPS-Inf relies on the formulation and solution of a Mixed-Integer Quadratic Programming problem for model partitioning and resource provisioning with the objective of minimizing cost without violating response time SLO. We deploy AMPS-Inf on the AWS Lambda platform, evaluate with the state-of-the-art pre-trained models in Keras including ResNet50, Inception-V3 and Xception, and compare with Amazon SageMaker and three baselines. Experimental results demonstrate that AMPS-Inf achieves up to 98% cost saving without degrading response time performance.",Jananie Jarachanthan; Li Chen; Fei Xu; Bo Li,50th International Conference on Parallel Processing,2021,,,12-Jan,ACM,10.1145/3472456.3472501,https://doi.org/10.1145/3472456.3472501,proceedings-article,Semantic Scholar,high,"Latency, Cost, Energy Consumption, Resource Management","serverless, reinforcement learning, deep learning","And implement amps-inf, an autonomous framework customized for model inferencing in serverless computing; 98% cost",Arise and remain open when shifting machine learning workloads to the serverless environment; For model partitioning and resource provisioning with the objective of minimizing cost without violating response time slo
paper_147,Cost-Efficient Serverless Inference Serving with Joint Batching and Multi-Processing,"With the emerging of machine learning, many commercial companies increasingly utilize machine learning inference systems as backend services to improve their products. Serverless computing is a modern paradigm that provides auto-scaling, event-driven services, making it particularly well-suited for various domains, including video stream analysis, IoT serving and machine learning applications. The flexible scaling feature of serverless computing is adept at handling the burstiness of ML workloads. However, despite its compatibility with ML inference tasks, the cost of serverless inference systems remain relatively high in comparison to traditional serving paradigms, primarily due to the under-utilization of CPU resources offered by serverless platforms. To tackle this challenge, we design and deploy a serverless inference serving system that incorporates batching and multi-process mechanisms to enhance cost efficiency. By applying a change-point detection algorithm to manage bursty workloads, it optimizes resource usage and achieves lower costs. We employ an Amazon EC2 server for handling request packaging and running the core Bayesian Optimization algorithm without any prior information. The preliminary system, implemented on AWS Lambda, can significantly reduce expenses and save up to 62% compared to the original serverless inference system.",Shen Cai; Zhi Zhou; Kongyange Zhao; Xu Chen,Proceedings of the 14th ACM SIGOPS Asia-Pacific Workshop on Systems,2023,,,43-49,ACM,10.1145/3609510.3609816,https://doi.org/10.1145/3609510.3609816,proceedings-article,Semantic Scholar,high,"Survey, Cost, Energy Consumption, Resource Management","autoscaling, performance optimization, serverless, reinforcement learning, cpu allocation",And deploy a serverless inference serving system that incorporates batching and multi-process mechanisms to enhance cost efficiency; 62% compared,"Despite its compatibility with ml inference tasks, the cost of serverless inference systems remain relatively high in comparison to traditional serving paradigms, primarily due to the under-utilization of cpu resources offered by serverless platforms; Its compatibility with ml inference tasks, the cost of serverless inference systems remain relatively high in comparison to traditional serving paradigms, primarily due to the under-utilization of cpu resources offered by serverless platforms"
paper_148,Skedulix: Hybrid Cloud Scheduling for Cost-Efficient Execution of Serverless Applications,"We present a framework for scheduling multifunction serverless applications over a hybrid public-private cloud. A set of serverless jobs is input as a batch, and the objective is to schedule function executions over the hybrid platform to minimize the cost of public cloud use, while completing all jobs by a specified deadline. As this scheduling problem is NP-Hard, we propose a greedy algorithm that dynamically determines both the order and placement of each function execution using predictive models of function execution time and network latencies. We present a prototype implementation of our framework that uses AWS Lambda and OpenFaaS, for the public and private cloud, respectively. We evaluate our prototype in live experiments using a mixture of compute and I/O heavy serverless applications. Our results show that our framework can achieve a speedup in batch processing of up to 1.92 times that of an approach that uses only the private cloud, at 40.5% the cost of an approach that uses only the public cloud.",Anirban Das; Andrew Leaf; Carlos A. Varela; Stacy Patterson,2020 IEEE 13th International Conference on Cloud Computing (CLOUD),2020,,,609-618,IEEE,10.1109/cloud49709.2020.00090,https://doi.org/10.1109/cloud49709.2020.00090,proceedings-article,Semantic Scholar,high,"Latency, Cost, Resource Management","function placement, serverless, cloud computing, reinforcement learning, prediction, deadline","A greedy algorithm that dynamically determines both the order and placement of each function execution using predictive models of function execution time and network latencies; A framework for scheduling multifunction serverless applications over a hybrid public-private cloud; A prototype implementation of our framework that uses aws lambda and openfaas, for the public and private cloud, respectively","Is np-hard, we propose a greedy algorithm that dynamically determines both the order and placement of each function execution using predictive models of function execution time and network latencies"
paper_149,Towards Low-Cost Global Highly Available Large Container-Based Serverless Functions,"Serverless computing and the Function-as-a-Service (FaaS) paradigm have transformed how cloud-hosted applications are deployed, providing remarkable scalability and geo-graphical distribution capabilities. AWS Lambda's support for containerized functions has further enhanced the packaging and deployment process, enabling seamless portability and consis-tency across various operational environments. However, a fun-damental challenge remains: the replication of Docker container images across multiple container registries in different regions to ensure high availability of globally deployed functions with low replication latency to support geographically dispersed clients. While multi-region deployment minimizes latency and en-hances service availability for diverse clients, the associated costs and operational complexities are non-trivial. The replication process, particularly for large container images, is both expensive and slow, potentially hindering rapid scalability and respon-siveness. Public cloud container image replication support such as that offered by Amazon's Cross Region Replication (CRR) represents a significant stride forward, automating the replication of container images across regions within container repositories. Despite its advantages, CRR is constrained by several limitations: all images in a container repository are replicated after this feature is enabled, and there is an absence of fine-grained filtering at the image level within repositories. This can result in superfluous replications and increased costs. This paper investigates alternatives for cost-effective and effi-cient global deployment of container-based serverless functions on AWS Lambda. We introduce on-demand container image replication mechanisms with promise to reduce storage costs by avoiding unnecessary replication. We investigate multiple approaches to replicate container images only when needed to minimize data transfer latency and storage overhead. We provide a comprehensive evaluation of these approaches, assessing their impact on cost, replication time, and turnaround time for function availability. Our findings demonstrate potential for substantial cost savings while maintaining high availability and consistent performance for container-based Lambda functions deployed worldwide.",Jasleen Kaur; Robert Cordingly; Ling-Hong Hung; Wes Lloyd,2024 IEEE Cloud Summit,2024,,,12-Jul,IEEE,10.1109/cloud-summit61220.2024.00008,https://doi.org/10.1109/cloud-summit61220.2024.00008,proceedings-article,Semantic Scholar,high,"Survey, Latency, Reliability Security Privacy, Cost","serverless, containerization, cloud computing, latency, reinforcement learning",On-demand container image replication mechanisms with promise to reduce storage costs by avoiding unnecessary replication,Remains: the replication of docker container images across multiple container registries in different regions to ensure high availability of globally deployed functions with low replication latency to support geographically dispersed clients; A fun-damental challenge remains: the replication of docker container images across multiple container registries in different regions to ensure high availability of globally deployed functions with low replication latency to support geographically dispersed clients
paper_150,Shattering the Ephemeral Storage Cost Barrier for Data-Intensive Serverless Workflows,"Serverless computing enables developers to deploy applications as workflows of functions that invoke one another, with cloud providers handling autoscaling and routing. However, serverless platforms lack efficient mechanisms for cross-function data transfers, which hinders the performance of data-intensive applications. Current solutions rely on intermediary services like AWS S3 or ElastiCache(EC), leading to significant cost inefficiencies---storage costs can account for 24-99% of the total execution bill. Zipline addresses this challenge with a fast, API-compatible data communication method enabling direct function-to-function transfers. Zipline buffers data in the sender function's memory and transmits only the references to the dynamically selected receiver, which pulls the data directly from the sender's memory. While eliminating the need for intermediary services, it also integrates seamlessly with existing autoscaling infrastructure, preserving function invocation semantics while significantly reducing costs and latency. In a vHive/Knative prototype on AWS EC2, Zipline achieves 2-5× lower costs & 1.3-3.4× faster execution times compared to S3. Against EC, Zipline cuts costs by 17-772× while improving performance by 2-5%. Zipline demonstrates a cost-effective and high-performance solution for data-intensive serverless applications.",Shyam Jesalpura; Dmitrii Ustiugov; Michal Baczun; Bora A. Malper; Rustem Feyzkhanov; Edouard Bugnion; Marios Kogias; Boris Grot,"Proceedings of the 3rd Workshop on SErverless Systems, Applications and MEthodologies",2025,,,33-41,ACM,10.1145/3721465.3721866,https://doi.org/10.1145/3721465.3721866,proceedings-article,Semantic Scholar,high,"Latency, Cost, Resource Management","autoscaling, serverless, cloud computing, latency, elasticity, reinforcement learning, memory management","Serverless computing enables developers to deploy applications as workflows of functions that invoke one another, with cloud providers handling autoscaling and routing","With a fast, api-compatible data communication method enabling direct function-to-function transfers; Serverless platforms lack efficient mechanisms for cross-function data transfers, which hinders the performance of data-intensive applications"
paper_151,Serverless streaming for emerging media: towards 5G network-driven cost optimization,"Immersive 3D media is an emerging type of media that captures, encodes and reconstructs the 3D appearance of people and objects, with applications in tele-presence, teleconference, entertainment, gaming and other fields. In this paper, we discuss a novel concept of live 3D immersive media streaming in a serverless setting. In particular, we present a novel network-centric adaptive streaming framework which deviates from the traditional client-based adaptive streaming used in 2D video. In our framework the decisions for the production of the transcoding profiles are taken in a centralized manner, by considering consumer metrics vs provisioning costs and inferring the expected consumer quality of experience and behavior based on them. In addition, we demonstrate that a naive application of the serverless paradigm might be sub-optimal under some common immersive 3D media scenarios.",Konstantinos Konstantoudakis; David Breitgand; Alexandros Doumanoglou; Nikolaos Zioulis; Avi Weit; Kyriaki Christaki; Petros Drakoulis; Emmanouil Christakis; Dimitrios Zarpalas; Petros Daras,Multimedia Tools and Applications,2022,81,9,12211-12250,Springer Science and Business Media LLC,10.1007/s11042-020-10219-7,https://doi.org/10.1007/s11042-020-10219-7,journal-article,Semantic Scholar,high,"Cost, Resource Management","performance optimization, serverless, reinforcement learning","A novel network-centric adaptive streaming framework which deviates from the traditional client-based adaptive streaming used in 2d video; The decisions for the production of the transcoding profiles are taken in a centralized manner, by considering consumer metrics vs provisioning costs and inferring the expected consumer quality of experience and behavior based on them",Not explicitly mentioned
paper_152,Experience Paper: Towards enhancing cost efficiency in serverless machine learning training,"Function-as-a-Service (FaaS) has raised a growing interest in how to ""tame"" serverless to enable domain-specific use cases such as data-intensive applications and machine learning (ML), to name a few. Recently, several systems have been implemented for training ML models. Certainly, these research articles are significant steps in the correct direction. However, they do not completely answer the nagging question of when serverless ML training can be more cost-effective compared to traditional ""serverful"" computing. To help in this task, we propose MLLess, a FaaS-based ML training prototype built atop IBM Cloud Functions. To boost cost-efficiency, MLLess implements two key optimizations: a significance filter and a scale-in auto-tuner, and leverages them to specialize model training to the FaaS model. Our results certify that MLLess can be 15X faster than serverful ML systems [24] at a lower cost for ML models (such as sparse logistic regression and matrix factorization) that exhibit fast convergence.",Marc Sánchez-Artigas; Pablo Gimeno Sarroca,Proceedings of the 22nd International Middleware Conference,2021,,,210-222,ACM,10.1145/3464298.3494884,https://doi.org/10.1145/3464298.3494884,proceedings-article,Semantic Scholar,high,"Cost, Energy Consumption","performance optimization, serverless, cloud computing, reinforcement learning","Mlless, a faas-based ml training prototype built atop ibm cloud functions","They do not completely answer the nagging question of when serverless ml training can be more cost-effective compared to traditional ""serverful"" computing"
paper_153,GraphQL vs. REST: A Performance and Cost Investigation for Serverless Applications,"Serverless computing simplifies application deployment by removing the need for infrastructure management, with RESTful APIs being the common interface. However, REST can lead to inefficiencies such as data over-fetching and under-fetching, which impact performance and cost. This paper investigates GraphQL as an alternative to REST for serverless functions using a serverless image processing pipeline. We evaluate roundtrip time (RTT), scalability, and cost, while also examining managed (AWS AppSync) and unmanaged (Apollo Server) GraphQL hosting solutions. Our results show that GraphQL generally outperforms REST with respect to pipeline RTT, especially when there is high network latency, offering a potentially better fit for optimizing data transfer in serverless applications.",Runjie Jin; Robert Cordingly; Dongfang Zhao; Wes Lloyd,Proceedings of the 10th International Workshop on Serverless Computing,2024,,,37-42,ACM,10.1145/3702634.3702956,https://doi.org/10.1145/3702634.3702956,proceedings-article,Semantic Scholar,high,"Latency, Cost","serverless, latency, reinforcement learning",Novel approach to serverless computing challenges,"Rest can lead to inefficiencies such as data over-fetching and under-fetching, which impact performance and cost"
paper_154,Cosmos: A Cost Model for Serverless Workflows in the 3D Compute Continuum,"Due to the high scalability, infrastructure management, and pay-per-use pricing model, serverless computing has been adopted in a wide range of applications such as real-time data processing, IoT, and AI-related workflows. However, deploying serverless functions across dynamic and heterogeneous environments such as the 3D (Edge-Cloud-Space) Continuum introduces additional complexity. Each layer of the 3D Continuum shows different performance capabilities and costs according to workload characteristics. Cloud services alone often show significant differences in performance and pricing for similar functions, further complicating cost management. Additionally, serverless workflows consist of functions with diverse character-istics, requiring a granular understanding of performance and cost trade-offs across different infrastructure layers to be able to address them individually. In this paper, we present Cosmos, a cost- and a performance-cost-tradeoff model for serverless workflows that identifies key factors that affect cost changes across different workloads and cloud providers. We present a case study analyzing the main drivers that influence the costs of serverless workflows. We demonstrate how to classify the costs of serverless workflows in leading cloud providers AWS and GCP. Our results show that for data-intensive functions, data transfer and state management costs contribute to up to 75% of the costs in AWS and 52% in GCP. For compute-intensive functions such as AI inference, the cost results show that BaaS services are the largest cost driver, reaching up to 83 % in AWS and 97 % in GCP.",Cynthia Marcelino; Sebastian Gollhofer-Berger; Thomas Pusztai; Stefan Nastic,2025 IEEE International Conference on Smart Computing (SMARTCOMP),2025,,,106-113,IEEE,10.1109/smartcomp65954.2025.00072,https://doi.org/10.1109/smartcomp65954.2025.00072,proceedings-article,Semantic Scholar,high,Cost,"serverless, cloud computing, reinforcement learning","Cosmos, a cost- and a performance-cost-tradeoff model for serverless workflows that identifies key factors that affect cost changes across different workloads and cloud providers; A case study analyzing the main drivers that influence the costs of serverless workflows; 75% of",Deploying serverless functions across dynamic and heterogeneous environments such as the 3d (edge-cloud-space) continuum introduces additional complexity
paper_155,Towards SLO-Compliant and Cost-Effective Serverless Computing on Emerging GPU Architectures,"Serverless platforms are supporting an increasing variety of applications (apps). Among these, apps such as Machine Learning (ML) inference serving can benefit significantly from leveraging accelerators like GPUs. Yet, major serverless providers, despite having GPU-equipped servers, do not offer GPU support for their serverless functions. While recent works have attempted to bridge this gap, they are agnostic to the capabilities of new-generation GPUs, thereby, overlooking several performance optimization opportunities. To address this, we leverage unique features of newer NVIDIA GPU architectures (specifically, their Multi-Instance GPU (MIG) and Multi-Process Service (MPS) capabilities) to devise a serverless framework, Protean, that can guarantee a higher degree of Service Level Objective (SLO) compliance than that offered by state-of-the-art works. Moreover, Protean also proposes to host its components on a combination of both on-demand (reliable) VMs and heavily discounted VMs to reduce costs to the end consumer, while offering high service availability. We extensively evaluate Protean using 22 ML inference workloads with real-world traces on an 8×A100 GPU cluster. Our results show that Protean significantly outperforms state-of-the-art works in terms of SLO compliance (up to ~93% more) and tail latency (up to 82% less), while reducing cost by up to 70%. We also maintain reasonable tail latencies (< 200 ms) for best effort requests.",Vivek M. Bhasi; Aakash Sharma; Rishabh Jain; Jashwant Raj Gunasekaran; Ashutosh Pattnaik; Mahmut Taylan Kandemir; Chita Das,Proceedings of the 25th International Middleware Conference,2024,,,211-224,ACM,10.1145/3652892.3700760,https://doi.org/10.1145/3652892.3700760,proceedings-article,Semantic Scholar,high,"Latency, Reliability Security Privacy, Cost","performance optimization, serverless, latency, reinforcement learning, distributed systems",82% less; 70,"Having gpu-equipped servers, do not offer gpu support for their serverless functions"
paper_156,Living on the Edge: Serverless Computing and the Cost of Failure Resiliency,"Serverless computing platforms have gained popularity because they allow easy deployment of services in a highly scalable and cost-effective manner. By enabling just-in-time startup of container-based services, these platforms can achieve good multiplexing and automatically respond to traffic growth, making them particularly desirable for edge cloud data centers where resources are scarce. Edge cloud data centers are also gaining attention because of their promise to provide responsive, low-latency shared computing and storage resources. Bringing serverless capabilities to edge cloud data centers must continue to achieve the goals of low latency and reliability. The reliability guarantees provided by serverless computing however are weak, with node failures causing requests to be dropped or executed multiple times. Thus serverless computing only provides a best effort infrastructure, leaving application developers responsible for implementing stronger reliability guarantees at a higher level. Current approaches for providing stronger semantics such as “exactly once” guarantees could be integrated into serverless platforms, but they come at high cost in terms of both latency and resource consumption. As edge cloud services move towards applications such as autonomous vehicle control that require strong guarantees for both reliability and performance, these approaches may no longer be sufficient. In this paper we evaluate the latency, throughput, and resource costs of providing different reliability guarantees, with a focus on these emerging edge cloud platforms and applications.",Sameer G Kulkarni; Guyue Liu; K. K. Ramakrishnan; Timothy Wood,2019 IEEE International Symposium on Local and Metropolitan Area Networks (LANMAN),2019,,,6-Jan,IEEE,10.1109/lanman.2019.8846970,https://doi.org/10.1109/lanman.2019.8846970,proceedings-article,Semantic Scholar,high,"Latency, Reliability Security Privacy, Cost, Energy Consumption, Resource Management","serverless, containerization, cloud computing, latency, throughput, reinforcement learning",Novel approach to serverless computing challenges,"Are weak, with node failures causing requests to be dropped or executed multiple times; They come at high cost in terms of both latency and resource consumption"
paper_157,Microless: Cost-Efficient Hybrid Deployment of Microservices on IaaS VMs and Serverless,"Microservices have gained popularity as an architectural approach for developing scalable and modular applications. Traditionally, microservice deployment relies on virtual machines (VMs) from Infrastructure-as-a-Service (IaaS) computing. However, the emerging serverless computing offers new possibilities for more scalable microservice deployment. In this paper, we provide insights into the optimal scenarios for IaaS VMs and serverless, and investigate the challenges in the programming model and invocation pattern. We propose Microless, a framework that achieves the hybrid deployment of microservices on serverless and IaaS VMs and overcomes the challenges. In Microless, the steady workload is processed on IaaS VMs, ensuring optimal resource utilization and run-time performance. For the fluctuating workload, serverless can rapidly scale out resources to handle burst requests, minimizing response latency and enhancing cost-effectiveness. Experimental results validate the effectiveness of Microless in runtime performance and deployment cost.",Jiagan Cheng; Yilong Zhao; Zijun Li; Quan Chen; Weihao Cui; Minyi Guo,2023 IEEE 29th International Conference on Parallel and Distributed Systems (ICPADS),2023,,,2303-2310,IEEE,10.1109/icpads60453.2023.00309,https://doi.org/10.1109/icpads60453.2023.00309,proceedings-article,Semantic Scholar,high,"Latency, Cost, Resource Management","serverless, microservices, latency, reinforcement learning","Microless, a framework that achieves the hybrid deployment of microservices on serverless and iaas vms and overcomes the challenges",In the programming model and invocation pattern; The emerging serverless computing offers new possibilities for more scalable microservice deployment
paper_158,Serverless at Scale: Evaluating AWS Lambda Cost and Latency Under Varying Loads,"Serverless computing has revolutionized the way modern cloud-native applications are developed and
deployed, offering a paradigm in which developers can focus solely on writing code without the burden of managing
infrastructure. Among the various Function-as-a-Service (FaaS) offerings, AWS Lambda stands out as a widely adopted
platform due to its automatic scaling, event-driven execution, and pay-per-use pricing model—making it ideal for
applications ranging from microservices to complex event-driven workflows. However, serverless architectures present
challenges in cold start latency, performance tuning, and cost optimization, particularly when using heavyweight runtimes
like Java or under sporadic invocation patterns. This study systematically evaluates AWS Lambda’s performance under
varying load conditions by analyzing runtime performance (Java vs. Python), memory allocation, payload size, and traffic
types including steady, burst, and spiky patterns. Key metrics such as cold start time, average execution duration, and
cost per invocation are examined using real-world traffic simulations and observability tools like AWS CloudWatch and
X-Ray. The findings demonstrate that tuning memory allocation, applying provisioned concurrency, and selecting
lightweight runtimes can significantly improve latency and cost-efficiency. The paper concludes with best practices for
serverless workload optimization, offering actionable insights for software architects and DevOps teams aiming to
balance scalability, responsiveness, and operational cost in cloud-native deployments.",Bharathvamsi Reddy Munisif,"International Journal of Innovative Research in Science, Engineering and Technology",2023,12,2,,Ess & Ess Research Publications,10.15680/ijirset.2023.1202007,https://doi.org/10.15680/ijirset.2023.1202007,journal-article,Semantic Scholar,high,"Latency, Cost, Energy Consumption, Resource Management","cold start, autoscaling, performance optimization, serverless, microservices, cloud computing, latency, reinforcement learning, monitoring, memory management","Serverless computing has revolutionized the way modern cloud-native applications are developed and
deployed, offering a paradigm in which developers can focus solely on writing code without the burden of managing
infrastructure","In cold start latency, performance tuning, and cost optimization, particularly when using heavyweight runtimes
like java or under sporadic invocation patterns; Serverless architectures present
challenges in cold start latency, performance tuning, and cost optimization, particularly when using heavyweight runtimes
like java or under sporadic invocation patterns"
paper_159,"Towards Practical, Serverless, Cost-effective, Real-time Pricing for Retail E-Commerce","Real-time pricing, an implementation of dynamic pricing in real-time, is a potent tool with the potential to improve revenue and competitiveness for e-commerce sellers. The broader adoption of dynamic pricing has faced obstacles due to the scarcity of practical, flexible, cost-effective, and readily deployable solutions. The advent of cloud computing has promised to address these challenges by enabling scalable, resilient, and cost-effective software systems. In this paper, we present an innovative solution designed to address this need, aiming to create a practical real-time pricing system for e-commerce, powered by modern cloud computing techniques. Our approach is structured from the ground up, delineating the essential components of a pricing strategy, including prediction of demand and sales conversion ratio. To model and predict these parameters, we employ Linear and Polynomial Regression techniques. These building blocks are then utilized to formulate an optimal pricing strategy. The implemented strategy is deployed within the AWS environment, leveraging serverless services such as AWS Lambda and DynamoDB. These service choices are meticulously selected to optimize deployment costs, ensuring cost-effectiveness compared to alternative options. Our results demonstrate the successful forecasting of pricing parameters and the dynamic adjustment of prices in real-time. The cost-effectiveness of this strategy is further supported by our cost analysis, which finds that implementing dynamic pricing for a medium-volume product with approximately 1 million monthly product views results in a daily cloud bill of about $1 USD.",Archana Kumari; Mohan Kumar. S,"2023 4th International Conference on Communication, Computing and Industry 6.0 (C216)",2023,,,6-Jan,IEEE,10.1109/c2i659362.2023.10430877,https://doi.org/10.1109/c2i659362.2023.10430877,proceedings-article,Semantic Scholar,high,"Survey, Cost, Energy Consumption","serverless, cloud computing, reinforcement learning, prediction","An innovative solution designed to address this need, aiming to create a practical real-time pricing system for e-commerce, powered by modern cloud computing techniques; Is structured from the ground up, delineating the essential components of a pricing strategy, including prediction of demand and sales conversion ratio","By enabling scalable, resilient, and cost-effective software systems"
paper_160,Paldia: Enabling SLO-Compliant and Cost-Effective Serverless Computing on Heterogeneous Hardware,"Among the variety of applications (apps) being deployed on serverless platforms, apps such as Machine Learning (ML) inference serving can achieve better performance from leveraging accelerators like GPUs. Yet, major serverless providers, despite having GPU-equipped servers, do not offer GPU support for their serverless functions. Given that serverless functions are deployed on various generations of CPUs already, extending this to various (typically more expensive) GPU generations can offer providers a greater range of hardware to serve incoming requests according to the functions and request traffic. Here, providers are faced with the challenge of selecting hardware to reach a well-proportioned trade-off point between cost and performance. While recent works have attempted to address this, they often fail to do so as they overlook optimization opportunities arising from intelligently leveraging existing GPU sharing mechanisms. To address this point, we devise a heterogeneous serverless framework, PALDIA, which uses a prudent Hardware selection policy to acquire capable, cost-effective hardware and perform intelligent request scheduling on it to yield high performance and cost savings. Specifically, our scheduling algorithm employs hybrid spatio-temporal GPU sharing that intelligently trades off job queueing delays and interference to allow the chosen cost-effective hardware to also be highly performant. We extensively evaluate PALDIA using 16 ML inference workloads with real-world traces on a 6 node heterogeneous cluster. Our results show that PALDIA significantly outperforms state-of-the-art works in terms of Service Level Objective (SLO) compliance (up to 13.3% more) and tail latency (up to ∼50% less), with cost savings up to 86%.",Vivek M. Bhasi; Aakash Sharma; Shruti Mohanty; Mahmut Taylan Kandemir; Chita R. Das,2024 IEEE International Parallel and Distributed Processing Symposium (IPDPS),2024,,,100-113,IEEE,10.1109/ipdps57955.2024.00018,https://doi.org/10.1109/ipdps57955.2024.00018,proceedings-article,Semantic Scholar,high,"Latency, Cost, Resource Management","performance optimization, serverless, latency, queuing, reinforcement learning, cpu allocation, distributed systems",13; 86,"Of selecting hardware to reach a well-proportioned trade-off point between cost and performance; Having gpu-equipped servers, do not offer gpu support for their serverless functions"
paper_161,Cost-optimal Operation of Latency Constrained Serverless Applications: From Theory to Practice,"Serverless computing and the function as a service model are new paradigms enabling the fine granular, bottomup construction of cloud-native applications. It can significantly reduce operating costs while shifting the management tasks from developers and application providers towards the cloud operators. But these benefits are provided at the cost of less control over the underlying infrastructure and the application performance, including the end-to-end latency. However, grouping of functions into deployable serverless software artifacts remains still under our control, which has a considerable impact on performance and operation costs. In this paper, we propose fast and efficient algorithms that can partition an application’s functions into separate deployment artifacts in a cost-optimal way while meeting user-defined average end-to-end latency bounds. Moreover, our approach supports the dynamic redesign and reconfiguration of the current deployment setup in response to changes in monitored metrics. Our main contribution is threefold. First, we establish the relevant theoretical models capturing the behavior of the serverless ecosystem and we define the main problem. In addition, the concept of the integrated application management is introduced. Second, we propose novel algorithms providing optimal solutions for different variants of the core problem and the complexity of the methods are analyzed. Third, we demonstrate the applicability and the benefits of our solution by evaluating different deployment scenarios of a realistic use case in Amazon’s public cloud environment.",János Czentye; István Pelle; Balázs Sonkoly,NOMS 2023-2023 IEEE/IFIP Network Operations and Management Symposium,2023,,,10-Jan,IEEE,10.1109/noms56928.2023.10154412,https://doi.org/10.1109/noms56928.2023.10154412,proceedings-article,Semantic Scholar,high,"Latency, Cost","serverless, cloud computing, latency, reinforcement learning",Fast and efficient algorithms that can partition an application’s functions into separate deployment artifacts in a cost-optimal way while meeting user-defined average end-to-end latency bounds; Novel algorithms providing optimal solutions for different variants of the core problem and the complexity of the methods are analyzed; Supports the dynamic redesign and reconfiguration of the current deployment setup in response to changes in monitored metrics,"Grouping of functions into deployable serverless software artifacts remains still under our control, which has a considerable impact on performance and operation costs; These benefits are provided at the cost of less control over the underlying infrastructure and the application performance, including the end-to-end latency"
paper_162,"FaaSGraph: Enabling Scalable, Efficient, and Cost-Effective Graph Processing with Serverless Computing","Graph processing is widely used in cloud services; however, current frameworks face challenges in efficiency and cost-effectiveness when deployed under the Infrastructure-as-a-Service model due to its limited elasticity. In this paper, we present FaaSGraph, a serverless-native graph computing scheme that enables efficient and economical graph processing through the co-design of graph processing frameworks and serverless computing systems. Specifically, we design a data-centric serverless execution model to efficiently power heavy computing tasks. Furthermore, we carefully design a graph processing paradigm to seamlessly cooperate with the data-centric model. Our experiments show that FaaS-Graph improves end-to-end performance by up to 8.3X and reduces memory usage by up to 52.4% compared to state-of-the-art IaaS-based methods. Moreover, FaaSGraph delivers steady 99%-ile performance in highly fluctuated workloads and reduces monetary cost by 85.7%.",Yushi Liu; Shixuan Sun; Zijun Li; Quan Chen; Sen Gao; Bingsheng He; Chao Li; Minyi Guo,"Proceedings of the 29th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 2",2024,,,385-400,ACM,10.1145/3620665.3640361,https://doi.org/10.1145/3620665.3640361,proceedings-article,Semantic Scholar,high,"Cost, Energy Consumption","serverless, cloud computing, elasticity, reinforcement learning, memory management","Faasgraph, a serverless-native graph computing scheme that enables efficient and economical graph processing through the co-design of graph processing frameworks and serverless computing systems; A data-centric serverless execution model to efficiently power heavy computing tasks; 52",In efficiency and cost-effectiveness when deployed under the infrastructure-as-a-service model due to its limited elasticity; Current frameworks face challenges in efficiency and cost-effectiveness when deployed under the infrastructure-as-a-service model due to its limited elasticity
paper_163,Time and Cost-Efficient Cloud Data Transmission based on Serverless Computing Compression,"Nowadays, there exists a lot of cross-region data transmission demand on cloud. It is promising to use serverless computing for compressing data to save the transmission data amount. However, it is challenging to estimate the data transmission time and monetary cost with serverless compression. In addition, minimizing the data transmission cost is non-trivial due to enormous parameter space and joint optimization. This paper focuses on this problem and makes the following contributions: (1) We propose empirical data transmission time and monetary cost models based on serverless compression. (2) For single-task cloud data transmission, we propose two efficient parameter search methods based on Sequential Quadratic Programming (SQP ) and Eliminate then Divide and Conquer (EDC), which are theoretically proven with error upper bounds. (3) Furthermore, for multi-task cloud data transmission, a parameter search method based on dynamic programming and numerical computation is proposed to reduce the algorithm complexity from exponential to linear complexity. We have implemented the entire actual system and evaluated it with various workloads and application cases on the real-world AWS serverless computing platform. Experimental results on cross-region public cloud show that the proposed approach can improve the parameter search efficiency by more than 3× compared with the state-of-art parameter search methods and achieves better parameter quality. Compared with other competing cloud data transmission approaches, our approach is able to achieve higher time efficiency and lower monetary cost.",Rong Gu; Xiaofei Chen; Haipeng Dai; Shulin Wang; Zhaokang Wang; Yaofeng Tu; Yihua Huang; Guihai Chen,IEEE INFOCOM 2023 - IEEE Conference on Computer Communications,2023,,,10-Jan,IEEE,10.1109/infocom53939.2023.10229090,https://doi.org/10.1109/infocom53939.2023.10229090,proceedings-article,Semantic Scholar,high,"Cost, Energy Consumption","performance optimization, serverless, cloud computing, reinforcement learning","Empirical data transmission time and monetary cost models based on serverless compression; Two efficient parameter search methods based on sequential quadratic programming (sqp ) and eliminate then divide and conquer (edc), which are theoretically proven with error upper bounds; Is able to achieve higher time efficiency and lower monetary cost",It is challenging to estimate the data transmission time and monetary cost with serverless compression; And makes the following contributions: (1) we propose empirical data transmission time and monetary cost models based on serverless compression
paper_164,Workflow aware analytical model to predict performance and cost of serverless execution,"Serverless computing has emerged as a powerful deployment model based on the Function‐as‐a‐Service (FaaS) paradigm, where applications are orchestrated through a set of independent functions. The function orchestration within an application can be represented through a serverless workflow, which defines the overall execution plan of the application. To ensure the quality of service for serverless computing platforms, it is essential to develop performance and cost models that can predict the service quality that can be obtained from deploying and executing applications in the cloud platform. While several analytical models have been developed for various cloud deployment frameworks in recent years, there has been a lack of performance and cost analysis models for serverless computing platforms. The existing performance and cost monitoring tools available in serverless frameworks face several challenges, such as complexity, lack of transparency, and incomplete monitoring data. In this paper, we fill the gap by proposing an efficient workflow‐based analytical model that can estimate the end‐to‐end response time and cost of the serverless execution plan. The proposed model can handle complex structures like loop, cycles, self‐loop, and parallel substructures that exist in serverless workflows. Additionally, we propose a heuristic optimization algorithm to identify the optimal resource configuration to achieve the optimal response time under a given budget constraint. We evaluated the effectiveness of the proposed model by considering seven serverless applications in both AWS Lambda and Microsoft Azure platforms. We compared the accuracy of the proposed model with the real values of response time and cost obtained in AWS Lambda and Microsoft Azure serverless platforms. The proposed performance and cost model in the AWS Lambda platform has been observed to have an average accuracy of 99.2% and 98.7% respectively. In the Microsoft Azure platform, the average accuracy of the performance and cost model has been observed to be 98.6% and 98.2% respectively.",Anisha Kumari; Bibhudatta Sahoo; Ranjan Kumar Behera,Concurrency and Computation: Practice and Experience,2023,35,22,,Wiley,10.1002/cpe.7743,https://doi.org/10.1002/cpe.7743,journal-article,Semantic Scholar,high,"Survey, Latency, QoS, Cost, Energy Consumption, Resource Management","performance optimization, serverless, cloud computing, reinforcement learning, monitoring","A heuristic optimization algorithm to identify the optimal resource configuration to achieve the optimal response time under a given budget constraint; Model can handle complex structures like loop, cycles, self‐loop, and parallel substructures that exist in serverless workflows; Model by considering seven serverless applications in both aws lambda and microsoft azure platforms","Structures like loop, cycles, self‐loop, and parallel substructures that exist in serverless workflows"
paper_165,<i>Astrea:</i>Auto-Serverless Analytics Towards Cost-Efficiency and QoS-Awareness,"With the ability to simplify the code deployment with one-click upload and lightweight execution, serverless computing has emerged as a promising paradigm with increasing popularity. However, there remain open challenges when adapting data-intensive analytics applications to the serverless context, in which users of {\em serverless analytics} encounter the difficulty in coordinating computation across different stages and provisioning resources in a large configuration space. This paper presents our design and implementation of {\em Astrea}, which configures and orchestrates serverless analytics jobs in an autonomous manner, while taking into account flexibly-specified user requirements. {\em Astrea} relies on the modeling of performance and cost which characterizes the intricate interplay among multi-dimensional factors ({\em e.g.}, function memory size, degree of parallelism at each stage). We formulate an optimization problem based on user-specific requirements towards performance enhancement or cost reduction, and develop a set of algorithms based on graph theory to obtain optimal job execution. We deploy {\em Astrea} in the AWS Lambda platform and conduct real-world experiments over representative benchmarks, including big data analytics and machine learning workloads, at different scales. Extensive results demonstrate that {\em Astrea} can achieve the optimal execution decision for serverless data analytics, in comparison with various provisioning and deployment baselines. For example, when compared with three provisioning baselines, {\em Astrea} manages to improve the job completion time performance by $21\%$ to $69\%$ under a given budget constraint, while saving cost by $20\%$ to $84\%$ without violating performance requirements.",Jananie Jarachanthan; Li Chen; Fei Xu; Bo Li,IEEE Transactions on Parallel and Distributed Systems,2022,33,12,3833-3849,Institute of Electrical and Electronics Engineers (IEEE),10.1109/tpds.2022.3172069,https://doi.org/10.1109/tpds.2022.3172069,journal-article,Semantic Scholar,high,"Survey, QoS, Cost, Energy Consumption, Resource Management","performance optimization, serverless, reinforcement learning, memory management","Our design and implementation of {\em astrea}, which configures and orchestrates serverless analytics jobs in an autonomous manner, while taking into account flexibly-specified user requirements","When adapting data-intensive analytics applications to the serverless context, in which users of {\em serverless analytics} encounter the difficulty in coordinating computation across different stages and provisioning resources in a large configuration space; There remain open challenges when adapting data-intensive analytics applications to the serverless context, in which users of {\em serverless analytics} encounter the difficulty in coordinating computation across different stages and provisioning resources in a large configuration space"
paper_166,Cost-AoI Aware Task Scheduling in Industrial IOT Based on Serverless Edge Computing,"Wireless Industrial IoT plays a crucial role in smart factories, where many sensors are rapidly generating task requests scheduled for timely responses. Maintaining information freshness is necessary but challenging. Edge networks that combine emerging serverless feathers can enable significant improvements in development efficiency and more flexible adaptation to workloads. However, the cost of scheduling cannot be ignored. Most of the present work in serverless edge computing does not consider the impact of the age of information (AoI) and cost in task scheduling. In this paper, we consider the relationship between AoI in users and cost in service providers in practical scenarios. We model the task scheduling problem in a serverless edge computing scenario as a Markov Decision Process (MDP) and consider multi-hop forwarding task scheduling with guaranteed AoI and costs under different pressures of workloads. To solve the highly dynamic problem, we design a multi-agent deep reinforcement learning algorithm based on Proximal Policy Optimization (PPO), validate it on real datasets, and experiments show that our algorithm reduces 10% cost in low workload and up to 16% AoI in the high workload situation.",Mingchu Li; Zhihua Wang,2024 IEEE Wireless Communications and Networking Conference (WCNC),2024,,,6-Jan,IEEE,10.1109/wcnc57260.2024.10570806,https://doi.org/10.1109/wcnc57260.2024.10570806,proceedings-article,Semantic Scholar,high,"Cost, Energy Consumption, Resource Management","performance optimization, serverless, reinforcement learning","A multi-agent deep reinforcement learning algorithm based on proximal policy optimization (ppo), validate it on real datasets, and experiments show that our algorithm reduces 10% cost in low workload and up to 16% aoi in the high workload situation; Reduces 10% cost in low workload and up to 16% aoi in the high workload situation; 16% aoi",The cost of scheduling cannot be ignored; Challenging
paper_167,CodeCrunch: Improving Serverless Performance via Function Compression and Cost-Aware Warmup Location Optimization,"Serverless computing has a critical problem of function cold starts. To minimize cold starts, state-of-the-art techniques predict function invocation times to warm them up. Warmed-up functions occupy space in memory and incur a keep-alive cost, which can become exceedingly prohibitive under bursty load. To address this issue, we design CodeCrunch, which introduces the concept of serverless function compression and exploits server heterogeneity to make serverless computing more efficient, especially under high memory pressure.",Rohan Basu Roy; Tirthak Patel; Rohan Garg; Devesh Tiwari,"Proceedings of the 29th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 1",2024,,,85-101,ACM,10.1145/3617232.3624866,https://doi.org/10.1145/3617232.3624866,proceedings-article,Semantic Scholar,high,"Latency, Cost","cold start, performance optimization, serverless, reinforcement learning, memory management","Codecrunch, which introduces the concept of serverless function compression and exploits server heterogeneity to make serverless computing more efficient, especially under high memory pressure",Of function cold starts
paper_168,Making Serverless Not So Cold in Edge Clouds: A Cost-Effective Online Approach,"Applying the serverless paradigm to edge computing improves edge resource utilization while bringing the benefits of flexible scaling and pay-as-you-go to latency-sensitive applications. This extends the boundaries of serverless computing and improves the quality of service for Function-as-a-Service users. However, as an emerging cloud computing paradigm, serverless edge computing faces pressing challenges, with one of the biggest obstacles being delay caused by excessively long container cold starts. Cold start delay is defined as the time between when a serverless function is triggered and when it begins to execute, and its existence seriously impacts resource utilization and Quality of Service (QoS). In this article, we study how to minimize the total system cost by caching function containers and selecting routes for neighboring functions via edge or public clouds. We prove that the proposed problem is NP-hard even in the special case where the user request contains only one function, and that the unpredictability of user requests and the impact between adjacent time decisions require that the problem to be solved in an online fashion. We then design the Online Lazy Caching algorithm, an online algorithm with a worst-case competitive ratio using a randomized dependent rounding algorithm to solve the problem. Extensive simulation results show that the proposed online algorithm can achieve close-to-optimal performance in terms of both total cost and cold start cost compared to other existing algorithms, with average improvements of 31.6<inline-formula><tex-math notation=""LaTeX"">$\%$</tex-math><alternatives><mml:math><mml:mo>%</mml:mo></mml:math><inline-graphic xlink:href=""xiao-ieq1-3355118.gif""/></alternatives></inline-formula> and 51.7<inline-formula><tex-math notation=""LaTeX"">$\%$</tex-math><alternatives><mml:math><mml:mo>%</mml:mo></mml:math><inline-graphic xlink:href=""xiao-ieq2-3355118.gif""/></alternatives></inline-formula>.",Ke Xiao; Song Yang; Fan Li; Liehuang Zhu; Xu Chen; Xiaoming Fu,IEEE Transactions on Mobile Computing,2024,23,9,8789-8802,Institute of Electrical and Electronics Engineers (IEEE),10.1109/tmc.2024.3355118,https://doi.org/10.1109/tmc.2024.3355118,journal-article,Semantic Scholar,high,"Latency, QoS, Cost, Resource Management","cold start, autoscaling, serverless, containerization, cloud computing, latency, reinforcement learning","Problem is np-hard even in the special case where the user request contains only one function, and that the unpredictability of user requests and the impact between adjacent time decisions require that the problem to be solved in an online fashion; Online algorithm can achieve close-to-optimal performance in terms of both total cost and cold start cost compared to other existing algorithms, with average improvements of 31","As an emerging cloud computing paradigm, serverless edge computing faces pressing challenges, with one of the biggest obstacles being delay caused by excessively long container cold starts; Is np-hard even in the special case where the user request contains only one function, and that the unpredictability of user requests and the impact between adjacent time decisions require that the problem to be solved in an online fashion"
paper_169,"Cost Analysis of Running Web Application in Cloud Monolith, Microservice and Serverless Architecture","Cloud computing has become a popular choice for deploying web applications, but the selection of the appropriate architecture for different application types remains a challenge for businesses. In this study, we conducted performance and cost analyses of three architectures: Monolith, Microservice, and Serverless (specifically Lambda and Fargate) to provide businesses with valuable insights for decision-making. To ensure the relevance of our findings, we conducted tests on an application designed for static, database, and batch job services, deployed on AWS. Using JMeter, we simulated traffic with varying levels of high, medium, and low intensity, distributing 500 requests across six test scenarios. The results and subsequent analysis revealed that Lambda outperformed the other architectures significantly, while Fargate and Microservice architectures exhibited lower performance in comparison. However, cost played a crucial role in architecture selection. Fargate proved to be exceptionally expensive, with costs escalating further when batch jobs were involved. On the other hand, Lambda demonstrated lower overall costs compared to the other architectures, especially when batch jobs were running under low traffic conditions. However, the cost advantage diminished when running batch jobs in higher traffic scenarios, surpassing the expenses of Monolith and Microservice architectures. The findings highlight the superior performance of Lambda, but also emphasize the importance of considering costs and specific workload requirements when selecting an architecture. Lambda outperformed other architectures by reducing average response time by 25% and cost by 15% under low-traffic scenarios compared to Monolithic and Microservice architectures.",Muhammad Uzair Nadeem; Syed Muhammad Khaliq-ur-Rahman Raazi; Bilal Mehboob; Syed Mubashir Ali; Saqlain Raza,Journal of Independent Studies and Research Computing,2024,22,2,,Shaheed Zulfiqar Ali Bhutto Institute of Science and Technology,10.31645/jisrc.24.22.2.7,https://doi.org/10.31645/jisrc.24.22.2.7,journal-article,Semantic Scholar,high,"Survey, Latency, Cost","serverless, cloud computing, reinforcement learning",Novel approach to serverless computing challenges,For businesses; Cost played a crucial role in architecture selection
paper_170,Reducing the Cost of GPU Cold Starts in Serverless Deep Learning Inference Serving,"The rapid growth of Deep Learning (DL) has led to increasing demand for DL-as-a-Service. In this paradigm, DL inferences are served on-demand through a serverless cloud provider, which manages the scaling of hardware resources to satisfy dynamic workloads. This is enticing to businesses due to lower infrastructure management costs compared to dedicated on-site hosting. However, current serverless systems suffer from long cold starts where requests are queued until a server can be initialized with the DL model, which is especially problematic due to large DL model sizes. In addition, low-latency demands such as in real-time fraud detection and algorithmic trading cause long inferences in CPU-only systems to violate deadlines. To tackle this, current systems rely on over-provisioning expensive GPU resources to meet low-latency requirements, thus increasing the total cost of ownership for cloud service providers. In this work, we characterize the cold start problem in GPU-accelerated serverless systems. We then design and evaluate novel solutions based on two main techniques. Namely, we propose remote memory pooling and hierarchical sourcing with locality-aware autoscaling where we exploit underutilized memory and network resources to store and prioritize sourcing the DL model from existing host machines over remote host memory then cloud storage. We demonstrate through simulations that these techniques can perform up to 19.3× and 1.4× speedup in 99th percentile and median end-to-end latencies respectively compared to a baseline. Such speedups enable serverless systems to meet low-latency requirements despite dynamic workloads.",Justin San Juan; Bernard Wong,2023 IEEE International Conference on Pervasive Computing and Communications Workshops and other Affiliated Events (PerCom Workshops),2023,,,225-230,IEEE,10.1109/percomworkshops56833.2023.10150381,https://doi.org/10.1109/percomworkshops56833.2023.10150381,proceedings-article,Semantic Scholar,high,"Latency, Cost, Resource Management","cold start, autoscaling, serverless, cloud computing, latency, queuing, reinforcement learning, deep learning, deadline, memory management, cpu allocation",Remote memory pooling and hierarchical sourcing with locality-aware autoscaling where we exploit underutilized memory and network resources to store and prioritize sourcing the dl model from existing host machines over remote host memory then cloud storage; 19,"Current serverless systems suffer from long cold starts where requests are queued until a server can be initialized with the dl model, which is especially problematic due to large dl model sizes; Dynamic workloads"
paper_171,Seraph: A Performance-Cost Aware Tuner for Training Reinforcement Learning Model on Serverless Computing,"Training a reinforcement learning model is critical for various AI tasks. However, determining the hardware resources required for training RL models is challenging due to the interaction between the CPU and GPU, and the variability that exists in the training. The problem becomes more challenging when deploying an RL training job on the cloud with serverless computing, as we should consider both the performance and cost of training RL models. Existing tuners, like Ray Tune, require users to provide a search space. It is both error-prone and unable to search the setup with the desired cost. We present Seraph, the first tuner for RL training that finds the hardware configuration with the best performance within a user-given cost boundary. Seraph explicitly models the performance of training by decomposing RL training and using a stochastic model to harness variability. Compared to Ray Tune, it finds the optimal with 71% tuning time reduction.",Jinbo Han; Xingda Wei; Rong Chen; Haibo Chen,Proceedings of the 15th ACM SIGOPS Asia-Pacific Workshop on Systems,2024,,,95-101,ACM,10.1145/3678015.3680479,https://doi.org/10.1145/3678015.3680479,proceedings-article,Semantic Scholar,high,"Cost, Resource Management","serverless, cloud computing, reinforcement learning, cpu allocation","Seraph, the first tuner for rl training that finds the hardware configuration with the best performance within a user-given cost boundary","Determining the hardware resources required for training rl models is challenging due to the interaction between the cpu and gpu, and the variability that exists in the training; Becomes more challenging when deploying an rl training job on the cloud with serverless computing, as we should consider both the performance and cost of training rl models"
paper_172,Cost-Effective Malware Detection as a Service Over Serverless Cloud Using Deep Reinforcement Learning,"The current trends of cloud computing in general, and serverless computing in particular, affect multiple aspects of organizational activity. Organizations of all sizes are transitioning parts of their operations off-premise in order to reduce costs and scale their operations more efficiently. The field of network security is no exception, with many organizations taking advantage of the distributed and scalable cloud environment. Since the charging model for serverless computing is ""pay as you go"" (i.e., payment per action), a reduction in the number of required computations translates into significant cost savings. This understanding is also relevant to the field of malware detection, where organizations often deploy multiple types of detectors to increase detection accuracy. In this study, we utilize deep reinforcement learning to reduce computational costs in the cloud by selectively querying only a subset of available detectors. We demonstrate that our approach is not only effective both for on-premise and cloud-based computing architectures, but that applying it to serverless computing can reduce costs by an order of magnitude while maintaining near-optimal performance.",Yoni Birman; Shaked Hindi; Gilad Katz; Asaf Shabtai,"2020 20th IEEE/ACM International Symposium on Cluster, Cloud and Internet Computing (CCGRID)",2020,,,420-429,IEEE,10.1109/ccgrid49817.2020.00-51,https://doi.org/10.1109/ccgrid49817.2020.00-51,proceedings-article,Semantic Scholar,high,"Reliability Security Privacy, QoS, Cost","serverless, cloud computing, reinforcement learning, distributed systems","Is not only effective both for on-premise and cloud-based computing architectures, but that applying it to serverless computing can reduce costs by an order of magnitude while maintaining near-optimal performance",That applying it to serverless computing can reduce costs by an order of magnitude while maintaining near-optimal performance
paper_173,A deep reinforcement learning based algorithm for time and cost optimized scaling of serverless applications,"Serverless computing has gained a strong traction in the cloud computing
community in recent years. Among the many benefits of this novel computing
model, the rapid auto-scaling capability of user applications takes prominence.
However, the offer of adhoc scaling of user deployments at function level
introduces many complications to serverless systems. The added delay and
failures in function request executions caused by the time consumed for
dynamically creating new resources to suit function workloads, known as the
cold-start delay, is one such very prevalent shortcoming. Maintaining idle
resource pools to alleviate this issue often results in wasted resources from
the cloud provider perspective. Existing solutions to address this limitation
mostly focus on predicting and understanding function load levels in order to
proactively create required resources. Although these solutions improve
function performance, the lack of understanding on the overall system
characteristics in making these scaling decisions often leads to the
sub-optimal usage of system resources. Further, the multi-tenant nature of
serverless systems requires a scalable solution adaptable for multiple
co-existing applications, a limitation seen in most current solutions. In this
paper, we introduce a novel multi-agent Deep Reinforcement Learning based
intelligent solution for both horizontal and vertical scaling of function
resources, based on a comprehensive understanding on both function and system
requirements. Our solution elevates function performance reducing cold starts,
while also offering the flexibility for optimizing resource maintenance cost to
the service providers. Experiments conducted considering varying workload
scenarios show improvements of up to 23% and 34% in terms of application
latency and request failures, while also saving up to 45% in infrastructure
cost for the service providers.",Anupama Mampage; Shanika Karunasekera; Rajkumar Buyya,Future Generation Computer Systems,2025,173,,107873,Elsevier BV,10.1016/j.future.2025.107873,https://doi.org/10.1016/j.future.2025.107873,journal-article,arXiv,high,"Latency, Cost, Resource Management","cold start, autoscaling, serverless, cloud computing, latency, multi-tenant, reinforcement learning","A novel multi-agent deep reinforcement learning based
intelligent solution for both horizontal and vertical scaling of function
resources, based on a comprehensive understanding on both function and system
requirements; 23% and; 45% in","Mostly focus on predicting and understanding function load levels in order to
proactively create required resources; Seen in most current solutions"
paper_174,FuncPipe: A Pipelined Serverless Framework for Fast and Cost-efficient Training of Deep Learning Models,"Training deep learning (DL) models in the cloud has become a norm. With the emergence of serverless computing and its benefits of true pay-as-you-go pricing and scalability, systems researchers have recently started to provide support for serverless-based training. However, the ability to train DL models on serverless platforms is hindered by the resource limitations of today's serverless infrastructure and DL models' explosive requirement for memory and bandwidth. This paper describes FuncPipe, a novel pipelined training framework specifically designed for serverless platforms that enable fast and low-cost training of DL models. FuncPipe is designed with the key insight that model partitioning can be leveraged to bridge both memory and bandwidth gaps between the capacity of serverless functions and the requirement of DL training. Conceptually simple, we have to answer several design questions, including how to partition the model, configure each serverless function, and exploit each function's uplink/downlink bandwidth. In particular, we tailor a micro-batch scheduling policy for the serverless environment, which serves as the basis for the subsequent optimization. Our Mixed-Integer Quadratic Programming formulation automatically and simultaneously configures serverless resources and partitions models to fit within the resource constraints. Lastly, we improve the bandwidth efficiency of storage-based synchronization with a novel pipelined scatter-reduce algorithm. We implement FuncPipe on two popular cloud serverless platforms and show that it achieves 7%-77% cost savings and 1.3X-2.2X speedup compared to state-of-the-art serverless-based frameworks.",Yunzhuo Liu; Bo Jiang; Tian Guo; Zimeng Huang; Wenhao Ma; Xinbing Wang; Chenghu Zhou,ACM SIGMETRICS Performance Evaluation Review,2023,51,1,35-36,Association for Computing Machinery (ACM),10.1145/3606376.3593543,https://doi.org/10.1145/3606376.3593543,journal-article,Semantic Scholar,high,"Cost, Energy Consumption, Resource Management","performance optimization, serverless, cloud computing, reinforcement learning, deep learning, memory management",Funcpipe on two popular cloud serverless platforms and show that it achieves 7%-77% cost savings and 1,Of today's serverless infrastructure and dl models' explosive requirement for memory and bandwidth; The ability to train dl models on serverless platforms is hindered by the resource limitations of today's serverless infrastructure and dl models' explosive requirement for memory and bandwidth
paper_175,Artificial Bee Colony Optimization for Delay and Cost Aware Task Scheduling in Serverless Computing Environment,"Serverless edge computing is increasingly adopted in smart cities and industrial automation applications, which leverages cloud computing for scalable resources and uses Function as a Service (FaaS) for efficient load balancing, pay-as-you-go execution, and third-party management of provisioning and auto-scaling. However, task scheduling in serverless environments is challenging due to service latency, provider costs, and cold start issues caused by dynamic workloads and resource availability. While existing literature has focused on task scheduling, it often overlooks the joint minimization of service delay and provider costs, as well as long-term workloads, and energy use. In this work, we propose an optimization framework using mixed integer linear programming (MILP) to jointly minimize task execution delay and provider costs, namely DECASE. Given the NP-hard nature of the optimization for large networks, we developed a metaheuristic Artificial Bee Colony (ABC) algorithm to provide near-optimal task scheduling and resource allocation within polynomial time. The developed DECASE system significantly reduces delays and serverless resource provider costs by up to 20% and 25% compared to existing methods.",Shah Jalal; Palash Roy; Sudip Chandra Ghoshal; Subrato Basak; Belal Hoshan; Md. Abdur Razzaque; Saiful Azad,2024 6th International Conference on Sustainable Technologies for Industry 5.0 (STI),2024,,,6-Jan,IEEE,10.1109/sti64222.2024.10951128,https://doi.org/10.1109/sti64222.2024.10951128,proceedings-article,Semantic Scholar,high,"Latency, Reliability Security Privacy, Cost, Energy Consumption, Resource Management","cold start, autoscaling, resource management, performance optimization, serverless, cloud computing, latency, load balancing, energy efficiency, reinforcement learning","An optimization framework using mixed integer linear programming (milp) to jointly minimize task execution delay and provider costs, namely decase; 20% and","Task scheduling in serverless environments is challenging due to service latency, provider costs, and cold start issues caused by dynamic workloads and resource availability; Caused by dynamic workloads and resource availability"
paper_176,Optimizing Cost and Performance in Serverless Batch ProcessingA Comparative Analysis of AWS Step Functions vs,This research presents a comprehensive comparative analysis of AWS Step Functions and traditional workflow orchestrators in the context of large-scale batch processing.,Nitya Sri Nellore,Journal of Mathematical &amp; Computer Applications,2022,1,1,5-Jan,Scientific Research and Community Ltd,10.47363/jmca/2022(1)e160,https://doi.org/10.47363/jmca/2022(1)e160,journal-article,Semantic Scholar,high,"Survey, Cost","serverless, reinforcement learning",This research presents a comprehensive comparative analysis of aws step functions and traditional workflow orchestrators in the context of large-scale batch processing,Not explicitly mentioned
paper_177,An Investigation of the Impact of Language Runtime on the Performance and Cost of Serverless Functions,"Serverless, otherwise known as ""Function-as-a-Service"" (FaaS), is a compelling evolution of cloud computing that is highly scalable and event-driven. Serverless applications are composed of multiple independent functions, each of which can be implemented in a range of programming languages. This paper seeks to understand the impact of the choice of language runtime on the performance and subsequent cost of serverless function execution. It presents the design and implementation of a new serverless performance testing framework created to analyse performance and cost metrics for both AWS Lambda and Azure Functions. For optimum performance and cost management of serverless applications, Python is the clear choice on AWS Lambda. C# .NET is the top performer and most economical option for Azure Functions. NodeJS on Azure Functions and .NET Core 2 on AWS should be avoided or at the very least, used carefully in order to avoid their potentially slow and costly start-up times.",David Jackson; Gary Clynch,2018 IEEE/ACM International Conference on Utility and Cloud Computing Companion (UCC Companion),2018,,,,IEEE,10.1109/ucc-companion.2018.00050,https://doi.org/10.1109/ucc-companion.2018.00050,proceedings-article,Semantic Scholar,high,Cost,"serverless, cloud computing, reinforcement learning",Novel approach to serverless computing challenges,Not explicitly mentioned
paper_178,Cost-efficient service selection and execution and blockchain-enabled serverless network for internet of medical things,"These days, healthcare applications on the Internet of Medical Things (IoMT) network have been growing to deal with different diseases via different sensors. These healthcare sensors are connecting to the various healthcare fog servers. The hospitals are geographically distributed and offer different services to the patients from any ubiquitous network. However, due to the full offloading of data to the insecure servers, two main challenges exist in the IoMT network. (i) Data security of workflows healthcare applications between different fog healthcare nodes. (ii) The cost-efficient and QoS efficient scheduling of healthcare applications in the IoMT system. This paper devises the Cost-Efficient Service Selection and Execution and Blockchain-Enabled Serverless Network for Internet of Medical Things system. The goal is to choose cost-efficient services and schedule all tasks based on their QoS and minimum execution cost. Simulation results show that the proposed outperform all existing schemes regarding data security, validation by 10%, and cost of application execution by 33% in IoMT.",Abdullah Lakhan; Mazhar Ali Dootio; Ali Hassan Sodhro; Sandeep Pirbhulal; Tor Morten Groenli; Muhammad Saddam Khokhar; Lei Wang,Mathematical Biosciences and Engineering,2021,18,6,7344-7362,American Institute of Mathematical Sciences (AIMS),10.3934/mbe.2021363,https://doi.org/10.3934/mbe.2021363,journal-article,Semantic Scholar,high,"Reliability Security Privacy, QoS, Cost, Resource Management","serverless, reinforcement learning, distributed systems","Outperform all existing schemes regarding data security, validation by 10%, and cost of application execution by 33% in iomt","Exist in the iomt network; Due to the full offloading of data to the insecure servers, two main challenges exist in the iomt network"
paper_179,Enhanced Runtime-Adaptable Routing for Serverless Functions based on Performance and Cost Tradeoffs in Hybrid Cloud Settings,"Serverless computing has reshaped the cloud computing landscape by offering benefits such as auto-scalability, streamlined operational management, and granular billing. As its adoption grows, challenges related to performance and cost optimization in hybrid architectures combining private servers and public cloud clusters have emerged. Central to these challenges are achieving optimal response latency and balancing performance and cost. To address these challenges, this paper introduces an adaptive routing service specifically designed for hybrid environments, proficient in leveraging real-time function metrics. Our proposed service pivots on three integral components: a monitor that captures performance metrics and raises alarms for predefined anomalies; a forecaster that predicts function latency across clusters, which includes wait and execution times and produces request distributions for each cluster to equalize the overall function latency; and a router then processes incoming requests, taking cues from the forecaster’s predictions. Notably, based on user-defined objectives, the forecaster can be directed to either minimize latency or optimize execution costs through trading off wait or execution time. Comprehensive evaluations on AWS and Azure clusters using the open source FaaS framework Apache OpenWhisk showcase our approach’s effectiveness, yielding a 9% improvement in average latency, a 45% decrease in standard deviation latency and a 17% cost reduction compared to conventional 50-50 routing. The advantages of elevated monitoring frequency are also illuminated, emphasizing quicker convergence times.",Georgios Fatouros; Georgios Kousiouris; Georgios Makridis; John Soldatos; Michael Filippakis; Dimosthenis Kyriazis,2023 IEEE International Conference on Cloud Computing Technology and Science (CloudCom),2023,,,177-184,IEEE,10.1109/cloudcom59040.2023.00038,https://doi.org/10.1109/cloudcom59040.2023.00038,proceedings-article,Semantic Scholar,high,"Survey, Latency, Cost","performance optimization, serverless, cloud computing, latency, reinforcement learning, prediction, monitoring, distributed systems","An adaptive routing service specifically designed for hybrid environments, proficient in leveraging real-time function metrics; 9% improvement",Related to performance and cost optimization in hybrid architectures combining private servers and public cloud clusters have emerged; Are achieving optimal response latency and balancing performance and cost
paper_180,Unleashing the Power of Serverless Computing: Elevating Software Engineering with AWS Lambda for Cost-Efficiency and Speed,"Serverless computing is valuable for quite the opposite reason: it is a paradigm change in how software
engineering can be done. One of the most popular serverless computing services provided by Amazon Web
Services (AWS) is AWS Lambda, which provides a fundamentally new model that minimizes the cost and time
needed to get things done. This paper explores AWS Lambda in view of responding to some of the challenges of
SE and some of the key areas include scalability, managing infrastructure and developing software at a high
velocity. Until recently, software developers were dependent on hardware means, organizing and provisioning
servers for applications, which left many applications underutilized, over-provisioned, and, last but not least,
expensive. AWS Lambda manages these challenges by enabling developers to execute code without owning or
having to allocate any server and still scale up or down their apps depending on the traffic. Serverless computing
deals with the entire underlying infrastructure in order to remove most of the concerns related to the deployment
and upkeep of applications. The primary benefits of AWS Lambda consist of event-based systems architecture,
variable pricing models, and easy scalability. First, these features decrease operational costs, while second, they
increase flexibility as applications can be deployed based on observed occurrences. In addition, working with other
AWS services like S3, DynamoDB, and API Gateway makes Lambda a ubiquitous part of building and designing
cloud-based applications. This paper outlines the serverless model and also shows how AWS Lambda enhances the
development model as per the costs, scalability, and effectiveness required. In a literature survey, we discuss the
emergence of serverless computing and its adjacency to software engineering. In the methodology section, and with
reference to the case studies, we explain how AWS Lambda catalyzes faster time-to-market for applications. Last is
the conclusion area where authors summarize specific findings on ways serverless outperforms the traditional cloud
structure in saving costs, delivering speed and agility. In conclusion, the replays underpin AWS Lambda as a
leading innovation in transforming the future of software engineering best practices by encouraging the adoption of
a serverless first approach for resource and business optimization.
Keywords: Serverless Computing, AWS Lambda, Cost Efficiency, Event-Driven Architecture, Scalability,
Infrastructure Management, Software Engineering, Cloud Computing.",Sai Krishna Chirumamilla,INTERANTIONAL JOURNAL OF SCIENTIFIC RESEARCH IN ENGINEERING AND MANAGEMENT,2021,5,4,7-Jan,Indospace Publications,10.55041/ijsrem7621,https://doi.org/10.55041/ijsrem7621,journal-article,Semantic Scholar,high,"Survey, Cost, Energy Consumption, Resource Management","performance optimization, serverless, cloud computing, reinforcement learning","This paper explores aws lambda in view of responding to some of the challenges of
se and some of the key areas include scalability, managing infrastructure and developing software at a high
velocity","Of
se and some of the key areas include scalability, managing infrastructure and developing software at a high
velocity; By enabling developers to execute code without owning or
having to allocate any server and still scale up or down their apps depending on the traffic"
paper_181,Smart Minion: A Low-cost Serverless Multimodal Access Control System Based on Face Recognition and Gesture Recognition,"With the advance of the Internet of Things (IoT) and artificial intelligence (AI) technology, more and more applications appear for mobile computing, such as face recognition for access control. Yet, most artificial intelligence of things (AIoT) products in our homes are based on cloud service application programming interfaces (APIs). All the original data are sent wirelessly to the server for cloud computing, which may lead to privacy issues and high energy consumption. In this study, we propose a novel low-cost serverless access control system with multimodal inferring capability. Within the system, practical on-device face recognition and cost-efficient dynamic gesture recognition are implemented for liveness detection. We utilize the MobileNetV2 model for transfer learning the task-specific face data and a random forest model for one-dimensional gesture recognition. Both tiny machine learning (TinyML) models are successfully deployed on a low-cost microcontroller (MCU). The multimodal inferring perform pretty well. After using the sequential inferring mechanism, the robustness of the system is further reinforced. A low-cost prototype is assembled for field tests. The compact all-in-one product based on the proposed system with a cute minion theme has also been designed. The energy consumption of different MCU operations is measured in detail. The system provides a valuable reference for realizing pervasive smart sensing and, thus, contributes to the bright future of AIoT.",Zijie Chen; Yiming Gao; Junrui Liang,2023 International Conference on Artificial Intelligence of Things and Systems (AIoTSys),2023,,,133-138,IEEE,10.1109/aiotsys58602.2023.00042,https://doi.org/10.1109/aiotsys58602.2023.00042,proceedings-article,Semantic Scholar,high,"Reliability Security Privacy, Cost, Energy Consumption","serverless, cloud computing, energy efficiency, reinforcement learning",A novel low-cost serverless access control system with multimodal inferring capability; System with a cute minion theme has also been designed,And high energy consumption
paper_182,"Towards Serverless Sky Computing: An Investigation on Global Workload Distribution to Mitigate Carbon Intensity, Network Latency, and Cost","The high demand for energy consumption and the resulting carbon footprint of the cloud pose significant sustainability challenges, as cloud data centers consume vast amounts of energy. The emergence of serverless cloud computing platforms has opened up new avenues for more sustainable cloud computing. Serverless Function-as-a-Service (FaaS) cloud computing platforms facilitate deploying applications as decoupled microservices to leverage automatic rapid scaling, high availability, fault tolerance, and on-demand pricing. The absence of always-on hosting costs associated with virtual machines enables serverless functions to be deployed with many different function configurations and cloud regions to achieve high performance, low network latency, and reduced costs. In this paper, we investigate the utility of a global sky computing platform where serverless resources are aggregated between up to 19 distinct cloud regions. We prototype a serverless load distribution system to distribute client requests across serverless aggregations to minimize performance objectives, including network latency, runtime, hosting costs, and carbon footprint. To evaluate our serverless distribution system's ability to meet performance objectives, we continuously executed large experiments across 19 regions around the world from November 2022 through March 2023. Our serverless load distribution approach using aggregated resources reduced the carbon intensity of a globally distributed serverless application by up to 99.8%, network latency by 65%, or hosting costs by 58% by optimizing function routing to deployments with optimal hardware configurations.",Robert Cordingly; Jasleen Kaur; Divyansh Dwivedi; Wes Lloyd,2023 IEEE International Conference on Cloud Engineering (IC2E),2023,,,59-69,IEEE,10.1109/ic2e59103.2023.00015,https://doi.org/10.1109/ic2e59103.2023.00015,proceedings-article,Semantic Scholar,high,"Latency, Reliability Security Privacy, Cost, Energy Consumption, Resource Management","autoscaling, serverless, microservices, cloud computing, latency, load balancing, energy efficiency, reinforcement learning, distributed systems",19 distinct; 99,Network Latency
paper_183,Predicting the Costs of Serverless Workflows,"Function-as-a-Service (FaaS) platforms enable users to run arbitrary functions without being concerned about operational issues, while only paying for the consumed resources. Individual functions are often composed into workflows for complex tasks. However, the pay-per-use model and nontransparent reporting by cloud providers make it challenging to estimate the expected cost of a workflow, which prevents informed business decisions. Existing cost-estimation approaches assume a static response time for the serverless functions, without taking input parameters into account. In this paper, we propose a methodology for the cost prediction of serverless workflows consisting of input-parameter sensitive function models and a monte-carlo simulation of an abstract workflow model. Our approach enables workflow designers to predict, compare, and optimize the expected costs and performance of a planned workflow, which currently requires time-intensive experimentation. In our evaluation, we show that our approach can predict the response time and output parameters of a function based on its input parameters with an accuracy of 96.1%. In a case study with two audio-processing workflows, our approach predicts the costs of the two workflows with an accuracy of 96.2%.",Simon Eismann; Johannes Grohmann; Erwin van Eyk; Nikolas Herbst; Samuel Kounev,Proceedings of the ACM/SPEC International Conference on Performance Engineering,2020,,,265-276,ACM,10.1145/3358960.3379133,https://doi.org/10.1145/3358960.3379133,proceedings-article,Semantic Scholar,high,"Survey, Latency, Cost, Resource Management","serverless, cloud computing, reinforcement learning, prediction","A methodology for the cost prediction of serverless workflows consisting of input-parameter sensitive function models and a monte-carlo simulation of an abstract workflow model; That our approach can predict the response time and output parameters of a function based on its input parameters with an accuracy of 96; Enables workflow designers to predict, compare, and optimize the expected costs and performance of a planned workflow, which currently requires time-intensive experimentation","The pay-per-use model and nontransparent reporting by cloud providers make it challenging to estimate the expected cost of a workflow, which prevents informed business decisions; Tasks"
paper_184,Energy Efficient Scheduling for Serverless Systems,"Serverless computing, also referred to as Function-as-a-Service (FaaS), is a cloud computing model that has attracted significant attention and has been widely adopted in recent years. The serverless computing model offers an intuitive, event-based interface that makes the development and deployment of scalable cloud-based applications easier and cost-effective. An important aspect that has not been examined in these systems is their energy consumption during the application execution. One way to deal with this issue is to schedule the function invocations in an energy-efficient way. However, efficient scheduling of applications in a multi-tenant environment, like FaaS systems, poses significant challenges. The trade-off between the server’s energy usage and the hosted functions’ performance requirements needs to be taken into consideration. In this work, we propose an Energy Efficient Scheduler for orchestrating the execution of serverless functions so that it minimizes energy consumption while it satisfies the applications’ performance demands. Our approach considers real-time performance measurements and historical data and applies a novel DVFS technique to minimize energy consumption. Our detailed experimental evaluation using realistic workloads on our local cluster illustrates the working and benefits of our approach.",Michail Tsenos; Aristotelis Peri; Vana Kalogeraki,2023 IEEE International Conference on Autonomic Computing and Self-Organizing Systems (ACSOS),2023,,,27-36,IEEE,10.1109/acsos58161.2023.00020,https://doi.org/10.1109/acsos58161.2023.00020,proceedings-article,Semantic Scholar,high,"Survey, Cost, Energy Consumption, Resource Management","serverless, cloud computing, multi-tenant, energy efficiency, reinforcement learning, distributed systems",An energy efficient scheduler for orchestrating the execution of serverless functions so that it minimizes energy consumption while it satisfies the applications’ performance demands; Considers real-time performance measurements and historical data and applies a novel dvfs technique to minimize energy consumption,"Efficient scheduling of applications in a multi-tenant environment, like faas systems, poses significant challenges; Is to schedule the function invocations in an energy-efficient way"
paper_185,Accountable Carbon Footprints and Energy Profiling For Serverless Functions,"Cloud computing is a significant and growing cause of carbon emissions. Understanding the energy consumption and carbon footprints of cloud applications is a fundamental prerequisite to raising awareness, designing sustainability metrics, and creating targeted system optimizations. In this paper, we address the challenges of providing accurate and full-system (not just CPU) carbon footprints for serverless (FaaS) functions. To the best of our knowledge, this is the first work which develops an energy and carbon metrology framework for FaaS. Carbon footprints require a new approach to energy profiling. We use FaaS workload properties such as locality to develop a simple and practical online statistical disaggregation approach. Our fine-grained per-invocation carbon footprints also include shared hardware and software emissions, and use insights from Shapley values to fairly account for both operational and embodied emissions. Owing to the growing importance of carbon measurement, we develop a new rigorous marginal energy based validation methodology which results in accountable, complete, and fair footprints. Over a wide range of FaaS workloads and hardware platforms, our energy footprints have an accuracy of > 99%.",Prateek Sharma; Alexander Fuerst,Proceedings of the ACM Symposium on Cloud Computing,2024,,,522-541,ACM,10.1145/3698038.3698531,https://doi.org/10.1145/3698038.3698531,proceedings-article,Semantic Scholar,high,Energy Consumption,"performance optimization, serverless, cloud computing, energy efficiency, reinforcement learning, cpu allocation","A new rigorous marginal energy based validation methodology which results in accountable, complete, and fair footprints",Of providing accurate and full-system (not just cpu) carbon footprints for serverless (faas) functions
paper_186,EneX: An Energy-Aware Execution Scheduler for Serverless Computing,"The emerging serverless computing paradigm has recently attracted huge attention from both academia and industry. It brings benefits, such as less operational complexity, high scalability and availability, and lower costs. Serverless applications are usually partitioned into several chains of functions. The serverless provider should schedule functions for execution per customers' requests considering their chained nature. Also, the existing scheduling mechanisms for serverless platforms pay little attention to the reduction of energy consumption during functions' execution. To fill this gap, we present an energy-aware execution scheduler for serverless service providers named EneX. To do so, we formulate the minimization of energy consumption for executing the incoming chains of functions with specified computational loads and deadlines. Due to the intractability of the problem, we introduce a linear programming reformulation based on which, we propose an online scheduler. Finally, our experiments demonstrate the significant improvement of EneX in terms of energy efficiency.",Seyed Hamed Rastegar; Hossein Shafiei; Ahmad Khonsari,IEEE Transactions on Industrial Informatics,2024,20,2,2342-2353,Institute of Electrical and Electronics Engineers (IEEE),10.1109/tii.2023.3290985,https://doi.org/10.1109/tii.2023.3290985,journal-article,Semantic Scholar,high,"Reliability Security Privacy, Cost, Energy Consumption, Resource Management","serverless, energy efficiency, reinforcement learning, deadline","An online scheduler; A linear programming reformulation based on which, we propose an online scheduler; An energy-aware execution scheduler for serverless service providers named enex",Not explicitly mentioned
paper_187,A Serverless Engine for High Energy Physics Distributed Analysis,"The Large Hadron Collider (LHC) at CERN has generated in the last decade an unprecedented volume of data for the High-Energy Physics (HEP) field. Scientific collaborations interested in analysing such data very often require computing power beyond a single machine. This issue has been tackled traditionally by running analyses in distributed environments using stateful, managed batch computing systems. While this approach has been effective so far, current estimates for future computing needs of the field present large scaling challenges. Such a managed approach may not be the only viable way to tackle them and an interesting alternative could be provided by serverless architectures, to enable an even larger scaling potential. This work describes a novel approach to running real HEP scientific applications through a distributed serverless computing engine. The engine is built upon ROOT, a well-established HEP data analysis software, and distributes its computations to a large pool of concurrent executions on Amazon Web Services Lambda Serverless Platform. Thanks to the developed tool, physicists are able to access datasets stored at CERN (also those that are under restricted access policies) and process it on remote infrastructures outside of their typical environment. The analysis of the serverless functions is monitored at runtime to gather performance metrics, both for data- and computation-intensive workloads.",Jacek Kusnierz; Vincenzo E. Padulano; Maciej Malawski; Kamil Burkiewicz; Enric Tejedor Saavedra; Pedro Alonso-Jorda; Michael Pitt; Valentina Avati,"2022 22nd IEEE International Symposium on Cluster, Cloud and Internet Computing (CCGrid)",2022,,,575-584,IEEE,10.1109/ccgrid54584.2022.00067,https://doi.org/10.1109/ccgrid54584.2022.00067,proceedings-article,Semantic Scholar,high,"Survey, Energy Consumption, Resource Management","autoscaling, serverless, energy efficiency, reinforcement learning, distributed systems",Novel approach to serverless computing challenges,"Has been tackled traditionally by running analyses in distributed environments using stateful, managed batch computing systems"
paper_188,Energy-aware Provisioning of Microservices for Serverless Edge Computing,"Serverless edge computing allows for highly efficient resource utilization, reducing the energy footprint of edge data centers. Indeed, the containers can be dynamically created and destroyed, allowing to adapt the workload to the available resources. Creating containers upon arrivals of service requests entails, however, a high start-up latency, which may be unsuitable for time-critical services. As alternative solution, pre-started containers (“warm containers”) are used to decrease start-up latency, but incurring in higher resource costs. In this work, we minimize the energy consumption of the active servers in the data center by optimally managing the various container states while meeting the target delay of the requested services. Further, in light of the problem complexity, we investigate how a simple threshold-based algorithm performs and show that it can closely match the optimum.",Madhura Adeppady; Alberto Conte; Holger Karl; Paolo Giaccone; Carla Fabiana Chiasserini,GLOBECOM 2023 - 2023 IEEE Global Communications Conference,2023,,,3070-3075,IEEE,10.1109/globecom54140.2023.10437798,https://doi.org/10.1109/globecom54140.2023.10437798,proceedings-article,Semantic Scholar,high,"Latency, Cost, Energy Consumption, Resource Management","serverless, containerization, microservices, latency, energy efficiency, reinforcement learning",Novel approach to serverless computing challenges,"A high start-up latency, which may be unsuitable for time-critical services; Incurring in higher resource costs"
paper_189,Towards Energy-Aware Execution and Offloading of Serverless Functions,"The convergence of Function-as-a-Service (FaaS) with Edge computing presents a promising avenue to address the demands of geo-distributed and pervasive applications. Yet, leveraging both the reduced latency of Edge and the scalability of FaaS necessitates novel architectures and implementations, given the higher heterogeneity and resource constraints of Edge environments. An important issue regards energy management, as serverless functions may be executed in energy-constrained computing nodes (e.g., powered by batteries or renewable yet uncertain energy supplies). In this paper, we present a solution for energy-aware function execution relying on two key mechanisms: (i) the ability of choosing among multiple function implementations at run-time, trading off energy savings with approximate computation results; (ii) computational offloading, to move function execution from the Edge to the Cloud, based on energy-aware policies. We integrate our solution in Serverledge, an open-source FaaS platform designed for the Edge-to-Cloud continuum. Our evaluation shows that energy-aware offloading and execution are effective in extending the lifespan and throughput of battery-powered nodes.",Cecilia Calavaro; Gabriele Russo Russo; Martina Salvati; Valeria Cardellini; Francesco Lo Presti,Proceedings of the 4th Workshop on Flexible Resource and Application Management on the Edge,2024,,,23-30,ACM,10.1145/3659994.3660313,https://doi.org/10.1145/3659994.3660313,proceedings-article,Semantic Scholar,high,"Survey, Latency, Energy Consumption, Resource Management","serverless, cloud computing, latency, throughput, energy efficiency, reinforcement learning, distributed systems","A solution for energy-aware function execution relying on two key mechanisms: (i) the ability of choosing among multiple function implementations at run-time, trading off energy savings with approximate computation results; (ii) computational offloading, to move function execution from the edge to the cloud, based on energy-aware policies","Of edge environments; Regards energy management, as serverless functions may be executed in energy-constrained computing nodes (e"
paper_190,EcoFaaS: Rethinking the Design of Serverless Environments for Energy Efficiency,"While serverless computing is increasingly popular, its energy and power consumption behavior is hardly explored. In this work, we perform a thorough characterization of the serverless environment and observe that it poses a set of challenges not effectively handled by existing energy-management schemes. Short serverless functions execute in opaque virtualized sandboxes, are idle for a large fraction of their invocation time, context switch frequently, and are co-located in a highly dynamic manner with many other functions of diverse properties. These features are a radical shift from more traditional application environments and require a new approach to manage energy and power. Driven by these insights, we design EcoFaaS, the first energy management framework for serverless environments. EcoFaaS takes a user-provided end-to-end application Service Level Objective (SLO). It then splits the SLO into per-function deadlines that minimize the total energy consumption. Based on the computed deadlines, EcoFaaS sets the optimal per-invocation core frequency using a prediction algorithm. The algorithm performs a fine-grained analysis of the execution time of each invocation, while taking into account the specific invocation inputs. To maximize efficiency, EcoFaaS splits the cores in a server into multiple Core Pools, where all the cores in a pool run at the same frequency and are controlled by a single scheduler. EcoFaaS dynamically changes the sizes and frequencies of the pools based on the current system state. We implement EcoFaaS on two open-source serverless platforms (OpenWhisk and KNative) and evaluate it using diverse serverless applications. Compared to state-of-the-art energy-management systems, EcoFaaS reduces the total energy consumption of serverless clusters by $42 \%$ while simultaneously reducing the tail latency by $34.8 \%$.",Jovan Stojkovic; Nikoleta Iliakopoulou; Tianyin Xu; Hubertus Franke; Josep Torrellas,2024 ACM/IEEE 51st Annual International Symposium on Computer Architecture (ISCA),2024,,,471-486,IEEE,10.1109/isca59077.2024.00042,https://doi.org/10.1109/isca59077.2024.00042,proceedings-article,Semantic Scholar,high,"Survey, Latency, Energy Consumption","serverless, latency, energy efficiency, reinforcement learning, prediction, deadline, distributed systems","Ecofaas, the first energy management framework for serverless environments; Ecofaas on two open-source serverless platforms (openwhisk and knative) and evaluate it using diverse serverless applications",Not effectively handled by existing energy-management schemes
paper_191,MicroFaaS: Energy-efficient Serverless on Bare-metal Single-board Computers,"Serverless function-as-a-service (FaaS) platforms offer a radically-new paradigm for cloud software development, yet the hardware infrastructure underlying these platforms is based on a decades-old design pattern. The rise of FaaS presents an opportunity to reimagine cloud infrastructure to be more energy-efficient, cost-effective, reliable, and secure. In this paper, we show how replacing handfuls of x86-based rack servers with hundreds of ARM-based single-board computers could lead to a virtualization-free, energy-proportional cloud that achieves this vision. We call our systematically-designed implementation MicroFaaS, and we conduct a thorough evaluation and cost analysis comparing MicroFaaS to a throughput-matched FaaS platform implemented in the style of conventional virtualization-based cloud systems. Our results show a 5.6x increase in energy efficiency and 34.2% decrease in total cost of ownership compared to our baseline.",Anthony Byrne; Yanni Pang; Allen Zou; Shripad Nadgowda; Ayse K. Coskun,"2022 Design, Automation &amp; Test in Europe Conference &amp; Exhibition (DATE)",2022,,,754-759,IEEE,10.23919/date54114.2022.9774688,https://doi.org/10.23919/date54114.2022.9774688,proceedings-article,Semantic Scholar,high,"Survey, Cost, Energy Consumption","serverless, cloud computing, throughput, energy efficiency, reinforcement learning","How replacing handfuls of x86-based rack servers with hundreds of arm-based single-board computers could lead to a virtualization-free, energy-proportional cloud that achieves this vision",Not explicitly mentioned
paper_192,Clustering-Based Serverless Edge Computing Assisted Federated Learning for Energy Procurement,"Prosumers nowadays are capable of consuming and generating renewable energy along with providing charging services for public electric vehicles (EVs) through EV support equipment (EVSE). However, the energy demand of prosumers and EVs as well as the renewable energy generation of prosumers have uncertain nature, which causes difficulty for each prosumer to purchase the proper energy at a lower price in advance. Thus, it is paramount important to do energy procurement prediction (EPP) for each prosumer. Nevertheless, submitting data from each prosumer to a centralized server for EPP will result in communication delay and need to consume a huge amount of network bandwidth and energy. Therefore, in this paper, a clustering-based serverless edge computing-assisted federated learning (FL) approach is proposed for EPP, where the objective is to minimize the Huber loss between the predicted and the real value per prosumer. In particular, firstly, normalized Laplacian-based spectral clustering is leveraged to group the prosumers with a similar energy procurement pattern to solve the problem of biased energy procurement forecast caused by updating the model among all the clients. Secondly, long short-term memory (LSTM) in the federated learning setting is utilized to train the global model of each clustered group, where the model aggregation occurs in the serverless edge computing ability-enhanced local edge server with the best performance. The evaluation results demonstrate the proposed method can achieve the lowest Huber loss compared with the baseline methods.",Luyao Zou; Md. Shirajum Munir; Ye Lin Tun; Choong Seon Hong,2022 23rd Asia-Pacific Network Operations and Management Symposium (APNOMS),2022,,,6-Jan,IEEE,10.23919/apnoms56106.2022.9919944,https://doi.org/10.23919/apnoms56106.2022.9919944,proceedings-article,Semantic Scholar,high,"Survey, Latency, Energy Consumption","serverless, latency, energy efficiency, reinforcement learning, prediction, memory management, distributed systems",Method can achieve the lowest huber loss compared with the baseline methods,"The energy demand of prosumers and evs as well as the renewable energy generation of prosumers have uncertain nature, which causes difficulty for each prosumer to purchase the proper energy at a lower price in advance; Of biased energy procurement forecast caused by updating the model among all the clients"
paper_193,Leveraging an open source serverless framework for high energy physics computing,"CERN (Centre Europeen pour la Recherce Nucleaire) is the largest research centre for high energy physics (HEP). It offers unique computational challenges as a result of the large amount of data generated by the large hadron collider. CERN has developed and supports a software called ROOT , which is the de facto standard for HEP data analysis. This framework offers a high-level and easy-to-use interface called RDataFrame , which allows managing and processing large data sets. In recent years, its functionality has been extended to take advantage of distributed computing capabilities. Thanks to its declarative programming model, the user-facing API can be decoupled from the actual execution backend . This decoupling allows physical analysis to scale automatically to thousands of computational cores over various types of distributed resources. In fact, the distributed RDataFrame module already supports the use of established general industry engines such as Apache Spark or Dask. Notwithstanding the foregoing, these current solutions will not be sufficient to meet future requirements in terms of the amount of data that the new projected accelerators will generate. It is of interest, for this reason, to investigate a different approach, the one offered by serverless computing. Based on a first prototype using AWS Lambda , this work presents the creation of a new backend for RDataFrame distributed over the OSCAR tool, an open source framework that supports serverless computing. The implementation introduces new ways, relative to the AWS Lambda -based prototype, to synchronize the work of functions.",Vincenzo Eduardo Padulano; Pablo Oliver Cortés; Pedro Alonso-Jordá; Enric Tejedor Saavedra; Sebastián Risco; Germán Moltó,The Journal of Supercomputing,2023,79,8,8940-8965,Springer Science and Business Media LLC,10.1007/s11227-022-05016-y,https://doi.org/10.1007/s11227-022-05016-y,journal-article,Semantic Scholar,high,"Survey, Energy Consumption, Resource Management","serverless, energy efficiency, reinforcement learning, distributed systems","Cern has developed and supports a software called root , which is the de facto standard for hep data analysis",As a result of the large amount of data generated by the large hadron collider
paper_194,FOA-Energy: A Multi-objective Energy-Aware Scheduling Policy for Serverless-based Edge-Cloud Continuum,"The cloud is evolving into a computing continuum by extending its capabilities toward the edge. This continuum better addresses the needs of modern applications, but it also introduces new challenges, particularly in resource management and scheduling. Serverless is a driving force in consolidating the continuum, allowing quick adaptations toward the edge level while keeping the applications' footprints low. Data-centric applications that deal with massive data and require deploying large software environments are becoming a common use-case for the combination of these new technologies. Standard cloud scheduling policies are based on greedy algorithms that do not efficiently handle platforms' heterogeneity nor deal with problems such as cold start delays. In this paper, we address these issues by extending a methodology to investigate serverless platforms on the edge-cloud continuum, and to study new scheduling policies in simulated environments. We also propose a multi-objective algorithm to allocate serverless functions in the continuum while considering heterogeneity to optimize energy consumption, data transfers, makespan, and resource utilization. As a baseline, we are inspired by a standard greedy algorithm from a widely used platform, Kubernetes. Our approach outperforms the baseline regarding energy consumption, data transfers, makespan, and resource utilization by up to three orders of magnitude.",Anderson Andrei Da Silva; Yiannis Georgiou; Michael Mercier; Gregory Mounié; Denis Trystram,Proceedings of the 40th ACM/SIGAPP Symposium on Applied Computing,2025,,,225-232,ACM,10.1145/3672608.3707941,https://doi.org/10.1145/3672608.3707941,proceedings-article,Semantic Scholar,high,"Latency, Energy Consumption, Resource Management","cold start, resource management, serverless, cloud computing, latency, energy efficiency, reinforcement learning","Outperforms the baseline regarding energy consumption, data transfers, makespan, and resource utilization by up to three orders of magnitude","It also introduces new challenges, particularly in resource management and scheduling; Such as cold start delays"
paper_195,Energy-Aware Scheduling of a Serverless Workload in an ISA-Heterogeneous Cluster,"The serverless model decouples computation from infrastructure. This results in flexibility for running serverless functions on heterogeneous hardware, such as emerging x86/ARM ISA-heterogeneous clusters. We present a method for scheduling serverless workloads across ISA-heterogeneity boundaries to reduce energy usage. Our method combines the offline profiling of functions for energy use and performance, the construction of performance/energy affinity models, and an energy-aware scheduler. Our evaluation with servers equipped with Xeon x86 and Ampere Altra Max ARM processors and 22 serverless functions shows that energy usage can be reduced by up to 15.2%.",Simon Arys; Romain Carlier; Etienne Rivière,Proceedings of the 10th International Workshop on Serverless Computing,2024,,,25-30,ACM,10.1145/3702634.3702954,https://doi.org/10.1145/3702634.3702954,proceedings-article,Semantic Scholar,high,"Survey, Energy Consumption, Resource Management","serverless, energy efficiency, reinforcement learning, cpu allocation, distributed systems","A method for scheduling serverless workloads across isa-heterogeneity boundaries to reduce energy usage; Combines the offline profiling of functions for energy use and performance, the construction of performance/energy affinity models, and an energy-aware scheduler; 15",Not explicitly mentioned
paper_196,LEASE: Leveraging Energy-Awareness in Serverless Edge for Latency-Sensitive IoT Services,"Resource scheduling catering to real-time IoT services in a serverless-enabled edge network is particularly challenging owing to the workload variability, strict constraints on tolerable latency, and unpredictability in the energy sources powering the edge devices. This paper proposes a framework LEASE that dynamically schedules resources in serverless functions catering to different microservices and adhering to their deadline constraint. To assist the scheduler in making effective scheduling decisions, we introduce a priority-based approach that offloads functions from over-provisioned edge nodes to under-provisioned peer nodes, considering the expended energy in the process without compromising the completion time of microservices. For real-world implementations, we consider a testbed comprising a Raspberry Pi cluster serving as edge nodes, equipped with container orchestrator tools such as Kubernetes and powered by OpenFaaS, an open-source serverless platform. Experimental results demonstrate that compared to the benchmarking algorithm, LEASE achieves a 23.34% reduction in the overall completion time, with 97.64% of microservices meeting their deadline. LEASE also attains a 30.10% reduction in failure rates.",Aastik Verma; Anurag Satpathy; Sajal. K. Das; Sourav Kanti Addya,2024 IEEE International Conference on Pervasive Computing and Communications Workshops and other Affiliated Events (PerCom Workshops),2024,,,302-307,IEEE,10.1109/percomworkshops59983.2024.10502788,https://doi.org/10.1109/percomworkshops59983.2024.10502788,proceedings-article,Semantic Scholar,high,"Survey, Latency, Energy Consumption, Resource Management","serverless, containerization, microservices, latency, energy efficiency, reinforcement learning, deadline, distributed systems","A priority-based approach that offloads functions from over-provisioned edge nodes to under-provisioned peer nodes, considering the expended energy in the process without compromising the completion time of microservices; A framework lease that dynamically schedules resources in serverless functions catering to different microservices and adhering to their deadline constraint; 34% reduction","On tolerable latency, and unpredictability in the energy sources powering the edge devices"
paper_197,Performance Optimization of Serverless Computing for Latency-Guaranteed and Energy-Efficient Task Offloading in Energy-Harvesting Industrial IoT,"Serverless architecture enables various intelligent applications to be run without managing infrastructure. In this architecture, the computing cost is generally proportional to the number of requested stateless functions and this number can affect the task completion time and, thus, it is prominent to decide an appropriate number of requested stateless functions. In this article, we propose a latency-guaranteed and energy-efficient task offloading (LETO) system where an Internet of Things (IoT) device decides the number of stateless functions requested to the cloud by considering the deadline on the task completion time and its energy level. To minimize the computing cost while guaranteeing sufficiently short task completion time and low energy outage probability, we formulate a constrained Markov decision process (CMDP) problem and convert the CMDP problem into an equivalent linear programming (LP) model. By solving the LP model, the optimal policy on the number of requested stateless functions can be achieved. Evaluation results illustrate that LETO can cut down the operating expenditure (OPEX) by up to 59% compared to a latency-guaranteed offloading scheme while keeping the task completion time and the energy outage probability below desirable levels.",Haneul Ko; Sangheon Pack; Victor C. M. Leung,IEEE Internet of Things Journal,2023,10,3,1897-1907,Institute of Electrical and Electronics Engineers (IEEE),10.1109/jiot.2021.3137291,https://doi.org/10.1109/jiot.2021.3137291,journal-article,Semantic Scholar,high,"Survey, Latency, Cost, Energy Consumption","performance optimization, serverless, cloud computing, latency, energy efficiency, reinforcement learning, deadline",A latency-guaranteed and energy-efficient task offloading (leto) system where an internet of things (iot) device decides the number of stateless functions requested to the cloud by considering the deadline on the task completion time and its energy level; 59% compared,And convert the cmdp problem into an equivalent linear programming (lp) model
paper_198,A Stable Matching Approach to Energy Efficient and Sustainable Serverless Scheduling for the Green Cloud Continuum,"Cloud infrastructures are evolving from centralised systems to geographically distributed federations of edge devices, fog nodes, and clouds - often known as the Cloud-Edge Continuum. Continuum systems are dynamic, often massive in scale, and feature disparate infrastructure providers and platforms; this greatly increase the complexity of developing and managing applications. The Serverless paradigm shows the potential to greatly simplify the process of building Continuum applications - however, current scheduling mechanisms for Serverless Continuum platforms pay little attention to reducing the energy consumption and improving the sustainability of function execution. This is a significant omission, made worse as computing nodes within a Continuum may be powered by renewable energy sources that are intermittent and unpredictable, making low-powered and bottleneck nodes unavailable.There is great opportunity to design a decentralized energy management scheme for scheduling Serverless functions that takes advantage of the different layers of the Continuum, such as IoT devices located at the Edge, on-premises clusters closer to the data sources, or directly on large Cloud infrastructures. To achieve this, we formally model a green energy-aware Serverless workload scheduling problem for the multi-provider Cloud-Edge Continuum. We then design stable matching based technique for decentralized energy management (utilising a distributed controller) that considers the availability of green energy nodes and the QoS requirements of Serverless functions. We prove the complexity, stability and termination of the proposed heuristic algorithm, and also compare its performance with baseline scheduling techniques.",Yashwant Singh Patel; Paul Townend,2024 IEEE International Conference on Service-Oriented System Engineering (SOSE),2024,,,25-35,IEEE,10.1109/sose62363.2024.00010,https://doi.org/10.1109/sose62363.2024.00010,proceedings-article,Semantic Scholar,high,"Reliability Security Privacy, QoS, Energy Consumption, Resource Management","serverless, cloud computing, energy efficiency, reinforcement learning, distributed systems","Heuristic algorithm, and also compare its performance with baseline scheduling techniques",Current scheduling mechanisms for serverless continuum platforms pay little attention to reducing the energy consumption and improving the sustainability of function execution; For the multi-provider cloud-edge continuum
paper_199,OrcBench: A Representative Serverless Benchmark,"Serverless computing is rapidly growing area of research. No standardized benchmark currently exists for evaluating orchestration level decisions or executing large serverless workloads because of the limited data provided by cloud providers. Current benchmarks focus on other aspects, such as the cost of running general types of functions and their runtimes.We introduce OrcBench, the first orchestration benchmark based on the recently published Microsoft Azure serverless data set. OrcBench categorizes 8622 serverless functions into 17 distinct models, which represent 5.6 million invocations from the original trace.OrcBench also incorporates a time-series analysis to identify function chains within the dataset. OrcBench can use these to create workloads that mimic complete serverless applications, which includes simulating CPU and memory usage. The modeling allows these workloads to be scaled according to the target hardware configuration.",Ryan Hancock; Sreeharsha Udayashankar; Ali Jose Mashtizadeh; Samer Al-Kiswany,2022 IEEE 15th International Conference on Cloud Computing (CLOUD),2022,,,103-108,IEEE,10.1109/cloud55607.2022.00028,https://doi.org/10.1109/cloud55607.2022.00028,proceedings-article,Semantic Scholar,high,"Survey, Cost, Resource Management","serverless, cloud computing, reinforcement learning, memory management, cpu allocation","Orcbench, the first orchestration benchmark based on the recently published microsoft azure serverless data set",Not explicitly mentioned
paper_200,TriggerBench: A Performance Benchmark for Serverless Function Triggers,"Serverless computing offers a scalable event-based paradigm for deploying managed cloud-native applications. Function triggers are essential building blocks in serverless, as they initiate any function execution. However, function triggering is insufficiently studied and inherently hard to measure given the distributed, ephemeral, and asynchronous nature of event-based function coordination. To address this gap, we present TriggerBench, a cross-provider benchmark for evaluating serverless function triggers based on distributed tracing. We evaluate the trigger latency (i.e., time to transition between two functions) of eight types of triggers in Microsoft Azure and three in AWS. Our results show that all triggers suffer from long tail latency, storage triggers introduce variable multi-second delays, and HTTP triggers are most suitable for interactive applications. Our insights can guide developers in choosing optimal event or messaging triggers for latency-sensitive applications. Researchers can extend TriggerBench to study the latency, scalability, and reliability of further trigger types and cloud providers.",Joel Scheuner; Marcus Bertilsson; Oskar Gronqvist; Henrik Tao; Henrik Lagergren; Jan-Philipp Steghofer; Philipp Leitner,2022 IEEE International Conference on Cloud Engineering (IC2E),2022,,,96-103,IEEE,10.1109/ic2e55432.2022.00018,https://doi.org/10.1109/ic2e55432.2022.00018,proceedings-article,Semantic Scholar,high,"Survey, Latency, Reliability Security Privacy","serverless, cloud computing, latency, reinforcement learning, distributed systems","Triggerbench, a cross-provider benchmark for evaluating serverless function triggers based on distributed tracing","Function triggering is insufficiently studied and inherently hard to measure given the distributed, ephemeral, and asynchronous nature of event-based function coordination"
paper_201,Understanding Serverless Inference in Mobile-Edge Networks: A Benchmark Approach,"Although the emerging serverless paradigm has the potential to become a dominant way of deploying cloud-service tasks across millions of mobile and IoT devices, the overhead characteristics of executing these tasks on such a volume of mobile devices remain largely unclear. To address this issue, this paper conducts a deep analysis based on the OpenFaaS platform—a popular open-source serverless platform for mobile edge environments—to investigate the overhead of performing deep learning inference tasks on mobile devices. To thoroughly evaluate the inference overhead, we develop a performance benchmark, named <italic>ESBench</italic>, whereby a set of comprehensive experiments are conducted with respect to a bunch of simulated mobile devices associated with an edge cluster. Our investigation reveals that the performance of deep learning inference tasks is significantly influenced by the model size and resource contention in mobile devices, leading to up to <inline-formula><tex-math notation=""LaTeX"">$3\times$</tex-math><alternatives><mml:math><mml:mrow><mml:mn>3</mml:mn><mml:mo>×</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href=""wang-ieq1-3521657.gif""/></alternatives></inline-formula> degradation in performance. Moreover, we observe that the network environment can negatively impact the performance of mobile inference, increasing the CPU overhead under poor network conditions. Based on our findings, we further propose some recommendations for designing efficient serverless platforms and resource management strategies as well as for deploying serverless computing in the mobile edge environment.",Junhong Chen; Yanying Lin; Shijie Peng; Shuaipeng Wu; Kenneth Kent; Hao Dai; Kejiang Ye; Yang Wang,IEEE Transactions on Cloud Computing,2025,13,1,198-212,Institute of Electrical and Electronics Engineers (IEEE),10.1109/tcc.2024.3521657,https://doi.org/10.1109/tcc.2024.3521657,journal-article,Semantic Scholar,high,"Survey, Resource Management","resource management, serverless, cloud computing, reinforcement learning, deep learning, cpu allocation, distributed systems","A performance benchmark, named <italic>esbench</italic>, whereby a set of comprehensive experiments are conducted with respect to a bunch of simulated mobile devices associated with an edge cluster","The emerging serverless paradigm has the potential to become a dominant way of deploying cloud-service tasks across millions of mobile and iot devices, the overhead characteristics of executing these tasks on such a volume of mobile devices remain largely unclear"
paper_202,Beyond Microbenchmarks: The SPEC-RG Vision for a Comprehensive Serverless Benchmark,"Serverless computing services, such as Function-as-a-Service (FaaS), hold the attractive promise of a high level of abstraction and high performance, combined with the minimization of operational logic. Several large ecosystems of serverless platforms, both open- and closed-source, aim to realize this promise. Consequently, a lucrative market has emerged. However, the performance trade-offs of these systems are not well-understood. Moreover, it is exactly the high level of abstraction and the opaqueness of the operational-side that make performance evaluation studies of serverless platforms challenging. Learning from the history of IT platforms, we argue that a benchmark for serverless platforms could help address this challenge. We envision a comprehensive serverless benchmark, which we contrast to the narrow focus of prior work in this area. We argue that a comprehensive benchmark will need to take into account more than just runtime overhead, and include notions of cost, realistic workloads, more (open-source) platforms, and cloud integrations. Finally, we show through preliminary real-world experiments how such a benchmark can help compare the performance overhead when running a serverless workload on state-of-the-art platforms.",Erwin van Eyk; Joel Scheuner; Simon Eismann; Cristina L. Abad; Alexandru Iosup,Companion of the ACM/SPEC International Conference on Performance Engineering,2020,,,26-31,ACM,10.1145/3375555.3384381,https://doi.org/10.1145/3375555.3384381,proceedings-article,Semantic Scholar,high,"Survey, Cost","serverless, cloud computing, reinforcement learning",Through preliminary real-world experiments how such a benchmark can help compare the performance overhead when running a serverless workload on state-of-the-art platforms,The performance trade-offs of these systems are not well-understood
paper_203,Serverless Deployment Methodologies: Smooth Transitions and Improved Reliability,"The advancement of cloud computing has opened doors to serverless architectures, granting developers the freedom to create and launch applications without the burden of server management. This paper explores different approaches to deploying serverless applications, namely All-At-Once Deployment, Blue-Green Deployment, Canary Deployment, A/B Testing, and Shadow Deployment. Each method is thoroughly examined to grasp its approach, advantages, and ideal usage scenarios, offering a detailed roadmap for organizations seeking to enhance their deployment workflows for improved efficiency, dependability, and reduced downtime.",Ashutosh Tripathi,International Journal of Innovative Research in Advanced Engineering,2022,9,12,510-514,AM Publications,10.26562/ijirae.2022.v0912.10,https://doi.org/10.26562/ijirae.2022.v0912.10,journal-article,Semantic Scholar,high,"Reliability Security Privacy, Energy Consumption","serverless, cloud computing, reinforcement learning","The advancement of cloud computing has opened doors to serverless architectures, granting developers the freedom to create and launch applications without the burden of server management",Not explicitly mentioned
paper_204,REPFS: Reliability-Ensured Personalized Function Scheduling in Sustainable Serverless Edge Computing,"In recent years, serverless edge computing has been widely employed in the deployments of Internet-of-things (IoT) applications. Despite considerable research efforts in this field, existing works fail to jointly consider essential factors such as energy, reliability, personalized user requirements, and stochastic application executions. This oversight results in an inefficient utilization of computation and communication resources within serverless edge computing networks, subsequently diminishing the profit of service providers and degrading the quality-of-experience (QoE) of end users. In this paper, we explore the problem of reliability-ensured personalized function scheduling (REPFS) to jointly optimize the profit of service providers and the holistic QoE of end users in sustainable serverless edge computing. A personality-driven user QoE prediction method is first designed to accurately estimate the QoE of individual end users with differentiated personality types. Afterward, a deterministic function scheduling policy is developed on the problem-specific augmented non-dominated sorting genetic algorithm II (PSA-NSGA-II). Given the inherent uncertainty of application executions, a stochastic function scheduling strategy that can be easily parallelized for modern multicore scheduler platforms is also devised to accelerate solution generation for stochastic applications. Experimental results show that our deterministic function scheduling policy achieves 15% performance enhancement compared with representative multiobjective evolutionary algorithms. Furthermore, our stochastic function scheduling strategy promotes the service profit by 78% and the holistic user QoE by 118% on average compared with the developed deterministic scheduling policy.",Kun Cao; Jian Weng,IEEE Transactions on Sustainable Computing,2024,9,3,494-511,Institute of Electrical and Electronics Engineers (IEEE),10.1109/tsusc.2023.3336691,https://doi.org/10.1109/tsusc.2023.3336691,journal-article,Semantic Scholar,high,"Reliability Security Privacy, Energy Consumption, Resource Management","serverless, energy efficiency, reinforcement learning, prediction",Novel approach to serverless computing challenges,"Considerable research efforts in this field, existing works fail to jointly consider essential factors such as energy, reliability, personalized user requirements, and stochastic application executions; Of reliability-ensured personalized function scheduling (repfs) to jointly optimize the profit of service providers and the holistic qoe of end users in sustainable serverless edge computing"
paper_205,Reliability-Aware Personalized Deployment of Approximate Computation IoT Applications in Serverless Mobile Edge Computing,"Over the past few years, the integration of mobile edge computing (MEC) and serverless computing, known as serverless MEC (SMEC), has garnered considerable attention. Despite abundant existing works on SMEC exploration, there remains an unaddressed gap in guaranteeing dependable application outputs due to ignoring the threat of both soft and bit errors on SMEC infrastructures. Furthermore, existing works fall short of accommodating the personalized requirements and approximate computation of Internet of Things (IoT) applications, thereby resulting in holistic quality-of-service (QoS) degradation of SMEC systems typically provisioned by limited edge resources. In this article, we investigate the reliability-aware personalized deployment of approximate computation IoT applications for QoS maximization in SMEC environments. To this end, we propose a hybrid methodology composed of offline and online optimization phases. At the offline phase, a decomposition-based function placement method is devised to accomplish function-to-server mapping by integrating convex optimization, cross-entropy method, and incremental control techniques. At the online phase, a lightweight reinforcement learning scheme based on proximal policy optimization (PPO) is developed to handle the inherent dynamicity of IoT applications. We also build a simulation platform upon the real-world base station distribution in Shanghai Telecom and the practical cluster trace in the Alibaba open program. Evaluations demonstrate that our hybrid approach boosts the holistic QoS by 63.9% compared with the state-of-the-art peer algorithms.",Kun Cao; Mingsong Chen; Stamatis Karnouskos; Shiyan Hu,IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems,2025,44,2,430-443,Institute of Electrical and Electronics Engineers (IEEE),10.1109/tcad.2024.3437344,https://doi.org/10.1109/tcad.2024.3437344,journal-article,Semantic Scholar,high,"Survey, Reliability Security Privacy, QoS, Resource Management","function placement, performance optimization, serverless, reinforcement learning, distributed systems",A hybrid methodology composed of offline and online optimization phases,"Abundant existing works on smec exploration, there remains an unaddressed gap in guaranteeing dependable application outputs due to ignoring the threat of both soft and bit errors on smec infrastructures"
paper_206,RL-Based Approach to Enhance Reliability and Efficiency in Autoscaling for Heterogeneous Edge Serverless Computing Environments,"Edge serverless computing represents a rapidly advancing technological paradigm with various applications across multiple computing domains. However, resource constraints and workload variability significantly impact the availability, reliability, and scalability of edge serverless systems. To mitigate these challenges, we propose the implementation of reinforcement learning (RL) to optimize dynamic autoscaling configurations within Knative for edge servers. Our research is centered on developing specialized RL environments and agents specifically designed for edge computing scenarios, considering factors such as resource limitations, network variability, and proximity to end devices. We present a system architecture incorporating an RL agent into the existing infrastructure and demonstrate its efficacy in real-world edge computing environments. The experimental results indicate that our RL-based approach outperforms manual configurations, achieving a reduction in average latency of approximately 25% (from 7–12 milliseconds to 6 milliseconds) and an increase in throughput of over 40 % (from around 150 requests to 250 requests per 300-second episode). Furthermore, our solution enhances resource utilization in terms of CPU and memory management. These findings underscore the potential of intelligent autoscaling to improve the performance, reliability, and efficiency of edge serverless applications, thereby addressing the limitations associated with static configurations. This study highlights the significant impact of dynamic reinforcement learning on enhancing the dependability, availability, and scalability of edge computing systems.",Ilyas Hadjou; Young-Woo Kwon,2024 IEEE 29th Pacific Rim International Symposium on Dependable Computing (PRDC),2024,,,163-172,IEEE,10.1109/prdc63035.2024.00046,https://doi.org/10.1109/prdc63035.2024.00046,proceedings-article,Semantic Scholar,high,"Latency, Reliability Security Privacy, Energy Consumption, Resource Management","autoscaling, serverless, latency, throughput, reinforcement learning, memory management, cpu allocation",The implementation of reinforcement learning (rl) to optimize dynamic autoscaling configurations within knative for edge servers; A system architecture incorporating an rl agent into the existing infrastructure and demonstrate its efficacy in real-world edge computing environments,"Associated with static configurations; And workload variability significantly impact the availability, reliability, and scalability of edge serverless systems"
paper_207,FaaSCtrl: A Comprehensive-Latency Controller for Serverless Platforms,"Serverless computing systems have become very popular because of their natural advantages with respect to auto-scaling, load balancing and fast distributed processing. As of today, almost all serverless systems define two QoS classes: best-effort (<inline-formula><tex-math notation=""LaTeX"">$BE$</tex-math><alternatives><mml:math><mml:mrow><mml:mi>B</mml:mi><mml:mi>E</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href=""panda-ieq1-3473015.gif""/></alternatives></inline-formula>) and latency-sensitive (<inline-formula><tex-math notation=""LaTeX"">$LS$</tex-math><alternatives><mml:math><mml:mrow><mml:mi>L</mml:mi><mml:mi>S</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href=""panda-ieq2-3473015.gif""/></alternatives></inline-formula>). Systems typically do not offer any latency or QoS guarantees for <inline-formula><tex-math notation=""LaTeX"">$BE$</tex-math><alternatives><mml:math><mml:mrow><mml:mi>B</mml:mi><mml:mi>E</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href=""panda-ieq3-3473015.gif""/></alternatives></inline-formula> jobs and run them on a best-effort basis. In contrast, systems strive to minimize the processing time for <inline-formula><tex-math notation=""LaTeX"">$LS$</tex-math><alternatives><mml:math><mml:mrow><mml:mi>L</mml:mi><mml:mi>S</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href=""panda-ieq4-3473015.gif""/></alternatives></inline-formula> jobs. This work proposes a precise definition for these job classes and argues that we need to consider a bouquet of performance metrics for serverless applications, not just a single one. We thus propose the comprehensive latency (<inline-formula><tex-math notation=""LaTeX"">$CL$</tex-math><alternatives><mml:math><mml:mrow><mml:mi>C</mml:mi><mml:mi>L</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href=""panda-ieq5-3473015.gif""/></alternatives></inline-formula>) that comprises the mean, tail latency, median and standard deviation of a series of invocations for a given serverless function. Next, we design a system <italic>FaaSCtrl</italic>, whose main objective is to ensure that every component of the <inline-formula><tex-math notation=""LaTeX"">$CL$</tex-math><alternatives><mml:math><mml:mrow><mml:mi>C</mml:mi><mml:mi>L</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href=""panda-ieq6-3473015.gif""/></alternatives></inline-formula> is within a prespecified limit for an LS application, and for BE applications, these components are minimized on a best-effort basis. Given the sheer complexity of the scheduling problem in a large multi-application setup, we use the method of surrogate functions in optimization theory to design a simpler optimization problem that relies on performance and fairness. We rigorously establish the relevance of these metrics through characterization studies. Instead of using standard approaches based on optimization theory, we use a much faster reinforcement learning (RL) based approach to tune the knobs that govern process scheduling in Linux, namely the real-time priority and the assigned number of cores. RL works well in this scenario because the benefit of a given optimization is probabilistic in nature, owing to the inherent complexity of the system. We show using rigorous experiments on a set of real-world workloads that <italic>FaaSCtrl</italic> achieves its objectives for both LS and BE applications and outperforms the state-of-the-art by 36.9% (for tail response latency) and 44.6% (for response latency's std. dev.) for LS applications.",Abhisek Panda; Smruti R. Sarangi,IEEE Transactions on Cloud Computing,2024,12,4,1328-1343,Institute of Electrical and Electronics Engineers (IEEE),10.1109/tcc.2024.3473015,https://doi.org/10.1109/tcc.2024.3473015,journal-article,Semantic Scholar,high,"Latency, QoS, Resource Management","autoscaling, performance optimization, serverless, latency, load balancing, reinforcement learning, distributed systems","Using rigorous experiments on a set of real-world workloads that <italic>faasctrl</italic> achieves its objectives for both ls and be applications and outperforms the state-of-the-art by 36; A system <italic>faasctrl</italic>, whose main objective is to ensure that every component of the <inline-formula><tex-math notation=""latex"">$cl$</tex-math><alternatives><mml:math><mml:mrow><mml:mi>c</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:math><inline-graphic xlink:href=""panda-ieq6-3473015","In a large multi-application setup, we use the method of surrogate functions in optimization theory to design a simpler optimization problem that relies on performance and fairness"
paper_208,Caching Techniques to Improve Latency in Serverless Architectures,"Serverless computing has gained a significant traction in recent times because of its simplicity of development, deployment and fine-grained billing. However, while implementing complex services comprising databases, file stores, or more than one serverless function, the performance in terms of latency of serving requests often degrades severely. In this work, we analyze different serverless architectures with AWS Lambda services and compare their performance in terms of latency with a traditional virtual machine (VM) based approach. We observe that database access latency in serverless architecture is almost 14 times than that in VM based setup. Further, we introduce some caching strategies which can improve the response time significantly, and compare their performance.",Bishakh Chandra Ghosh; Sourav Kanti Addya; Nishant Baranwal Somy; Shubha Brata Nath; Sandip Chakraborty; Soumya K Ghosh,2020 International Conference on COMmunication Systems &amp; NETworkS (COMSNETS),2020,,,666-669,IEEE,10.1109/comsnets48256.2020.9027427,https://doi.org/10.1109/comsnets48256.2020.9027427,proceedings-article,Semantic Scholar,high,"Latency, Cost","serverless, latency, reinforcement learning","Some caching strategies which can improve the response time significantly, and compare their performance","While implementing complex services comprising databases, file stores, or more than one serverless function, the performance in terms of latency of serving requests often degrades severely; Services comprising databases, file stores, or more than one serverless function, the performance in terms of latency of serving requests often degrades severely"
paper_209,Towards Latency-Aware Linux Scheduling for Serverless Workloads,"A key principle in the design of the Linux kernel's Completely Fair Scheduler (CFS) is fairness: all running tasks receive a minimum time slice during every scheduling period, ensuring that none starve. However, this may lead to a significant number of context switches when a server is overloaded with a large number of colocated tasks, which may cause significant degradation in server performance. Unfortunately, this situation is exactly what we found when hosting serverless-style workloads which typically consist of a large number of short-lived, CPU-bound functions sharing resources. We propose modifying the Linux CFS to mitigate this problem by giving priority to the long tail of least loaded functions. These are the functions which are mostly idle and only run occasionally for a short while after being triggered unexpectedly. The large number of such functions in serverless environments means that prioritising them helps drain contended CPU run queues, reducing the total overhead due to context switching, thereby improving the performance not only of the prioritised functions but other functions as well. We implement this policy in the Linux kernel scheduler and demonstrate how it integrates well with Knative, an open source Kubernetes-based serverless framework. Given contention scenarios synthesised from real-world traces, our modified CFS can introduce a 5--30% increase in attainment of latency targets.",Al Amjad Tawfiq Isstaif; Richard Mortier,"Proceedings of the 1st Workshop on SErverless Systems, Applications and MEthodologies",2023,,,19-26,ACM,10.1145/3592533.3592807,https://doi.org/10.1145/3592533.3592807,proceedings-article,Semantic Scholar,high,"Latency, Resource Management","serverless, latency, queuing, reinforcement learning, cpu allocation","Modifying the linux cfs to mitigate this problem by giving priority to the long tail of least loaded functions; This policy in the linux kernel scheduler and demonstrate how it integrates well with knative, an open source kubernetes-based serverless framework; 30% increase","This may lead to a significant number of context switches when a server is overloaded with a large number of colocated tasks, which may cause significant degradation in server performance; Other functions as well"
paper_210,Analyzing Tail Latency in Serverless Clouds with STeLLAR,"Serverless computing has seen rapid adoption because of its instant scalability, flexible billing model, and economies of scale. In serverless, developers structure their applications as a collection of functions invoked by various events like clicks, and cloud providers take responsibility for cloud infrastructure management. As with other cloud services, serverless deployments require responsiveness and performance predictability manifested through low average and tail latencies. While the average end-to-end latency has been extensively studied in prior works, existing papers lack a detailed characterization of the effects of tail latency in real-world serverless scenarios and their root causes. In response, we introduce STeLLAR, an open-source serverless benchmarking framework, which enables an accurate performance characterization of serverless deployments. STeLLAR is provider-agnostic and highly configurable, allowing the analysis of both end-to-end and per-component performance with minimal instrumentation effort. Using STeLLAR, we study three leading serverless clouds and reveal that storage accesses and bursty function invocation traffic are key factors impacting tail latency in modern serverless systems. Finally, we identify important factors that do not contribute to latency variability, such as the choice of language runtime.",Dmitrii Ustiugov; Theodor Amariucai; Boris Grot,2021 IEEE International Symposium on Workload Characterization (IISWC),2021,,,51-62,IEEE,10.1109/iiswc53511.2021.00016,https://doi.org/10.1109/iiswc53511.2021.00016,proceedings-article,Semantic Scholar,high,"Survey, Latency, Cost","serverless, cloud computing, latency, reinforcement learning","Stellar, an open-source serverless benchmarking framework, which enables an accurate performance characterization of serverless deployments",Not explicitly mentioned
paper_211,A Review: Cold Start Latency in Serverless Computing,"The worldview of serverless computing addresses a significant evolutionary leap to smooth out the designer experience. Serverless computing, a feature of the cloud computing, seeks to ease the devlopers from the weights related with the server organization and essential infrastructure choices. Generally, it endeavors to satisfy its essential responsibility by releiving the designers from worries connected with server arrangement, setup, and scaling. The integration of FaaS plays a vital part in understanding the execution of serverless computing. This state of the art approach of the cloud computing works on application configuration, offering designers the capacity to evade server management through the reception of the ongoing Serverless Computing Paradigm. Working on a computational architecture that uses discrete functions as executables. These functions are sent exclusively on a serverless stage, giving quick adaptability per request to the clients. However, this adaptability frequently leads to the test known as the “Cold Starts”, where the delays happen during the task allocation to a runtime container. Presented by Amazon in 2014, AWS Lambda is one of the noticeable illustration of serverless computing architecture. Post-launch, different entities, incorporating both open-source and for benefit associations, embraced and popularized this innovation. Eminently, every platform tends to cold starts uniquely, provoking broad examination of every platforms performance under conditions comparable to the cold start in the recent years. This paper offers a top to bottom survey of the most recent progressions and cutting edge examinations in the space of serverless engineering for cold start interval reduction. By digging into the complexities of different platform performance and their ways to deal with the mitigation of the cold start challenge, this review aims to contribute significant insights to the continuous talk in the field of serverless computing.",Parikshit Verma; Paurav Goel; Neetu Rani,2024 Sixth International Conference on Computational Intelligence and Communication Technologies (CCICT),2024,,,141-148,IEEE,10.1109/ccict62777.2024.00034,https://doi.org/10.1109/ccict62777.2024.00034,proceedings-article,Semantic Scholar,high,"Survey, Latency, Resource Management","cold start, autoscaling, serverless, containerization, cloud computing, latency, reinforcement learning",Novel approach to serverless computing challenges,"This adaptability frequently leads to the test known as the “cold starts”, where the delays happen during the task allocation to a runtime container"
paper_212,Empirical Evaluation of Cold Start Latency in Serverless Platforms,"Serverless computing has gained significant popularity as a cloud-based alternative for creating, testing, and deploying applications as serverless operations. Serverless computing has gained significant attention in both industry and academics due to the introduction of serverless platforms by major IT companies. The primary characteristics of this system include autonomous design, seamless deployment, and automatic scalability, with Function-as-a-Service (FaaS) being a widely used implementation. Nevertheless, due to the emergence of serverless platforms, it has become necessary to migrate microservices to serverless in order to create effective applications with streamlined infrastructure management, less operational burden, and cost savings. Furthermore, current research indicates that serverless solutions experience cold start latency. One recent study recommends the best programming language to use in serverless platforms which yields low cold start latency. Considering the those programming language, In this work, we try to compare the performance of serverless functions. Those functions that are implemented as serverless applications demonstrate enhanced response time and throughput. Ultimately we are going to discover that is there any impact of code size on cold start on serverless platforms. After empirical analysis, It is observed that there is no relation between code size and cold start.",Vinay Raj; Himanshu Chhaparwal; Satwik Saale,2024 3rd International Conference for Advancement in Technology (ICONAT),2024,,,6-Jan,IEEE,10.1109/iconat61936.2024.10775275,https://doi.org/10.1109/iconat61936.2024.10775275,proceedings-article,Semantic Scholar,high,"Survey, Latency, Cost","cold start, serverless, microservices, cloud computing, latency, throughput, reinforcement learning",Novel approach to serverless computing challenges,Cold Start
paper_213,Real-Time FaaS: Towards a Latency Bounded Serverless Cloud,"Today, Function-as-a-Service is the most promising concept of serverless cloud computing. It makes possible for developers to focus on application development without any system management effort: FaaS ensures resource allocation, fast response time, schedulability, scalability, resiliency, and upgradability. Applications of 5G, IoT, and Industry 4.0 raise the idea to open cloud-edge computing infrastructures for time-critical applications too, i.e., there is a strong desire to pose real-time requirements for computing systems like FaaS. However, multi-node systems make real-time scheduling significantly complex since guaranteeing real-time task execution and communication is challenging even on one computing node with multi-core processors. In this paper, we present an analytical model and a heuristic partitioning scheduling algorithm suitable for real-time FaaS platforms of multi-node clusters. We show that our task scheduling heuristics could outperform existing algorithms by 55%. Furthermore, we propose three conceptual designs to enable the necessary real-time communications. We present the architecture of the envisioned real-time FaaS platform, emphasize its benefits and the requirements for the underlying network and nodes, and survey the related work that could meet these demands.",Márk Szalay; Péter Mátray; László Toka,IEEE Transactions on Cloud Computing,2023,11,2,1636-1650,Institute of Electrical and Electronics Engineers (IEEE),10.1109/tcc.2022.3151469,https://doi.org/10.1109/tcc.2022.3151469,journal-article,Semantic Scholar,high,"Survey, Latency, Resource Management","resource management, serverless, cloud computing, latency, reinforcement learning, cpu allocation, distributed systems","Three conceptual designs to enable the necessary real-time communications; An analytical model and a heuristic partitioning scheduling algorithm suitable for real-time faas platforms of multi-node clusters; The architecture of the envisioned real-time faas platform, emphasize its benefits and the requirements for the underlying network and nodes, and survey the related work that could meet these demands",Multi-node systems make real-time scheduling significantly complex since guaranteeing real-time task execution and communication is challenging even on one computing node with multi-core processors; Since guaranteeing real-time task execution and communication is challenging even on one computing node with multi-core processors
paper_214,Operating Latency Sensitive Applications on Public Serverless Edge Cloud Platforms,"Cloud native programming and serverless architectures provide a novel way of software development and operation. A new generation of applications can be realized with features never seen before while the burden on developers and operators will be reduced significantly. However, latency sensitive applications, such as various distributed IoT services, generally do not fit in well with the new concepts and today’s platforms. In this article, we adapt the cloud native approach and related operating techniques for latency sensitive IoT applications operated on public serverless platforms. We argue that solely adding cloud resources to the edge is not enough and other mechanisms and operation layers are required to achieve the desired level of quality. Our contribution is threefold. First, we propose a novel system on top of a public serverless edge cloud platform, which can dynamically optimize and deploy the microservice-based software layout based on live performance measurements. We add two control loops and the corresponding mechanisms which are responsible for the online reoptimization at different timescales. The first one addresses the steady-state operation, while the second one provides fast latency control by directly reconfiguring the serverless runtime environments. Second, we apply our general concepts to one of today’s most widely used and versatile public cloud platforms, namely, Amazon’s AWS, and its edge extension for IoT applications, called Greengrass. Third, we characterize the main operation phases and evaluate the overall performance of the system. We analyze the performance characteristics of the two control loops and investigate different implementation options.",Istvan Pelle; Janos Czentye; Janos Doka; Andras Kern; Balazs P. Gero; Balazs Sonkoly,IEEE Internet of Things Journal,2021,8,10,7954-7972,Institute of Electrical and Electronics Engineers (IEEE),10.1109/jiot.2020.3042428,https://doi.org/10.1109/jiot.2020.3042428,journal-article,Semantic Scholar,high,"Latency, Energy Consumption, Resource Management","performance optimization, serverless, cloud computing, latency, reinforcement learning, distributed systems","A novel system on top of a public serverless edge cloud platform, which can dynamically optimize and deploy the microservice-based software layout based on live performance measurements","Latency sensitive applications, such as various distributed iot services, generally do not fit in well with the new concepts and today’s platforms"
paper_215,Implementation of Low-Latency Message Delivery for Serverless Based Workflow,"The serverless platforms offer an orchestration tool that supports composing workflow with the serverless functions on their platform. This orchestration tool creates an independent function that invokes other serverless functions step by step. However, since the existing serverless platform does not consider the execution of the workflow, the messages between functions are delivered inefficiently. We implemented a layered message bus to improve message delivery latency when executing a workflow in the serverless environment. Our implementation shows 205.37x and 56.12x improvement in the best and the worst case, respectively, compared to OpenWhisk Composer.",Seunghyn Hwang; Heeseok Choi; Heonchang Yu,2019 IEEE 16th International Conference on Mobile Ad Hoc and Sensor Systems Workshops (MASSW),2019,,,170-171,IEEE,10.1109/massw.2019.00044,https://doi.org/10.1109/massw.2019.00044,proceedings-article,Semantic Scholar,high,"Latency, Resource Management","serverless, latency, reinforcement learning",12x improvement,"Since the existing serverless platform does not consider the execution of the workflow, the messages between functions are delivered inefficiently"
paper_216,FaaSt: A Latency-Aware Serverless Scheme for Edge-Cloud Environments,"Serverless computing offers an effective way to improve resource utilization and can significantly leverage edge-cloud environments. In this context, serverless request response times are one of the main focuses for optimization. However, the end-to-end routing path from a request to a function, which considerably contributes to the overall delay, is often overlooked. This oversight raises concerns about the actual performance of serverless in edge-cloud deployments, as serverless architectures are initially designed for cloud computing where node-to-node delay is negligible. To address this concern, our paper examines the current serverless networking design in a realistic edge-cloud setup. Our findings reveal significant performance degradation when serverless is applied in such environments due to key mismatches in the networking architecture. To mitigate these issues, we propose a novel latency-aware scheme and a load balancing mechanism for edge-cloud environments, called FaaSt. This proposal is implemented using open sources and standards, resulting in a significant reduction in response times.",Kien Nguyen; Hiep Dao; Tung Nguyen; Frank Loh; Nguyen Huu Thanh; Tobias Hoβfeld,2024 IEEE 13th International Conference on Cloud Networking (CloudNet),2024,,,9-Jan,IEEE,10.1109/cloudnet62863.2024.10815895,https://doi.org/10.1109/cloudnet62863.2024.10815895,proceedings-article,Semantic Scholar,high,"Latency, Resource Management","performance optimization, serverless, cloud computing, latency, load balancing, reinforcement learning","A novel latency-aware scheme and a load balancing mechanism for edge-cloud environments, called faast","The end-to-end routing path from a request to a function, which considerably contributes to the overall delay, is often overlooked"
paper_217,Latency-Sensitive Function Placement among Heterogeneous Nodes in Serverless Computing,"Function as a Service (FaaS) is highly beneficial to smart city infrastructure due to its flexibility, efficiency, and adaptability, specifically for integration in the digital landscape. FaaS has serverless setup, which means that an organization no longer has to worry about specific infrastructure management tasks; the developers can focus on how to deploy and create code efficiently. Since FaaS aligns well with the IoT, it easily integrates with IoT devices, thereby making it possible to perform event-based actions and real-time computations. In our research, we offer an exclusive likelihood-based model of adaptive machine learning for identifying the right place of function. We employ the XGBoost regressor to estimate the execution time for each function and utilize the decision tree regressor to predict network latency. By encompassing factors like network delay, arrival computation, and emphasis on resources, the machine learning model eases the selection process of a placement. In replication, we use Docker containers, focusing on serverless node type, serverless node variety, function location, deadlines, and edge-cloud topology. Thus, the primary objectives are to address deadlines and enhance the use of any resource, and from this, we can see that effective utilization of resources leads to enhanced deadline compliance.",Urooba Shahid; Ghufran Ahmed; Shahbaz Siddiqui; Junaid Shuja; Abdullateef Oluwagbemiga Balogun,Sensors,2024,24,13,4195,MDPI AG,10.3390/s24134195,https://doi.org/10.3390/s24134195,journal-article,Semantic Scholar,high,"Latency, Energy Consumption, Resource Management","function placement, serverless, containerization, cloud computing, latency, reinforcement learning, deadline","Faas has serverless setup, which means that an organization no longer has to worry about specific infrastructure management tasks; the developers can focus on how to deploy and create code efficiently",Network Latency
paper_218,Dynamic Storage Selection for Mitigating Tail Latency in Serverless Pipelines,"In the rapidly evolving landscape of cloud computing, serverless computing has seen significant growth, offering a user-friendly programming interface for building scalable microservices at reduced costs. However, due to its stateless nature, managing intermediate results in complex application pipelines is challenging due to the need for distributed object storage like Azure Blob Storage, AWS S3, or Redis. To address this challenge, we propose HyperStore, an ephemeral storage management framework that features a smart function container enabling seamless and real-time interaction with various storage providers, without altering the function code. Furthermore, HyperStore dynamically determines and selects the optimal storage for each pipeline function to meet Service Level Objectives (SLOs) at minimal cost and mitigate tail latency. Our framework can be integrated with existing Serverless systems such as OpenFaas, allowing function containers to communicate via a shared host volume for reduced latency in case of function co-location. Our detailed experimental results demonstrate the efficiency and advantages of our approach.",Michail Tsenos; Aristotelis Peri; Vana Kalogeraki,2024 IEEE International Conference on Autonomic Computing and Self-Organizing Systems (ACSOS),2024,,,111-120,IEEE,10.1109/acsos61780.2024.00029,https://doi.org/10.1109/acsos61780.2024.00029,proceedings-article,Semantic Scholar,high,"Latency, Cost, Energy Consumption","serverless, containerization, microservices, cloud computing, latency, reinforcement learning, distributed systems","Hyperstore, an ephemeral storage management framework that features a smart function container enabling seamless and real-time interaction with various storage providers, without altering the function code; Can be integrated with existing serverless systems such as openfaas, allowing function containers to communicate via a shared host volume for reduced latency in case of function co-location","Due to its stateless nature, managing intermediate results in complex application pipelines is challenging due to the need for distributed object storage like azure blob storage, aws s3, or redis; Application pipelines is challenging due to the need for distributed object storage like azure blob storage, aws s3, or redis"
paper_219,Mitigating Serverless Tail Latency: A Comprehensive Study of Factors and Strategies,"Serverless computing has gained widespread popularity due to its ability to dynamically allocate resources and abstract away the underlying infrastructure, allowing developers to focus on writing code without the need to manage servers. However, one challenge in serverless computing is tail latency, which refers to the time taken by the slowest requests to complete. High tail latency can result in poor user experience and decreased application performance. This research paper aims to explore techniques and best practices to reduce tail latency in serverless computing environments. We have reviewed the existing literature, identify the key factors affecting tail latency, and analyze various approaches and strategies to mitigate tail latency in serverless computing. Some real-world use cases and practical recommendations for developers and practitioners in term of tail latency in serverless computing to optimize the performance of serverless applications are also presented.",Anisha Kumari; Ranjan Kumar Behera; Bibhudatta Sahoo,2023 OITS International Conference on Information Technology (OCIT),2023,,,369-374,IEEE,10.1109/ocit59427.2023.10431282,https://doi.org/10.1109/ocit59427.2023.10431282,proceedings-article,Semantic Scholar,high,"Survey, Latency, Resource Management","serverless, latency, reinforcement learning","Serverless computing has gained widespread popularity due to its ability to dynamically allocate resources and abstract away the underlying infrastructure, allowing developers to focus on writing code without the need to manage servers","In serverless computing is tail latency, which refers to the time taken by the slowest requests to complete; One challenge in serverless computing is tail latency, which refers to the time taken by the slowest requests to complete"
paper_220,Startup Latency Analysis in Java Frameworks for Serverless AWS Lambda Deployments.,"Cold start latency in serverless computing, particularly in Java-based AWS Lambda functions, presents a significant challenge for latency-sensitive applications. This study investigates the performance characteristics of three modern Java frameworks - Spring Boot, Micronaut, and Quarkus - deployed on AWS Lambda using the ARM64 (Graviton2) architecture. It evaluates cold start latency across three deployment configurations: managed runtime (with and without SnapStart) and GraalVM native images. Metrics were collected at varying memory allocations using Java 21. Results show that Quarkus consistently outperforms others in cold start latency on standard JVM, while SnapStart and GraalVM significantly reduce the number of cold starts and achieve sub-second latency, respectively. We discuss the implications of these findings for choosing a Java framework and runtime strategy on AWS Lambda, considering the trade-offs in deployment time, complexity, and performance. The paper concludes with recommendations for leveraging SnapStart and native images to mitigate cold start issues in Java serverless applications on ARM64.",Maksimov Viacheslav Yurievich,The American Journal of Engineering and Technology,2025,7,4,16-21,The USA Journals,10.37547/tajet/volume07issue04-03,https://doi.org/10.37547/tajet/volume07issue04-03,journal-article,Semantic Scholar,high,"Survey, Latency, Resource Management","cold start, serverless, latency, reinforcement learning, memory management","Cold start latency in serverless computing, particularly in java-based aws lambda functions, presents a significant challenge for latency-sensitive applications",For latency-sensitive applications; In java serverless applications on arm64
paper_221,"Nightcore: efficient and scalable serverless computing for latency-sensitive, interactive microservices","The microservice architecture is a popular software engineering approach for building flexible, large-scale online services. Serverless functions, or function as a service (FaaS), provide a simple programming model of stateless functions which are a natural substrate for implementing the stateless RPC handlers of microservices, as an alternative to containerized RPC servers. However, current serverless platforms have millisecond-scale runtime overheads, making them unable to meet the strict sub-millisecond latency targets required by existing interactive microservices. We present Nightcore, a serverless function runtime with microsecond-scale overheads that provides container-based isolation between functions. Nightcore’s design carefully considers various factors having microsecond-scale overheads, including scheduling of function requests, communication primitives, threading models for I/O, and concurrent function executions. Nightcore currently supports serverless functions written in C/C++, Go, Node.js, and Python. Our evaluation shows that when running latency-sensitive interactive microservices, Nightcore achieves 1.36×–2.93× higher throughput and up to 69% reduction in tail latency.",Zhipeng Jia; Emmett Witchel,Proceedings of the 26th ACM International Conference on Architectural Support for Programming Languages and Operating Systems,2021,,,152-166,ACM,10.1145/3445814.3446701,https://doi.org/10.1145/3445814.3446701,proceedings-article,Semantic Scholar,high,"Survey, Latency, Resource Management","serverless, containerization, microservices, latency, throughput, reinforcement learning","Nightcore, a serverless function runtime with microsecond-scale overheads that provides container-based isolation between functions; 69% reduction; 69% reduction","Current serverless platforms have millisecond-scale runtime overheads, making them unable to meet the strict sub-millisecond latency targets required by existing interactive microservices"
paper_222,Low-Latency State Management for Real-Time Tasks in Edge Serverless,"Stateful serverless systems commonly adopt an architectural paradigm characterized by compute and storage separation within cloud data centers. Nevertheless, guaranteeing prompt response for real-time tasks at the edge becomes challenging due to network overheads. This paper introduces a Low-Latency state management framework for real-time tasks in edge serverless systems called LoLa, which adaptively places states proximate to functions, thereby mitigating delays in accessing states within edge serverless systems. Our approach aims at mitigating network latency and optimizing resource utilization by co-locating functions and states, thereby enhancing the system’s overall efficiency. We introduce an adaptive strategy to coordinate the migration of states. It dynamically adjusts the positions of states based on historical data and real-time feedback. Additionally, we designed an in-memory state storage mechanism to facilitate low-latency access and implement a lightweight and fine-grained state management to ensure stored state consistency. Evaluation results showcase the efficacy of LoLa in reducing state read and write latency within edge serverless systems. Specifically, the average response latency is observed to decrease by 65.2% and 38.1% in the best and worst-case scenarios, respectively.",Yanyan Wen; Guangping Xu; Jianshe Wang; Wei Hao,2024 IEEE International Symposium on Parallel and Distributed Processing with Applications (ISPA),2024,,,17-Oct,IEEE,10.1109/ispa63168.2024.00010,https://doi.org/10.1109/ispa63168.2024.00010,proceedings-article,Semantic Scholar,high,"Survey, Latency, Energy Consumption, Resource Management","serverless, cloud computing, latency, reinforcement learning, memory management","An adaptive strategy to coordinate the migration of states; A low-latency state management framework for real-time tasks in edge serverless systems called lola, which adaptively places states proximate to functions, thereby mitigating delays in accessing states within edge serverless systems; Aims at mitigating network latency and optimizing resource utilization by co-locating functions and states, thereby enhancing the system’s overall efficiency",State Management; Network Latency
paper_223,"Low-latency Serverless Computing: Characterization, Optimization and Outlooking: JCC 2021 Invited Keynote","Serverless computing promises cost-efficiency and elasticity for high-productive software development. To achieve this, the serverless computing platform must address two challenges: strong isolation between function instances, and low startup latency to ensure user experience. In this talk, I will first present a characterization of state-of-the-art serverless platform and derive several key metrics, which collectly forms a systematic methodology and a benchmark called severlessbench. Then, I will show how severless platform can be optimized for (sub-)millisecond startup latency for both normal and condential severless computing. Finally, I will present an outlook on challenges and opportunities of serverless comptuting, including how to make it secure and efficient for joint cloud computing.",Haibo Chen,2021 IEEE International Conference on Joint Cloud Computing (JCC),2021,,,xii-xii,IEEE,10.1109/jcc53141.2021.00008,https://doi.org/10.1109/jcc53141.2021.00008,proceedings-article,Semantic Scholar,high,"Survey, Latency, Cost, Energy Consumption","performance optimization, serverless, cloud computing, latency, elasticity, reinforcement learning",Serverless computing promises cost-efficiency and elasticity for high-productive software development,"And opportunities of serverless comptuting, including how to make it secure and efficient for joint cloud computing"
paper_224,FLASH: Low-Latency Serverless Model Inference with Multi-Core Parallelism in Edge,"Low response latency holds a pivotal role in the landscape of edge deep learning model inference, yet the constrained resources within edge computing environments often limit its full potential. Within the scope of this paper, we substantiate that even amid the resource limitations inherent to edge computing environments, it remains feasible to curtail model response latency by elevating multi-core parallel efficiency. Our research encompasses a comprehensive analysis of the parallel acceleration effects observed across models featuring diverse parameter magnitudes during the inference process. This analysis culminates in the development of FLASH, an online deep model inference system tailored for Serverless edge inference, strategically optimized through the utilization of multi-core parallelism. FLASH exhibits dynamic adaptability by modulating the number of CPU cores within computational instances in accordance with traffic request loads. It also employs a dynamic scaling mechanism to finely adjust model placement, ultimately facilitating inference acceleration and mitigating the concomitant cold start overhead. Empirical experimentation conducted across a spectrum of burst-level workloads serves to underscore FLASH’s capacity, resulting in an average reduction in response latency by 33% and a maximum reduction of 75%, while concurrently realizing a throughput enhancement of 2.94x.",Yanbo Li; Yanying Lin; Shijie Peng; Yingfei Tang; Tian Xiang; Wei Song; Kejiang Ye,2023 IEEE 29th International Conference on Parallel and Distributed Systems (ICPADS),2023,,,2640-2646,IEEE,10.1109/icpads60453.2023.00350,https://doi.org/10.1109/icpads60453.2023.00350,proceedings-article,Semantic Scholar,high,"Survey, Latency, Energy Consumption, Resource Management","cold start, autoscaling, function placement, serverless, latency, throughput, reinforcement learning, deep learning, cpu allocation",Novel approach to serverless computing challenges,"Inherent to edge computing environments, it remains feasible to curtail model response latency by elevating multi-core parallel efficiency"
paper_225,Implementing Serverless Architectures for Ultra-Low Latency Data Pipelines in Multiplayer Gaming Environments,"Real-time, competitive gaming has also resulted in higher demands of ultra-low latency in multiplayer gaming environments. Scalability and performance of the Traditional client-server models are a problem when the number of players involved and the speed of interactions is high, which introduces problems of latency, lag and synchronization errors. The current paper discusses the usage of serverless architectures as the means of addressing such issues. Serverless computing fully manages the infrastructure, providing developers with an opportunity to write event-driven code, automatically scaling the resources depending on the demand. AWS Lambda, Azure Functions, and Google Cloud Functions are services that offer low latency and scalable solutions to real-time multiplayer games. This paper presents an architectural overview, design, and implementation of serverless systems, analyses the performance monitor, and finally states the benefits of serverless computing when used in serving dynamical gaming workloads. It also discusses how serverless technologies may affect multiplayer gaming industry in future by improving scalability, cutting down operational costs and ensuring uninterrupted gaming experience to the players.",Urvangkumar Kothari -,Journal of Advances in Developmental Research,2022,13,2,,International Research Publication and Journals,10.71097/ijaidr.v13.i2.1477,https://doi.org/10.71097/ijaidr.v13.i2.1477,journal-article,Semantic Scholar,high,"Survey, Latency, Cost, Resource Management","autoscaling, serverless, cloud computing, latency, reinforcement learning","An architectural overview, design, and implementation of serverless systems, analyses the performance monitor, and finally states the benefits of serverless computing when used in serving dynamical gaming workloads","When the number of players involved and the speed of interactions is high, which introduces problems of latency, lag and synchronization errors"
paper_226,"Cold Start Latency in Serverless Computing: A Systematic Review, Taxonomy, and Future Directions","Recently, academics and the corporate sector have paid attention to
serverless computing, which enables dynamic scalability and an economic model.
In serverless computing, users only pay for the time they actually use
resources, enabling zero scaling to optimise cost and resource utilisation.
However, this approach also introduces the serverless cold start problem.
Researchers have developed various solutions to address the cold start problem,
yet it remains an unresolved research area. In this article, we propose a
systematic literature review on clod start latency in serverless computing.
Furthermore, we create a detailed taxonomy of approaches to cold start latency,
which we use to investigate existing techniques for reducing the cold start
time and frequency. We have classified the current studies on cold start
latency into several categories such as caching and application-level
optimisation-based solutions, as well as Artificial Intelligence (AI)/Machine
Learning (ML)-based solutions. Moreover, we have analyzed the impact of cold
start latency on quality of service, explored current cold start latency
mitigation methods, datasets, and implementation platforms, and classified them
into categories based on their common characteristics and features. Finally, we
outline the open challenges and highlight the possible future directions.",Muhammed Golec; Guneet Kaur Walia; Mohit Kumar; Felix Cuadrado; Sukhpal Singh Gill; Steve Uhlig,ACM Computing Surveys,2025,57,3,1-36,Association for Computing Machinery (ACM),10.1145/3700875,https://doi.org/10.1145/3700875,journal-article,arXiv,high,"Survey, Latency, QoS, Cost, Resource Management","cold start, autoscaling, serverless, latency, reinforcement learning","A
systematic literature review on clod start latency in serverless computing",And highlight the possible future directions; This approach also introduces the serverless cold start problem
paper_227,Dynamic Pre-Warm Strategies for Reducing Cold-Start Latency in Serverless Edge Computing,"Serverless edge computing uses lightweight containers to execute IoT applications on-demand, enhancing resource utilization efficiency at the network edge. However, cold-start latency, occurring when a container is instantiated from scratch, degrades IoT service responsiveness. Effective mitigation strategies are needed to maintain service quality. Current container caching strategies often fail to account for diverse workloads and predictable request patterns. This paper introduces a dynamic container pre-warm model that adjusts container states based on predicted future requests, mitigating cold-start overhead. Our approach employs a real-time algorithm for container instantiation and termination, balancing latency reduction and resource conservation. Inte-grating predictive analytics with adaptive resource management, we evaluate our model using a trace-driven simulation framework with real-world data. Our experiments show that the proposed strategy reduces cold starts by up to 60 % and improves average response times by 45 % compared to state-of-the-art methods. Additionally, our approach adapts to varying workloads, providing a scalable and robust solution for dynamic edge environments.",Yicong Song; Baoliu Ye; Yue Zeng; Xindong Wang,"2024 20th International Conference on Mobility, Sensing and Networking (MSN)",2024,,,228-235,IEEE,10.1109/msn63567.2024.00040,https://doi.org/10.1109/msn63567.2024.00040,proceedings-article,Semantic Scholar,high,"Latency, QoS, Energy Consumption, Resource Management","cold start, resource management, serverless, containerization, latency, reinforcement learning, prediction","A dynamic container pre-warm model that adjusts container states based on predicted future requests, mitigating cold-start overhead; Employs a real-time algorithm for container instantiation and termination, balancing latency reduction and resource conservation; Adapts to varying workloads, providing a scalable and robust solution for dynamic edge environments","Cold-start latency, occurring when a container is instantiated from scratch, degrades iot service responsiveness"
paper_228,Improving Application Migration to Serverless Computing Platforms: Latency Mitigation with Keep-Alive Workloads,"Serverless computing platforms provide Function(s)-as-a-Service (FaaS) to end users while promising reduced hosting costs, high availability, fault tolerance, and dynamic elasticity for hosting individual functions known as microservices. Serverless Computing environments abstract infrastructure management including creation of virtual machines (VMs), containers, and load balancing from users. To conserve cloud server capacity and energy, cloud providers allow serverless computing infrastructure to go COLD, deprovisioning hosting infrastructure when demand falls, freeing capacity to be harnessed by others. In this paper, we present on a case study migration of the Precipitation Runoff Modeling System (PRMS), a Java-based environmental modeling application to the AWS Lambda serverless platform. We investigate performance and cost implications of memory reservation size, and evaluate scaling performance for increasing concurrent workloads. We then investigate the use of Keep-Alive workloads to preserve serverless infrastructure to minimize cold starts and ensure fast performance after idle periods for up to 100 concurrent client requests. We show how Keep-Alive workloads can be generated using cloud-based scheduled event triggers, enabling minimization of costs, to provide VM-like performance for applications hosted on serverless platforms for a fraction of the cost.",Wes Lloyd; Minh Vu; Baojia Zhang; Olaf David; George Leavesley,2018 IEEE/ACM International Conference on Utility and Cloud Computing Companion (UCC Companion),2018,,,195-200,IEEE,10.1109/ucc-companion.2018.00056,https://doi.org/10.1109/ucc-companion.2018.00056,proceedings-article,Semantic Scholar,high,"Latency, Reliability Security Privacy, Cost, Energy Consumption, Resource Management","cold start, autoscaling, serverless, containerization, microservices, cloud computing, latency, elasticity, load balancing, energy efficiency, reinforcement learning, memory management","On a case study migration of the precipitation runoff modeling system (prms), a java-based environmental modeling application to the aws lambda serverless platform; How keep-alive workloads can be generated using cloud-based scheduled event triggers, enabling minimization of costs, to provide vm-like performance for applications hosted on serverless platforms for a fraction of the cost; 100 concurrent",Cold Start
paper_229,A Low-Latency Edge-Cloud Serverless Computing Framework with a Multi-Armed Bandit Scheduler,"Recently, serverless computing, particularly the Function-as-a-Service (FaaS) programming model, has become an important emerging technology for developers and cloud providers. It relieves developers from the burden of explicitly managing the computing resources and provides more accurate billing of the exact service and execution time. However, as a side effect of the service-side resource management, the system often inactivates a set of execution dockers, introducing a significant cold start time for the following invocation, resulting in unpredictable latency. Existing solutions mainly rely on improving an end-point management policy or scheduling into other same-tier endpoints and, more recently, considering a promising but simplified edge-cloud tier with available management information. The latter can mitigate latency by relying on offloading to a resource-rich cloud. In this paper, we consider extending the two-tier edge-cloud approach to not rely on any management information from the service side or account for function-dependent communication latency but to rely on a scheduler based on the multi-armed bandit (MAB) upper confidence bound (UCB) algorithm that dynamically learns from the prevailing real-time conditions to choose the best cloud platform to execute functions with minimal latency. A test bed was implemented, comprising an OpenWhisk system deployed on a local Kubernetes cluster (kind) and two commercial FaaS systems: Amazon Web Services (AWS) Lambda and Google Cloud Functions (GCF). The scheduler was tested in real-time using the serverless benchmark suite (SeBS). Our results show that the MAB UCB is superior to single-tier systems. The MAB UCB can achieve execution time within a close margin of an oracle scheduler and also can fail in some extreme cases.",Justin Chigu; Ahmed El-Mahdy; Bassem Mokhtar; Maha Elsabrouty,2024 International Wireless Communications and Mobile Computing (IWCMC),2024,,,1655-1660,IEEE,10.1109/iwcmc61514.2024.10592558,https://doi.org/10.1109/iwcmc61514.2024.10592558,proceedings-article,Semantic Scholar,high,"Survey, Latency, Cost, Resource Management","cold start, resource management, serverless, cloud computing, latency, reinforcement learning, distributed systems","Recently, serverless computing, particularly the function-as-a-service (faas) programming model, has become an important emerging technology for developers and cloud providers","As a side effect of the service-side resource management, the system often inactivates a set of execution dockers, introducing a significant cold start time for the following invocation, resulting in unpredictable latency; Simplified edge-cloud tier with available management information"
paper_230,Online Learning for Rate-Adaptive Task Offloading Under Latency Constraints in Serverless Edge Computing,"We consider the interplay between latency constrained applications and function-level resource management in a serverless edge computing environment. We develop a game theoretic model of the interaction between rate adaptive applications and a load balancing operator under a function-oriented pay-as-you-go pricing model. We show that under perfect information, the strategic interaction between the applications can be formulated as a generalized Nash equilibrium problem, and use variational inequality theory to prove that the game admits an equilibrium. For the case of imperfect information, we propose an online learning algorithm for applications to maximize their utility through rate adaptation and resource reservation. We show that the proposed algorithm can converge to equilibria and achieves zero regret asymptotically, and our simulation results show that the algorithm achieves good system performance at equilibrium, ensures fast convergence, and enables applications to meet their latency constraints.",Feridun Tütüncüoğlu; Slađana Jošilo; György Dán,IEEE/ACM Transactions on Networking,2023,31,2,695-709,Institute of Electrical and Electronics Engineers (IEEE),10.1109/tnet.2022.3197669,https://doi.org/10.1109/tnet.2022.3197669,journal-article,Semantic Scholar,high,"Latency, Cost, Resource Management","resource management, serverless, latency, load balancing, reinforcement learning","An online learning algorithm for applications to maximize their utility through rate adaptation and resource reservation; That under perfect information, the strategic interaction between the applications can be formulated as a generalized nash equilibrium problem, and use variational inequality theory to prove that the game admits an equilibrium; That the proposed algorithm can converge to equilibria and achieves zero regret asymptotically, and our simulation results show that the algorithm achieves good system performance at equilibrium, ensures fast convergence, and enables applications to meet their latency constraints",Not explicitly mentioned
paper_231,PLAYS: Minimizing DNN Inference Latency in Serverless Edge Cloud for Artificial Intelligence of Things,"Thanks to the capability of fine-grained resource allocation and fast task scheduling, serverless computing has been adopted into edge cloud to accommodate various applications, e.g., deep neural network (DNN) inference for Artificial Intelligence of Things (AIoT). In serverless edge cloud, the servers are started up on-demand. However, as a container-based architecture, the inherent sequential startup feature of container imposes high affection on the DNN inference performance in serverless edge clouds. In this article, we investigate the distributed DNN inference problem in serverless edge cloud with the consideration of such characteristics, aiming to eliminate the extra container startup time cost to minimize the DNN inference latency. We formulate this problem into a nonlinear optimization form and then linearize it into an integer programming problem, which is proved as NP-hard. To tackle the computation complexity, we propose a priority-based layer scheduling (PLAYS) algorithm. Extensive experiment results verify the effectiveness and the adaptability of our PLAYS algorithm in comparison with other state-of-art algorithms under several well known DNN models.",Hongmin Geng; Deze Zeng; Yuepeng Li; Lin Gu; Quan Chen; Peng Li,IEEE Internet of Things Journal,2024,11,23,37731-37740,Institute of Electrical and Electronics Engineers (IEEE),10.1109/jiot.2024.3443289,https://doi.org/10.1109/jiot.2024.3443289,journal-article,Semantic Scholar,high,"Survey, Latency, Cost, Resource Management","resource management, performance optimization, serverless, containerization, cloud computing, latency, reinforcement learning, deep learning, distributed systems",A priority-based layer scheduling (plays) algorithm,"As a container-based architecture, the inherent sequential startup feature of container imposes high affection on the dnn inference performance in serverless edge clouds; In serverless edge cloud with the consideration of such characteristics, aiming to eliminate the extra container startup time cost to minimize the dnn inference latency"
paper_232,Towards a container scheduling policy for alleviating total startup latency in serverless computing platform,"FaaS enables users to focus on developing function codes rather than managing complex infrastructure, as the serverless computing platform takes responsibility for resource management and dynamically scales computing resources for serverless functions. While serverless computing platform provides efficient hardware resource management and provisioning, they suffer from weaker computing performance due to the latency associated with serverless function startup. Startup latency refers to the time required to prepare execution environments for user functions. To alleviate this latency, this paper proposes a container scheduling policy aimed at reducing startup latency by reducing the likelihood of container cold starts. This is achieved by unifying language runtime images, creating pre-warm container pools, and warm containers. We formulate the startup latency problem and implement a scheduling policy in a serverless computing platform. Simulation results demonstrate that our proposed scheduling policy effectively reduces overall startup latency while ensuring optimal computing performance for user functions.",Chang Wang; Zhiqiong Liu; Jin Liu; Wang Li; Junxin Chen,"Third International Conference on Algorithms, Microchips, and Network Applications (AMNA 2024)",2024,,,,SPIE,10.1117/12.3032003,https://doi.org/10.1117/12.3032003,proceedings-article,Semantic Scholar,high,"Latency, Resource Management","cold start, resource management, serverless, containerization, latency, reinforcement learning",A container scheduling policy aimed at reducing startup latency by reducing the likelihood of container cold starts,"And implement a scheduling policy in a serverless computing platform; Infrastructure, as the serverless computing platform takes responsibility for resource management and dynamically scales computing resources for serverless functions"
paper_233,A Novel Technique to Improve Latency and Response Time of AI Models using Serverless Infrastructure,"Response time for AI-based models in time-critical applications is always a matter of concern. The situation is challenging when the model is deployed in a cloud-based infrastructure. To address this issue, a cloud-native development methodology called serverless infrastructure enables developers to create and execute applications without having to worry about managing servers. Generally, traditional systems require manual scaling, constant maintenance, and dedicated hardware resulting in high costs. To solve this, the AI model is deployed in serverless infrastructure services for hosting APIs that is to identify marine animals which have the potential to attack human beings at the seashores. The serverless infrastructure suffers from an initializing delay called cold start for occasional requests and hence the response time will be delayed even if the lambda function is free. The problem of cold starts is mitigated using the scheduler in the lambda function. The scheduler sends dummy requests to the server to keep the server warm and active. The AI model used as a test case utilizes Convolutional Neural Network Algorithms and Transfer Learning Technique, for detecting predators near the seashore. The model is deployed in a serverless infrastructure and has the benefits of automatic scaling, pay-per-use pricing, and decreased operational costs. The AI model is implemented in both serverless infrastructure and in Elastic Cloud Compute EC2. The performance of both systems was done for cost, latency, and response time. The proposed system provides promising results when compared to traditional server systems.",Bhanu Sankar Ravi; Chepuri Madhukanthi; P Sivasankar; John Deva Prasanna,2023 International Conference on Inventive Computation Technologies (ICICT),2023,,,428-433,IEEE,10.1109/icict57646.2023.10134379,https://doi.org/10.1109/icict57646.2023.10134379,proceedings-article,Semantic Scholar,high,"Latency, Cost, Resource Management","cold start, autoscaling, serverless, cloud computing, latency, elasticity, reinforcement learning, deep learning",System provides promising results when compared to traditional server systems,Of cold starts is mitigated using the scheduler in the lambda function
paper_234,FuncMem: Reducing Cold Start Latency in Serverless Computing Through Memory Prediction and Adaptive Task Execution,"Because serverless computing can scale automatically and affordably, it has become a popular choice for cloud-based services. However, despite these advantages, a serverless architecture is not suitable for applications requiring instantaneous executions because of cold starts. Existing techniques primarily focus on extending keep-alive time or pre-warming containers, which alleviate performance issues for specific serverless functions but introduce additional overhead to the architecture. To address these issues, we introduce FuncMem, a methodology designed to manage memory resources by prioritizing non-blocking asynchronous requests in a serverless architecture. First, FuncMem predicts and reduces excessive memory requirements for serverless functions. Second, it dynamically reschedules functions within an invoker, creating an adaptive task queue at runtime to mitigate cold starts and reduce wait times. We implemented our approach in OpenWhisk, a popular open-source framework, and evaluated it with multiple FaaS applications. Through comprehensive evaluations, we show that FuncMem achieves significant performance improvements, including a 63.48% reduction in cold start latency, a 46.98% decrease in memory allocation, a 54.93% reduction in cumulative execution time, a decrease in average waiting time from 5.22 seconds to 2 seconds, an increase in average throughput from 0.76 to 1.63 functions per second, and a decrease in average initialization time from 0.16 seconds to 0.7 seconds. Our results show the effectiveness of FuncMem in terms of latency and resource usage.",Manish Pandey; Young-Woo Kwon,Proceedings of the 39th ACM/SIGAPP Symposium on Applied Computing,2024,,,131-138,ACM,10.1145/3605098.3636033,https://doi.org/10.1145/3605098.3636033,proceedings-article,Semantic Scholar,high,"Survey, Latency, Resource Management","cold start, serverless, containerization, cloud computing, latency, throughput, queuing, reinforcement learning, prediction, memory management","Funcmem, a methodology designed to manage memory resources by prioritizing non-blocking asynchronous requests in a serverless architecture; That funcmem achieves significant performance improvements, including a 63; In openwhisk, a popular open-source framework, and evaluated it with multiple faas applications","Despite these advantages, a serverless architecture is not suitable for applications requiring instantaneous executions because of cold starts; Introduce additional overhead to the architecture"
paper_235,MASTER: Machine Learning-Based Cold Start Latency Prediction Framework in Serverless Edge Computing Environments for Industry 4.0,"The integration of serverless edge computing and the Industrial Internet of Things (IIoT) has the potential to optimize industrial production. However, cold start latency is one of the main challenges in this area, resulting in resource waste. To address this issue, we propose a new machine learning-based resource management framework called MASTER which utilizes an extreme gradient boosting (XGBoost) model to predict the cold start latency for Industry 4.0 applications for performance optimization. Furthermore, we created a new cold start dataset using an IIoT scenario (i.e. predictive maintenance) to validate the proposed MASTER framework in serverless edge computing environments. We have evaluated the performance of the MASTER framework using a real-world serverless platform, Google Cloud Platform for single-step prediction (SSP) and multiple-step prediction (MSP) operations and compared it with existing frameworks that used deep deterministic policy gradient (DDPG) and long short-term memory (LSTM) models. The experimental results show that the XGBoost-based resource management framework is the most successful model in predicting cold start with mean absolute percentage error (MAPE) values of 0.23 in SSP and 0.12 in MSP. It has been also identified that the Linear Regression model (utilized in the MASTER framework) has the least computational time (0.03 seconds) as compared to other deep learning and machine learning models considered in this work. Finally, we compare the energy consumption and $\text{CO}_{2}$ emissions of all models to emphasize resource awareness.",Muhammed Golec; Sukhpal Singh Gill; Huaming Wu; Talat Cemre Can; Mustafa Golec; Oktay Cetinkaya; Felix Cuadrado; Ajith Kumar Parlikad; Steve Uhlig,IEEE Journal of Selected Areas in Sensors,2024,1,,36-48,Institute of Electrical and Electronics Engineers (IEEE),10.1109/jsas.2024.3396440,https://doi.org/10.1109/jsas.2024.3396440,journal-article,Semantic Scholar,high,"Latency, Energy Consumption, Resource Management","cold start, resource management, performance optimization, serverless, cloud computing, latency, energy efficiency, reinforcement learning, deep learning, prediction, memory management",A new machine learning-based resource management framework called master which utilizes an extreme gradient boosting (xgboost) model to predict the cold start latency for industry 4; Master framework in serverless edge computing environments,"In this area, resulting in resource waste; Cold start latency is one of the main challenges in this area, resulting in resource waste"
paper_236,FaaSLight: General Application-level Cold-start Latency Optimization for Function-as-a-Service in Serverless Computing,"Serverless computing is a popular cloud computing paradigm that frees developers from server management. Function-as-a-Service (FaaS) is the most popular implementation of serverless computing, representing applications as event-driven and stateless functions. However, existing studies report that functions of FaaS applications severely suffer from cold-start latency. In this article, we propose an approach, namely, FaaSLight, to accelerating the cold start for FaaS applications through application-level optimization. We first conduct a measurement study to investigate the possible root cause of the cold-start problem of FaaS. The result shows that application code loading latency is a significant overhead. Therefore, loading only indispensable code from FaaS applications can be an adequate solution. Based on this insight, we identify code related to application functionalities by constructing the function-level call graph and separate other code (i.e., optional code) from FaaS applications. The separated optional code can be loaded on demand to avoid the inaccurate identification of indispensable code causing application failure. In particular, a key principle guiding the design of FaaSLight is inherently general, i.e., platform- and language-agnostic. In practice, FaaSLight can be effectively applied to FaaS applications developed in different programming languages (Python and JavaScript), and can be seamlessly deployed on popular serverless platforms such as AWS Lambda and Google Cloud Functions, without having to modify the underlying OSes or hypervisors, nor introducing any additional manual engineering efforts to developers. The evaluation results on real-world FaaS applications show that FaaSLight can significantly reduce the code loading latency (up to 78.95%, 28.78% on average), thereby reducing the cold-start latency. As a result, the total response latency of functions can be decreased by up to 42.05% (19.21% on average). Compared with the state-of-the-art, FaaSLight achieves a 21.25× improvement in reducing the average total response latency.",Xuanzhe Liu; Jinfeng Wen; Zhenpeng Chen; Ding Li; Junkai Chen; Yi Liu; Haoyu Wang; Xin Jin,ACM Transactions on Software Engineering and Methodology,2023,32,5,29-Jan,Association for Computing Machinery (ACM),10.1145/3585007,https://doi.org/10.1145/3585007,journal-article,Semantic Scholar,high,"Survey, Latency","cold start, performance optimization, serverless, cloud computing, latency, reinforcement learning","An approach, namely, faaslight, to accelerating the cold start for faas applications through application-level optimization; 78; 42",Existing studies report that functions of faas applications severely suffer from cold-start latency; Of faas
paper_237,FaaSConf: QoS-aware Hybrid Resources Configuration for Serverless Workflows,"Serverless computing, also known as Function-as-a-Service (FaaS), is a significant development trend in modern software system architecture. The workflow composition of multiple short-lived functions has emerged as a prominent pattern in FaaS, exposing a considerable resources configuration challenge compared to individual independent serverless functions. This challenge unfolds in two ways. Firstly, workflows frequently encounter dynamic and concurrent user workloads, increasing the risk of QoS violations. Secondly, the performance of a function can be affected by the resource reprovision of other functions within the workflow.With the popularity of the mode of concurrent processing in one single instance, concurrency limit as a critical configuration parameter imposes restrictions on the capacity of requests per instance. In this study, we present FaaSConf, a QoS-aware hybrid resource configuration approach that uses multi-agent reinforcement learning (MARL) to configure hybrid resources, including hardware resources and concurrency, thereby ensuring end-to-end QoS while minimizing resource costs. To enhance decision-making, we employ an attention technique in MARL to capture the complex performance dependencies between functions. We further propose a safe exploration strategy to mitigate QoS violations, resulting in a safer and efficient configuration exploration. The experimental results demonstrate that FaaSConf outperforms state-of-the-art approaches significantly. On average, it achieves a 26.5% cost reduction while exhibiting robustness to dynamic load changes.CCS CONCEPTS• Computing methodologies → Distributed computing methodologies.",Yilun Wang; Pengfei Chen; Hui Dou; Yiwen Zhang; Guangba Yu; Zilong He; Haiyu Huang,Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering,2024,,,957-969,ACM,10.1145/3691620.3695477,https://doi.org/10.1145/3691620.3695477,proceedings-article,Semantic Scholar,high,"QoS, Cost, Resource Management","serverless, reinforcement learning, distributed systems","Faasconf, a qos-aware hybrid resource configuration approach that uses multi-agent reinforcement learning (marl) to configure hybrid resources, including hardware resources and concurrency, thereby ensuring end-to-end qos while minimizing resource costs",Compared to individual independent serverless functions; Unfolds in two ways
paper_238,Serverless Computing for QoS-Effective NFV in the Cloud Edge,"Network Softwarization, particularly Network Function Virtualization (NFV), is revolutionizing networking by separating the hardware from the supported network functions, demonstrating unprecedented flexibility and cost-efficiency. With the rise of edge computing, NFV has found a strategic application at the network edge, where network functions are deployed closer to end-users and devices with improved performance and reduced latency. In this context, the serverless paradigm is gaining attention due to its fine-grained scalability, reduced management efforts, and resource efficiency. Despite the advantages, challenges arise from the ephemeral nature of serverless functions, leading to latency issues and hampering the creation of efficient coordination and orchestration mechanisms. Adopting this paradigm in resource-constrained scenarios, such as cloud edges, is even more challenging due to the insufficient presence of proper quality-of-service (QoS) mechanisms in these platforms. This article introduces our novel time effective middleware for priority oriented serverless network function virtualization (TEMPOS4NFV), a QoS-aware platform specialized in hosting serverless network functions in resource-constrained environments. TEMPOS4NFV addresses resource contention and coordination challenges, offering effective end-to-end QoS differentiation for network workloads executed over multiple federated sites. In addition, this article examines TEMPOS4NFV hosting a real virtual private network (VPN) case, demonstrating its ability to execute concurrent multi-site QoS differentiated workloads.",Andrea Sabbioni; Andrea Garbugli; Luca Foschini; Antonio Corradi; Paolo Bellavista,IEEE Communications Magazine,2024,62,4,40-46,Institute of Electrical and Electronics Engineers (IEEE),10.1109/mcom.001.2300182,https://doi.org/10.1109/mcom.001.2300182,journal-article,Semantic Scholar,high,"Latency, QoS, Cost, Energy Consumption, Resource Management","serverless, cloud computing, latency, reinforcement learning",Novel approach to serverless computing challenges,"Arise from the ephemeral nature of serverless functions, leading to latency issues and hampering the creation of efficient coordination and orchestration mechanisms; The advantages, challenges arise from the ephemeral nature of serverless functions, leading to latency issues and hampering the creation of efficient coordination and orchestration mechanisms"
paper_239,AI-Driven QoS-Aware Scheduling for Serverless Video Analytics at the Edge,"Today, video analytics are becoming extremely popular due to the increasing need for extracting valuable information from videos available in public sharing services through camera-driven streams in IoT environments. To avoid data communication overheads, a common practice is to have computation close to the data source rather than Cloud offloading. Typically, video analytics are organized as separate tasks, each with different resource requirements (e.g., computational- vs. memory-intensive tasks). The serverless computing paradigm forms a promising approach for mapping such types of applications, enabling fine-grained deployment and management in a per-function, and per-device manner. However, there is a tradeoff between QoS adherence and resource efficiency. Performance variability due to function co-location and prevalent resource heterogeneity make maintaining QoS challenging. At the same time, resource efficiency is essential to avoid waste, such as unnecessary power consumption and CPU reservation. In this paper, we present Darly, a QoS-, interference- and heterogeneity-aware Deep Reinforcement Learning-based Scheduler for serverless video analytics deployments on top of distributed Edge nodes. The proposed framework incorporates a DRL agent that exploits performance counters to identify the levels of interference and the degree of heterogeneity in the underlying Edge infrastructure. It combines this information along with user-defined QoS requirements to improve resource allocations by deciding the placement, migration, or horizontal scaling of serverless functions. We evaluate Darly on a typical Edge cluster with a real-world workflow composed of commonly used serverless video analytics functions and show that our approach achieves efficient scheduling of the deployed functions by satisfying multiple QoS requirements for up to 91.6% (Profile-based) of the total requests under dynamic conditions.",Dimitrios Giagkos; Achilleas Tzenetopoulos; Dimosthenis Masouros; Sotirios Xydis; Francky Catthoor; Dimitrios Soudris,Information,2024,15,8,480,MDPI AG,10.3390/info15080480,https://doi.org/10.3390/info15080480,journal-article,Semantic Scholar,high,"QoS, Energy Consumption, Resource Management","autoscaling, resource management, function placement, serverless, cloud computing, reinforcement learning, memory management, cpu allocation, distributed systems","Darly, a qos-, interference- and heterogeneity-aware deep reinforcement learning-based scheduler for serverless video analytics deployments on top of distributed edge nodes; Achieves efficient scheduling of the deployed functions by satisfying multiple qos requirements for up to 91; Framework incorporates a drl agent that exploits performance counters to identify the levels of interference and the degree of heterogeneity in the underlying edge infrastructure",There is a tradeoff between qos adherence and resource efficiency
paper_240,Deep Reinforcement Learning for QoS-Aware Package Caching in Serverless Edge Computing,"In serverless-enabled edge computing, container startup delay is one of the most critical issues because it violates some quality-of-service (QoS) requirements such as the ultra-low latency response times. Caching critical packages for the container can mitigate the startup delay associated with container instantiation. However, caches consume the memory resource that is highly limited at edge nodes. It means that the package cache must be carefully managed in serverless-enabled edge computing. This paper proposes a deep reinforcement learning (DRL)-based caching algorithm, which efficiently caches critical and popular packages with per-function response time QoS in hierarchical edge clouds. By conducting multi-agent reinforcement learning (MARL) for the caching agents of on-premise edge nodes in conjunction with a global reward that considers both cache hit and QoS violation numbers, the caching agents can be driven to cooperate with each other. The results of simulation demonstrate that the proposed DRL-based caching policy can improve QoS awareness more effectively than baselines. Compared with the LRU and LFU, the rate of violation fell by 18 and 27 percent, respectively.",Hongseok Jeon; Seungjae Shin; Chunglae Cho; Seunghyun Yoon,2021 IEEE Global Communications Conference (GLOBECOM),2021,,,6-Jan,IEEE,10.1109/globecom46510.2021.9685449,https://doi.org/10.1109/globecom46510.2021.9685449,proceedings-article,Semantic Scholar,high,"Latency, QoS, Resource Management","serverless, containerization, cloud computing, latency, reinforcement learning, memory management","A deep reinforcement learning (drl)-based caching algorithm, which efficiently caches critical and popular packages with per-function response time qos in hierarchical edge clouds; Drl-based caching policy can improve qos awareness more effectively than baselines",Caches consume the memory resource that is highly limited at edge nodes; Because it violates some quality-of-service (qos) requirements such as the ultra-low latency response times
paper_241,Improved QoS at the Edge Using Serverless Computing to Deploy Virtual Network Functions,"Multiaccess edge computing (MEC) will strengthen forthcoming 5G networks by improving the Quality of Service (QoS), in particular, reducing latency, increasing data processing rates, and providing real-time information to develop high-value Internet-of-Things (IoT) services. To enable data-intensive network services and support advanced analytics, many network operators have proposed to integrate MEC systems with network function virtualization (NFV) consolidating virtual network functions (VNFs) and edge capabilities on a shared infrastructure. As of yet, this integration is not fully established, with various architectural issues currently open, even at standardization level. For instance, any update to VNFs deployed in a MEC system requires a time-consuming manual effort, which affects the overall infrastructure operations. To address these pitfalls, VNFs can be decomposed into microservices, which maintain their own states and exhibit different resource consumption requirements. This article presents an approach to integration that leverages serverless computing to merge MEC and NFV at the system level and to deploy VNFs on demand, by combining MEC functional blocks with an NFV orchestrator using a Kubernetes cluster. We further investigate whether the resource utilization of a MEC system can be improved by leveraging networked FPGA-enabled MEC servers, through an extension of the edge layer that takes advantage of available programmable hardware. We quantitatively evaluate and demonstrate the improvement of 75% end-to-end latency, 99.96% VNF execution time, 26.9% resource utilization, and 15.8% energy consumption in comparison with traditional baselines of cloud, edge, and serverless-edge test cases for a high-definition real-time video streaming application.",Saqib Rasool Chaudhry; Andrei Palade; Aqeel Kazmi; Siobhan Clarke,IEEE Internet of Things Journal,2020,7,10,10673-10683,Institute of Electrical and Electronics Engineers (IEEE),10.1109/jiot.2020.3011057,https://doi.org/10.1109/jiot.2020.3011057,journal-article,Semantic Scholar,high,"Survey, Latency, QoS, Energy Consumption, Resource Management","serverless, microservices, cloud computing, latency, energy efficiency, reinforcement learning, distributed systems","Multiaccess edge computing (mec) will strengthen forthcoming 5g networks by improving the quality of service (qos), in particular, reducing latency, increasing data processing rates, and providing real-time information to develop high-value internet-of-things (iot) services","Currently open, even at standardization level"